\documentclass[a4paper]{book}
\usepackage{extarrows}
\usepackage{amsmath,amsthm}\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{answers}
\usepackage{eufrak}
\usepackage{eucal}
\usepackage{fancyhdr}
\usepackage{graphicx}
{\setlength\arraycolsep{2pt}
\usepackage{mathrsfs}
\usepackage{graphicx,fancyhdr}
\usepackage{graphicx} 
\graphicspath{ {./images/} }
\usepackage{caption}
\usepackage{CJKnumb}
\usepackage{titlesec}
\titleformat{\chapter}{}{}{0em}{\bf\huge}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}
\usepackage[colorlinks,urlcolor=blue,citecolor=blue,linkcolor=blue]{hyperref}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{xspace}
\usepackage{parskip}
\usepackage[sort,comma]{natbib}

\newtheorem{theorem}{Theorem}%[section]
\newtheorem{lemma}[theorem]{Lemma}%[section]
\newtheorem{example}[theorem]{Example}%[section]
\newtheorem{remark}[theorem]{Remark}%[section]
\newtheorem{note}[theorem]{Note}%[section]
\newtheorem{proposition}[theorem]{Proposition}%[section]
\newtheorem{definition}[theorem]{Definition}%[section]
\newtheorem{conjecture}[theorem]{Conjecture}%[section]
\newtheorem{corollary}[theorem]{Corollary}%[section]
\newtheorem{problem}[theorem]{Problem}%[section]
\newtheorem{condition}[theorem]{Condition}%[section]

\numberwithin{theorem}{section}%[fixes numbering]

\renewcommand{\proofname}{\textbf{Proof}}

\newenvironment{ddd}{\begin{rmdef}\rm}{\end{rmdef}}
\newenvironment{eee}{\begin{rmexa}\rm}{\end{rmexa}}
\newenvironment{rrr}{\begin{rmrem}\rm}{\end{rmrem}}
\newenvironment{pf}[1][Proof]{\par\noindent{\em #1}. }{\hfill\framebox(6,6)\par\medskip}

\usepackage{geometry}
 \usepackage[normalem]{ulem}
%\renewcommand{\baselinestretch}{1.5}

\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

\newcommand{\Poincare}{Poincar\'e\xspace}
\newcommand{\Holder}{Hölder}

\usepackage{graphicx} %picture
\usepackage{float} %picture
\usepackage{subfigure} %picture

\usepackage[nottoc,notlot,notlof]{tocbibind}
%Hölder
%\renewcommand{\baselinestretch}{1.5}
\let\cleardoublepage\clearpage
\begin{document}

\begin{titlepage}\phantom{|}\vspace{0.75in}
\begin{center}
    \underline{THE ISOPERIMETRIC PROBLEM}
\end{center}
\begin{center}
    \underline{}
\end{center}
\vspace{1.5in}%{2.0in}
\begin{center}
    Dissertation submitted at the University of Leicester \\
    in partial fulfilment of the requirements for \\ 
    the degree of Bachelor of Science of Mathematics\\
\end{center}
\vspace{.5in}
\begin{center}
    by
\end{center}
\vspace{.5in}
\begin{center}
    Steven Cheung \\
    Department of Mathematics \\
    University of Leicester \\
\end{center}
\vspace{0.5in}
\begin{center}
    May 2024
\end{center}
\end{titlepage}

\bibliographystyle{agsm}
\renewcommand{\bibname}{References}

\tableofcontents
\thispagestyle{empty}
\chapter*{Declaration}                % The * means no number for this chapter
\pagenumbering{arabic}
\addcontentsline{toc}{chapter}{\hspace{0.2in}Declaration}
All sentences or passages quoted in this project dissertation from other
people's work have been specifically acknowledged by clear cross referencing
to author, work and page(s). I understand that failure to do this amounts
to plagiarism and will be considered grounds for failure in this module and
the degree examination as a whole.


\bigskip

\noindent
Name: Steven Cheung


\bigskip

\noindent
Signed: (add the signature from adobe pdf editor)


\bigskip

\noindent
Date: 

%-------------------------------------------------------------------------------------
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{\hspace{0.2in}Abstract}
In general, we want the maximum area whose boundary must pertain a specific length. This basic idea of the isoperimetric problem leaves many mathematicians puzzled still to this day.
\newline
\newline
\textbf{Rich History:} Our problem is one not to be trifled with, and across many a centuries to even dating back to 200 BC, we can see the events unfold of how we learn about how the small intricacies become part of something larger and more complex. 
\newline
\newline
\textbf{2-D Case:} The isoperimetric problem revolves around finding the shape that achieves the maximum enclosed area among all closed curves with a given length. We introduce three proofs from different approaches from different disciplines of mathematics. Amongst the many simple curves, we identify that the circle is unique for pertaining the optimal area. We touch on Steiner's proof along the way to provide his insight into how this particular curve is maximal comparative to others. We then show how the Euler-Lagrange Equation comes into effect; the finding of extremal curves with fixed areas and fixed perimeters. Finally, we will then show how Fourier analysis and differential geometry can be used as tools to prove the problem. Our overall findings and conclusions are to show that across many a proofs through the decades, mathematicians have opted to find curves under this fixed perimeter constraint with additional factors taking place. 
\newline
\newline
\textbf{N-Dimensions:} Spherical in 3-D, which allows us to refer back to our 2-D case. Here we will discuss the spherical isoperimetric inequality. To begin we introduce several more important tools, the support function, Hausdorff metric, volume and surface measure, and then prove the Brunn-Minkowski inequality. Using this inequality, the proof of the isoperimetric inequality in $n$-dimension will be shown. We will then see how the 2-D and the 3-D cases will behave under this new result.
\newline
\newline
\textbf{Manifolds:} A light introduction to the isoperimetric inequalities in manifolds.
\newline
\newline
Finally a comparison between the proofs. Where we shall discuss the limitations of each proof and how it differs to each other.

%-------------------------------------------------------------------------------------
%\chapter{Introduction}
%\addcontentsline{toc}{chapter}{\hspace{0.2in}Introduction}
\chapter{Historical Notes}
%\addcontentsline{toc}{section}{\hspace{0.2in}Historical Notes}
Isoperimeter, isos which is ancient Greek for equal and perimetron for perimeter. The isoperimetric problem, even though it was not properly formalized, was already thought about all throughout the history. 
\newline
\newline
Book V of Pappus of Alexandria's Mathematical collections~\citep{wiegert2010sagacity} began with a preface titled ``On the Sagacity of Bees'', rather than the history of mathematicians past or their accomplishments to follow. This was written near the end of the 3rd century $A.D.$. Observing, Pappus credited the bees with ``a certain geometrical forethought'' (Thomas 593~\citep{ivor1941selections}) for their nearly faultless hexagonal comb structure. He wrote
\begin{center}
    \begin{quote}
        ``Bees know just this fact which is useful to them, that 
        the hexagon is greater than the square and the triangle 
        and will hold more honey for the same expenditure of 
        material in constructing each''
    \end{quote}
    (Thomas 593~\citep{ivor1941selections})
\end{center}
Beyond the efficiency of bees, Pappus prefaced, ``We'' he continued
\begin{center}
    \begin{quote}
        ``... will {}investigate a somewhat wider problem, namely that, 
        of all equilateral and equiangular plane figures having an equal 
        perimeter, that which has the greater number of angles is always great 
        and the greates of them all is the circle having it's perimeter equal to them''
    \end{quote}
    (Thomas 593~\citep{ivor1941selections})
\end{center}

Pappus then started working on the isoperimetric problem, which included numerous smaller problems within it. The main objective of the problem is to determine which of the planes and figures with the same perimeter has the largest area amongst them.

Although Pappus addressed the problem in the collections, it has been a topic of interest for centuries before. Appearing in both mathematical and literary materials and captivating the minds of mathematicians. 
\newline
\newline
The isoperimetric problem demonstrates ancient mathmaticians' perceptiveness and the consistency of mathematical endeavor over time, even in the modern age. The problem have been used by poets and historians, despite its mathematical nature. Most famously, Virgil made use of the concept in his Roman epic, The Aeneid. To quote Virgil
\begin{center}
    \begin{quote}
        ``At last they landed, where from far your eyes
        May view the turrets of new Carthage rise;
        There bought a space of ground, which Byrsa call'd,
        From the bull's hide they first inclos'd and wall'd.''
    \end{quote}
    (Book I of Aeneid~\citep{virgil1981aeneid})
\end{center}

Virgil's version has it that Dido, daughter of the king of Tyre, fled home after her brother killed her husband. Dido ended up on the north coast of Africa, where she bargained to buy as much land as she could enclose with an oxhide. Thus, she cut the hide into thin strips, where she presumably met and solved enclosing the largest area with a given perimeter - the isoperimetric problem. Dido may have been clever enough and chose an area by the coast to exploit the shore as part of the perimeter. But this mostly spoils the purity of posed problem. Kline concludes~\citep{kline1985mathematics}. The Aeneid was written between $29$ and $19 B.C.$.
\begin{figure}[h]
    \begin{center}   
        \includegraphics[width=120mm]{dido_1}
        \caption{Representations of areas bounded by common shapes of the same perimeter. The semicircle, answer to Dido's problem which contains the greatest area. (image and caption from~\citep{demjanenko2008isoperimetric})}
    \end{center}
\end{figure}
\leavevmode

In the 3rd century $A.D.$, Roman historian Marcus Junianus Justinus compliled an account of Carthaginian folklore that the legendary founding of Carthage by Dido, called Elissa by the Greeks (the mythological origin of the city):
\begin{center}
    \begin{quote}
        ``Then [Elissa] bout some land, just as much as could be covered by a cow's hide, where she could give some recreation to her men... She next gave orders for the hide to be cut into very fine strips, and in this way she took possession of a great area than she had apparently bargained for''
    \end{quote}
    (Book XVIII 157~\citep{yardley1994justin})
\end{center}

Since ancient Greece, around $100B.C.$, they wanted to measure the size of islands by timing how long it takes to circumnavigate the entire island. Proclus, a classical mathematician, mocked geometers for ``measuring the size of a city from the lengths of its walls''. To the common person of antiquity, two shapes with equal perimeter may have different areas. Interestingly, some individuals exploited this misconception to defraud others of land. Considerably more amusing, these con artists were viewed as liberal which demonstrates how unnatural the idea of shapes with a similar edge having different regions was to the old Greeks.
\newline
\newline
Geoffrey of Monmouth's Historia Regum Britanniae (History of the Kings of England), a 12th century $A.D.$ chronicle of Arthurian legends, mentions the isoperimetric problem. In this story, Hengist, a German duke, appeals to King Vortigern for land in exchange for his military service:
\begin{center}
    \begin{quote}
        ``'Grant', said Vortigern, 'unto thy servant but so much only as may be compassed round about by a single thong within the land thou hast given me, that so I ma build me a high place therein whereunto if need be I may betake me’...Straightaway...Hengist took a bull’s hide, and wrought the same into a single thong throughout. He then compassed round with his thong a stony place that he had right cunningly chosen, and within the space thus meted out did begin to build a castle that was afterwards called in British , Kaercorrei, but in Saxon, Thongceaster, the which in Latin’s speech is called Castrum corrigae'''
    \end{quote}
    (Monmouth 105-106~\citep{evans1920histories})
\end{center}
\leavevmode
\newline
\newline
Thus, the poets and historians who chronicled the exploits of these mythological characters as well as the figures themselves found special meaning in the isoperimetric problem. Despite its extensive implications, the notion of isoperimetry was ``naturally greek''. The Greeks have pretty much solved it, by their standards. Zenodorus was an ancient Greek mathematician from around $200B.C.$ to $120B.C.$. And have mostly proved that a circle has greater area than any polygon with the same perimeter. Majority of his work was lost. However, fortunately, parts of his work survived through references by Pappus and Theon of Alexandria.

Theon of Alexandria then develops this idea, with a summary of the proofs present by Zenodorus in ``On Isoperimetric Figures''. According to Theon, Zenodorus did not initiate his disussion of isoperimetry with the circle. Rather he stated that ``Of all rectilinear figures having an equal perimeter - I mean equilateral and equiangular figures - the greatest is that which has the most angles'' (Thomas 388-389~\citep{ivor1941selections}). In more modern language, the proposition is stated as follows: ``Given two regular $n$-gons with the same perimeter, one with $n=n_1$ and the other with $n=n_2>n_1$ then the regular $n_2$-gon has the larger area'' (Nahin 47~\citep{nahin2021least}). Following this, Zenodorus was able to arrive at the proposition that ``if a circle have an equal perimeter with an equilateral, equiangular, and rectilinear figure, the circle shall be the great" (Thomas 391~\citep{ivor1941selections}). As Heath notes in his ``History of Greek Mathematics'', Zenodorus chose to base his proof of this proposition on the theorem already established by Archimedes that ``the area of a circle is equal to the right-angled triange with perpendicular side equal to the radius and base equal to the perimeter of the circle'' (Heath 209~\citep{heath2013history}). From here, Zenodorus proceeded on the basis of two preliminary lemmas: first that ``if there be two triangles on the same base and with the same perimeter, one being isosceles and the other scalene, the isosceles triangle has the greater area'' (Heath 209~\citep{heath2013history}); second that ``given two isosceles triangles not similar to one another, if [one constructs] on the same bases, two triangles similar to one another such that the same of the areas of the similar triangles is great than the sum of the areas of the non-similar triangles'' (Heath 210~\citep{heath2013history}). Both commentors seem to hint that it will be covered in subsequent chapters, but as Heath bemoans ``in the text as we have it the promise is not fulfilled'' (Heath 212~\citep{heath2013history}) (this entire paragraph is lifted from~\citep{wiegert2010sagacity})
\newline
\newline
In the ancient world, the problem of isoperimetry was associated with the work of Zenodorus and his commentator, Pappus. It was the work of a Swiss mathematician Jacob Steiner (1796-1863) who tackled the isoperimetric theorem in the modern word.

Indeed, the problem of isoperimetry in the nineteenth century emerged at an important juncture in mathematical thought. Mathematicians working in all fields of inquiry struggled over the use of analytic (i.e. calculus) or synthentic (i.e pure geometry) methods in solving problems~\citep{wiegert2010sagacity}. Nahin notes that Steiner's 1842 geometrical proof of the isoperimetric theorem is still regarded as a ``model of mathematical ingenuity'' despite subsequent discoveries of defects in the synthetic approach. The following propositions must be understood to be logically equivalent in order for Steiner's proof of the isoperimetric theorem to hold:
\begin{center}
    \begin{quote}
        A. ``Of all closed curves in a plane with equal perimeters, the cicle bounds the largest area''
        \newline
        [and]
        \newline
        B. ``Of all closed curves in a plane with equal areas, the cricle has the smallest perimeter''
    \end{quote}
    (Nahim 55~\citep{nahin2021least})
\end{center}

Steiner thought he had demonstrated that the circle was the answer to the isoperimetric problem. As later researchers, especially the German mathematician Peter Dirichlet (1805-1859) remarked, Steiner had made an underlying assumption not explicitly addressed in his proof, namely that a solution existed (Nahin 59~\citep{nahin2021least}).
\newline
\newline
Other mathematicians attempted to tackle the isoperimetric problem from the analytic or calculus-based perspective. And to no avail. We will expand on this in later sections.

Problems posed by the ancients, not only speeded the progression towards more rigorous and complete systems of mathematics, but also prompted later innovators to develop new systems to deal with these early questions. The isoperimetric problem thus demonstrates an important continuity in mathematical thought. From Zenodorus to Pappus and from Steiner to the mathematicians of the twenty-first century, isoperimetry has transcended its origins in ancient geometry to become a building block of more modern analytic systems of mathematics~\citep{wiegert2010sagacity}. Below is a table summary, where we have timelined the history of the problem:
\begin{center}
    \begin{tabular}{||c c c||} 
        \hline
        Name & Time Period & What they did? \\ [0.5ex] 
        \hline
        Pappus & written 3rd Century $A.D.$ & started working about the isoperimetric problem \\ && from bee's hexagonal comb structure  \\ 
        \hline
        Dido (The Aeneid) & 29$B.C.$-19$B.C.$ & enclose as much land with oxhide \\
        \hline
        Zenodorus & 200$B.C.$-120$B.C.$ & more angles means more area \\
        \hline
        Ancient Greece & 100$B.C.$ & circumnavigate land \\
        \hline
        Arthurian Legends & 12th Century $A.D.$ & exchanged land for military service \\
        \hline
        Steiner & 1842 & first proof (existence) \\ 
        \hline
        Peter Dirichlet & 1805-1859 & noticed flaw with Steiner's proof \\ [1ex]
        \hline
    \end{tabular}
\end{center}

\chapter{Preliminaries}
%\addcontentsline{toc}{chapter}{\hspace{0.2in}Important Preliminaries}
\section{2-Dimensional Preliminaries}
We will take for granted the Jordan Curve Theorem
\begin{theorem}[Jordan Curve Theorem]
    A simple closed curve in the plane divides the plane into two regions, one compact and one non-compact, and in the common boundary of both regions.
\end{theorem} 

The Jordan Curve Theorem is just a standard, but highly non-trivial, result of the topology of $\mathbb{R}^2$, that any simple closed curve in the plane has an 'interior' and 'exterior': more precisely, the complement of the image of $\gamma$ (i.e. the set of two points $\mathbb{R}^2$ that are \underline{not} in the image of $\gamma$) is the disjoint union of two subsets of $\mathbb{R}^2$, denoted by $int(\gamma)$ and $ext(\gamma)$, with the following properties:
\begin{enumerate}
    \item $int(\gamma)$ is bounded, i.e. it is contained inside the circle of sufficiently large radius.
    \item $ext(\gamma)$ is unbounded
    \item Both of the regions $int(\gamma)$ and $ext(\gamma)$ are connected, i.e. they have the property that any two points in the same region can be joined by a curve contained entirely in the region (but any curve joining a point of $int(\gamma)$) to a point of $ext(\gamma)$ must cross the curve $\gamma$)
\end{enumerate}


\begin{note} 
    When we talk of the region bounded by a simple closed curve in the plane, we always mean the compact region
\end{note}

\begin{definition}
    A closed curve, is a curve that changes direction but does not cross itself whilst changing direction and which completely encloses an \textit{area}. 

    An open curve, is a curve that does not enclose any area within itself and has two endpoints.
\end{definition}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=130mm]{ClosedCurve}
        \caption{(i) are closed curves, (ii) are open curves}
    \end{center}
\end{figure}\leavevmode

\begin{definition}
    A simple curve, is a curve that changes direction but does not cross itself whilst changing direction. 

    A nonsimple curve, is a curve that cross itself.
\end{definition}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=130mm]{SimpleCurves}
        \caption{(i) is simple curves, (ii) is nonsimple curves}
    \end{center}
\end{figure}\leavevmode

\begin{definition}
    A simple closed curve in $\mathbb{R}^2$, is a closed curve in $\mathbb{R}^2$ that has no self-intersections
\end{definition}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=130mm]{SimpleClosedCurveExamples}
        \caption{(i) is simple curves, (ii) is nonsimple curves}
    \end{center}
\end{figure}\leavevmode

The two definitions, above, are vital into understanding the main theorem. Since the isoperimetric inequality is a global result, we borrow concepts from topology, such as:

\begin{definition}
    A function is bounded if $\exists M \in \mathbb{R}$ such that $\left| f(x) \right| \leq M$.
\end{definition}

\begin{definition}
	Let $f:D\to\mathbb{R}$ a function and $c\in\mathbb{R}$ such that there exists $p>0$ such that $(c-p,c+p)\in D$. Then $f$ is called \textit{continuous} at $c$ if
	\begin{center}
		$\underset{x\to c}{\lim}f(x)=f(c)$.
	\end{center}
\end{definition}

\begin{definition}
    Let $X$ be a topological space and $A \subset X$. An open cover for $A$ is a family $\{U_\lambda\}_{\lambda\in I}$ of open subsets of $X$ such that
    \begin{center}
        $A \subset\underset{\lambda\in I}{\bigcup}{U_\lambda}$
    \end{center}
    An open cover is called finite if $\|I\|<\infty$. If $\{U_\lambda\}_{\lambda\in I}$ is an open cover for $A$ and $J \subset I$ is such that $A\subset\underset{\lambda\in J}{\bigcup}{U_\lambda}$, then $\{U_\lambda\}_{\lambda\in J}$ is called a subcover of $\{U_\lambda\}_{\lambda\in I}$.
\end{definition}

\begin{definition}
    A subset $A \subset X$ of a topological space called compact if every open cover of $A$ has a finite subcover. A space is called compact space if it is a compact subset of itself.
\end{definition}

\begin{definition} (Heine-Borel Theorem)
    A set in $\mathbb{R}^n$ is said to be compact if it is closed and bounded.
\end{definition}

\newpage
\subsection{Fourier Series}
We use Fourier series to expand periodic functions from $\mathbb{B}$ to $\mathbb{C}$. This is so we can simplify the fourmulas of area by rewriting it using Fourier coefficients. We shall be introducing the theory behind Fourier series and answer the questions of existence and convergence of Fourier expansions.

\begin{definition}
    A function $f:\mathbb{R}\to\mathbb{C}$ is called \textit{periodic} with period $\mathrm{L}\in\mathbb{R}$ if it satisfies
    \begin{center}
        $f(x+L)=f(x)$
    \end{center}
    for all $x\in\mathbb{R}$.
\end{definition}

\begin{remark}
    We will concentrate functions with period $2\pi$. We can transform a periodic function $f$ with period $\mathrm{L}$ to a function with period $2\pi$ using $\displaystyle \mathrm{F}(x):=f(\frac{\mathrm{L}}{2\pi}x)$.
\end{remark}

\begin{definition}
    Let $f:\mathbb{R}\to\mathbb{C}$ be a periodic function that is Riemann integrable on the interval $[0,2\pi]$. Then the numbers
    \begin{center}
        $\displaystyle c_{k}:=\frac{1}{2\pi}\int_{0}^{2\pi}f(x)e^{-ikx}\,dx\;$, $k\in\mathbb{Z}$
    \end{center}
    are called the \textit{Fourier coefficients} of $f$. With the partial sums $\mathfrak{F}[f](x)=\sum_{k=-\mathrm{N}}^{\mathrm{N}}c_{k}e^{ikx}$, we define the formal limit of the partial sums
    \begin{center}
        $\displaystyle \mathfrak{F}[f](x):=\underset{n\to\infty}{\lim}\mathfrak{F}[f](x)=\overset{\infty}{\underset{k=-\infty}{\sum}}c_{k}e^{ikx}$
    \end{center}
    as the \textit{Fourier series} of $f$.
\end{definition}

\subsection{Plane Curves}
In this subsection, we consider curves in the Euclidean plane. Here, we will introduce briefly the language of the differential geometry of curves.

\begin{definition}
    Let $\mathrm{I}\subseteq\mathbb{R}$ be an interval. A \textit{plane parameterized curve} is a continuously differential map $c:\mathrm{I}\to\mathbb{R}^{2}$. A plane parametrized curve is called \textit{regular}, if for all $t\in\mathrm{I}$ the derivative of $c$, denoted by $\dot{c}=(c'_{1},c'_{2})$, satisfies $\dot{c}(t)\neq0$.
\end{definition} 

\begin{note}
    From now on, all our curves will be regularly parameterized curves.
\end{note}

\begin{definition}
    A curve $c:\mathbb{R}\to\mathbb{R}^{2}$ is called
    \begin{itemize}
        \item periodic with $\mathrm{L}$, if it holds that
        \begin{enumerate}
            \item $\exists\mathrm{I}>0: c(t+\mathrm{L})=c(t)\;\forall t\in\mathbb{R}$, and
            \item $\forall\mathrm{L}'$ with $c(t+\mathrm{L}')=c(t)\;\forall t\in\mathbb{R}$: $\mathrm{L}\leq\mathrm{L}'$.
        \end{enumerate}
        \item closed if it has a periodic regular parametrization
        \item simply closed if it has a periodic regular parametrization $c$ with period $\mathrm{L}$ so that $c|_{[0,\mathrm{L})}$ is injective.
    \end{itemize}
\end{definition}

\begin{remark}
    The definition 1.2.16 of a period above is a special case of 1.2.11. Contrary to defition 1.2.11, we require that the period $\mathrm{L}$ is the smallest possible number with the needed properties. Later this will be important because we want to know at which time the curve finishes one round around the domain. Furthermore, we need a boundary curve of a domain and, if we have a curve that is not simply close, our enclosed set is not connected.
\end{remark}

\subsection{Length and Area}
In this subsection we will show the relation between the parameterization of a curve and the enclosed area. First we, will introduce a few properties on the length of a curve that can be proved with simple computation.

\begin{definition}
    A unit speed curve is a regular curve $c:\mathrm{I}\to\mathbb{R}^2$ satisfying $||\dot{c}(t)||=1\;\;\;\forall t\in\mathrm{I}$, where $||\cdot||$ is the Euclidean norm.
\end{definition}

\begin{proposition}
    For all regualr curves $c$, there exists a transformation of parameter $\varphi$ so that the reparameterization $c\circ\varphi$ is a unit speed curve
\end{proposition}

\begin{definition}
    Let $c:[a,b]\to\mathbb{R}^2$ be a curve. Then $\mathrm{L}[c]:=\int_{a}^{b}||\dot{c}(t)||\,dt$ is called the length of c.
\end{definition}

\begin{lemma}
    The length of a curve is invariant under reparameterization.
\end{lemma}

\begin{remark}
    Before we prove the Isoperimetric Inequality we will show a way to compute the area of a domain using the parametrization of the boundary curve.
\end{remark}

\begin{lemma}
    let $\mathrm{G}\subseteq\mathbb{R}^{2}$ be a bounded domain such that the boundary is a simply closed curve with parameterization $c(t)=(x(t),y(t))^{\mathrm{T}}$ and period $\mathrm{L}$, Then
    \begin{center}
        $\mathrm{A}[\mathrm{G}]=-\int_0^{\mathrm{L}} \dot{x}(t) y(t) d t=\int_0^{\mathrm{L}} x(t) \dot{y}(t) d t=\frac{1}{2} \int_0^{\mathrm{L}}(x(t) \dot{y}(t)-\dot{x}(t) y(t)) d t .$
    \end{center}    
\end{lemma}
\begin{proof}
    Let $c$ be the curve mentioned above. Without loss of generality, assume that $c$ is a unit speed curve and is positively oriented. Let $n(t)$ be the inner unit normal of $c(t)$ and define $i d_{\mathbb{R}^2}: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ with $i d_{\mathbb{R}^2}(x, y)=(x, y)$. Using Gauss theorem and the fact that the curve is a unit speed curve, we get
    $\int_{\mathrm{G}}\left(\frac{\partial\left(i d_{\mathbb{R}^2}\right)^1}{\partial x}+\frac{\partial\left(i d_{\mathbb{R}^2}\right)^2}{\partial y}\right) d x d y=\int_{\mathrm{G}} \operatorname{div} i d_{\mathbb{R}^2} d x d y=-\int_0^{\mathrm{L}}\left\langle i d_{\mathbb{R}^2}(c(t)), n(c(t))\right\rangle d t .$

    First look at the left side of this equation
    $\int_{\mathrm{G}}\left(\frac{\partial\left(i d_{\mathbb{R}^2}\right)^1}{\partial x}+\frac{\partial\left(i d_{\mathbb{R}^2}\right)^2}{\partial y}\right) d x d y=\int_{\mathrm{G}}\left(\frac{\partial x}{\partial x}+\frac{\partial y}{\partial y}\right) d x d y=2 \int_{\mathrm{G}} d x d y=2 \mathrm{~A}[\mathrm{G}] .$

    For the right side, we compute
    $\begin{aligned}
    -\int_0^{\mathrm{L}}\left\langle i d_{\mathbb{R}^2}(c(t)), n(c(t))\right\rangle d t & =-\int_0^{\mathrm{L}}(-x(t) \dot{y}(t)+\dot{x}(t) y(t)) d t \\
    & =\int_0^{\mathrm{L}}(x(t) \dot{y}(t)-\dot{x}(t) y(t)) d t .
    \end{aligned}$

    Putting both sides together, we get
    $2 \mathrm{~A}[\mathrm{G}]=\int_0^{\mathrm{L}}(x(t) \dot{y}(t)-\dot{x}(t) y(t)) d t \Leftrightarrow \mathrm{A}[\mathrm{G}]=\frac{1}{2} \int_0^{\mathrm{L}}(x(t) \dot{y}(t)-\dot{x}(t) y(t)) d t .$

    Using partial integration, it follows
    $\int_0^{\mathrm{L}} x(t) \dot{y}(t) d t=\underbrace{[x(t) y(t)]_0^{\mathrm{L}}}_{=0}-\int_0^{\mathrm{L}} \dot{x}(t) y(t) d t=-\int_0^{\mathrm{L}} \dot{x}(t) y(t) d t .$
\end{proof}

\subsection{Basics in Convex Geometry}
You may be wondering why we would study convex geometry but this is the necessary language and notation, which will be used in the following sections. Convex geometry will give us a way to describe objects and sets in Euclidean space; We consider convex, compact sets in $\mathbb{R}^n$ and their properties (areas, volumes, etc). The term convex is used to refere to a shape that has a curve or a protuding suface. In other words, all the lines across the outline are straight and they point outwards. Examples of convex polygons are signboard, a football, etc. The complement of convex is concave, where the shape curves inwards and no protuding surface at some point. For example the inside of a bowl. A clear definition of when a set is convex is given below. 

As our goal is to maximize, get the largest area, it is quite clear on why we choose convex curves over concave curves. When studying the polygons, it is easy to think that all convex polygons are regular as all regular polygons are convex, but that is not the case.
\newline

\begin{definition}
	A set $A\subseteq\mathbb{R}^n$ is called $convex$ if all $x,y\in A$ satisfy $(1-\lambda)x+\lambda y\in A$, $\forall\lambda\in[0,1]$.
\end{definition}

\begin{remark}
	Intersections of convex sets, and for affine maps the pre-image and the image of convex sets are also convex. Let $A, B \subset\mathbb{R}^n$ be convex and $\lambda\in\mathbb{R}$. Then
	\begin{center}
		$\lambda B=\{x\in\mathbb{R}^n;\exists b\in B$ with $x=\lambda\dot b\}$, and
	
		$\lambda+B=\{x\in\mathbb{R}^n;\exists a\in A, b\in B$ with $x=a+b\}$
	\end{center}
	are also convex
\end{remark}

\begin{definition}
	Let $A\subseteq\mathbb{R}^n$ be non-empty, compact and convex. Then $A$ is called $convex$ $body$. The set of all convex bodies of $\mathbb{R}^n$ is denoted by $\mathscr{K}^n$ and the set of all convex bodies in $\mathbb{R}^n$ with non-empty interior is denoted by $\mathscr{K}_{0}^{n}$.
\end{definition}

\begin{definition}
	\begin{itemize}
		\item Define $\bar{R}=\mathbb{R}\cup\{ \infty,-\infty\}$.
		\item A function $f:\mathbb{R}^n\to\bar{\mathbb{R}}$ is called $proper$ if it satisfies $\{f=-\infty\}=\emptyset$ and $\{f=\infty\}\neq\mathbb{R}^n$.
		\item A proper function $f:\mathbb{R}^n\to\bar{\mathbb{R}}$ is called $convex$ if it satisfies 
		\begin{center}
			$\displaystyle f((1-\lambda)x+\lambda y)\leq(1-\lambda)f(x)+\lambda f(y)$
		\end{center}
		for all $x, y\in\mathbb{R}^n$ and $0\leq\lambda\leq1$.
		\item . A function $f:D\to\bar{\mathbb{R}}$ with $D\subseteq\mathbb{R}^n$ is called convex if its expansion on $\mathbb{R}^n$
		\begin{center}
			\begin{equation}
				  \tilde{f}(x):=\begin{cases}
				    	f(x), & \text{for $x\in D$}.\\
				   	 \infty, & \text{otherwise}.
				  \end{cases}
			\end{equation}
		\end{center}
		is convex.
		\item A function $f$ is $concave$ if $-f$ is convex.
	\end{itemize}
\end{definition}
\begin{figure}[h]
    \begin{center}   
        \includegraphics[width=80mm]{ConcaveFunction}
        \caption{The blue, green and red graphs are associated to convex functions but the pink graph is associated to a concave.}
    \end{center}
\end{figure}

\section{$n$-Dimensional Preliminaries}

\subsection{The Support Function}
The following section introduces the support function, which can be used to ascertain the "height" of a convex body. The support function is a convex function on $\mathbb{R}$ and is compatible with many geometric opetions such as scaling, translation, rotation and importantly the \textbf{Minkowski addition}. These characteristics make the support function one of the most important foundational ideas in convex geometry.

\begin{definition}
    Let $K\subseteq\mathbb{R}^n$ be non-empty, convex and closed. The $support$ $function$ $h(K,\cdot\space)=h_k$ is defined by
    \begin{center}
        $h(K,u):=\sup\{\langle x,u\rangle;x\in K\}$ for $u\in\mathbb{R}^n$
    \end{center}
    Furthermore we define for $u\in dom\,h(K,\cdot)\backslash\{0\}$
    \begin{center}
        $H(K,u):=\{x\in\mathbb{R}^n;\langle x,u\rangle=h(K,u)\}$ a supporting plane of K,
        
        $H^{-}:=\{x\in\mathbb{R}^n;\langle x,u\rangle\leq h(K,u)\}$ a support half space of K, and 
        
        $F(K,u):=H(K,u)\cap K$ a support domain of K
    \end{center}
\end{definition}

\begin{remark}
    The suuport function for $u\in\mathbb{S}^{n-1}\cap dom\,h(K,\cdot)$ can be viewed as the distance of the supporting plane at K with outer unit normal to the origin.(give some figure)
\end{remark}

\begin{remark}
    For $B^{n}$ and $u\in\mathbb{S}^{n-1}$ the support function can be computed easily. For arbirary $x\in B^{n}$ and $u\in\mathbb{S}^{n-1}$ Cauchy Swarz gives us
    \begin{center}
        $|\langle x,u\rangle|\leq||u||\:||x||\leq1$
    \end{center}
    The support function is equal 1 on $B^{n}$ since the maximum is also 1.
\end{remark}

\begin{remark}
    The support funtion has the following properties:
    \begin{enumerate}
        \item $h_{k}\leq h_{L}$ if and only if $K\subseteq L$,
        \item $h(\{z\},u)=\langle x,y\rangle$ for $z,u\in\mathbb{R}^{n}$,
        \item $h(K+t,u)=h(K,u)+\langle t,u\rangle$ for $t,u\in\mathbb{R}^{n}$,
        \item $h(\lambda K, u)=\lambda h(K,u)=h(K,\lambda u)$ for $\lambda\in\mathbb{R}_{0}^{+}$, $u\in\mathbb{R}^{n}$,
        \item $h(-K,u)=h(K,-u)$ for $u\in\mathbb{R}^{n}$,
        \item $h(K,u_{1}+u_{2})\leq h(K,u_{1})+h(K,u_{2})$ for $u_{1},u_{2}\in\mathbb{R}^{n}$,
        \item $h(K,\cdot)=: h_{k}$ is convex.
    \end{enumerate}
\end{remark}

\begin{lemma}
    Let $K,L\in\mathscr{K}^{n}$, then$h(K+L,u)=h(K,u)+h(L,u)$.
\end{lemma}
\begin{proof}
    Let $u\in\mathbb{R}^{n}\backslash\{0\}$.

    First, we show $h(K+L,u)\geq h(K,u)+h(L,u)$. Since $K$ and $L$ are compact, the supremum of the support function is attained. Thus, there exists $x\in K$ and $y\in L$ such that $h(L,u)=\langle y,u\rangle$ and $h(K,u)=\langle x,u\rangle$.

    Then we have
    \begin{center}
        $h(K,u)+h(L,u)=\langle y,u\rangle+\langle x,u\rangle=\langle x+y,u\rangle\leq h(K+L,u)$.
    \end{center}

    Secondly, we want to show $h(K+L,u)\leq h(K,u)+h(L,u)$. Let $z\in K+L$ so that $H(K+L,u)=\langle u,z\rangle$. Then there exists $x\in K$ and $y\in L$ such that $z=x+y$. It follows
    \begin{center}
        $h(K+L,u)=\langle z,u\rangle=\langle x+y,u\rangle=\langle x,u\rangle+\langle y,u\rangle\leq h(K,u)+h(L,u)$.
    \end{center}
    Both inequalities are shown and so the claim follows.
\end{proof}

\subsection{The Hausdorff Metric}
To prove the continuity of the volume functional and of the support function with respect to convex bodies, we need a metric on the set of convex bodies. This metric will be introduced in the following subsection.

\begin{definition}
    For $K,L\in K^{n}$, define Hausdorff distance or Hausedorff metric by
    \begin{center}
        $\delta(K,L):=\min\{\lambda\geq;K\subseteq L+\lambda B^{n},L\subseteq K+\lambda B^{n}\}$,
    \end{center}
\end{definition}

\begin{remark}
    The Hausdorff distance (Hausdorff metric) on the set of convex bodies. This follows directly from the properties of minima and from the convexity of $K$.
\end{remark}

\begin{lemma}
    Let $K,L\in\mathscr{K}^{n}$, $K,L\subseteq RB^{n}$, where $R>0$, and $u,v\in\mathbb{R}^{n}$. Then
    \begin{center}
        $|h(K,u)-h(L,v)|\leq R|u-v|+\max\{|u|,|v|\}\delta(K,L)$.
    \end{center}
\end{lemma}
\begin{proof}
    Proof can be found in~\citep{schneider2014convex} (section 1.8, Lemma 1.8.12).
\end{proof}

\begin{remark}
    Lemma above proves the local Lipschitz continuity of the support function in both arguments.
\end{remark}

\begin{theorem}
    Let $K,L\in\mathscr{K}^{n}$, then
    \begin{center}
        $\delta(K,L)=\underset{u\in\mathbb{S}^{n-1}}{\sup}|h(K,u)-h(L,u)|=:||\bar{h}_{K}-\bar{h}_{L}||$,
    \end{center}
    where $\displaystyle \bar{h}_{K}=h_{k}|_{\mathbb{S}^{n-1}}$.
\end{theorem}
\begin{proof}
    Let $\delta(K,L)\leq\alpha$. This implies $K\subseteq L+\alpha B^{n}$. For $u\in\mathbb{S}^{n-1}$, it follows 
    \begin{center}
        $h(K,u)\leq h(L+\alpha B^{n},u)=h(L,u)+\alpha h(B^{n},u)=h(L,u)+\alpha$
    \end{center}
    After switching $K$ and $L$, we can conclude for $u\in\mathbb{S}^{n-1}$ that
    \begin{center}
        $|h(K,u)-h(L,u)|\leq\alpha$
    \end{center}
    This implies $||\bar{h}_{K}-\bar{h}_{L}||\leq\delta(K,L)$. Using a similar argument one can show the other estimation.
\end{proof}

\begin{lemma}
    Let $K_{1},K_{2}\in\mathscr{K}^{n}$ and $K_{2}\subseteq\mathring{K}_{1}$. Then there exists $\eta>0$ such that for all $K\in\mathscr{K}^{n}$ with $\delta(K,K_{1})<\eta$, $K_{2}\subseteq K$ holds.
\end{lemma}
\begin{proof}
    Can be found in~\citep{schneider2014convex} (Section 1.8, Lemma 1.8.18)
\end{proof}

%-------------------------------------------------------------------------------------

\chapter{Multiple Proofs Concerning the Isoperimetric Property}
This is possibly may be one of the oldest problem in differential geometry. With that it comes with multiple mathematicians trying to prove the problem and or simplify the problem. The first considered real and rigorous proof was by Jakob Steiner however it had an apparent flaw, later indicated by K. Weierstrass. That it only proved the existence. In fact the isoperimetric problem was only a corollary of a theory developed by Weierstrass to handle problems of maximizing or minimizing certain integrals, this theory is called calculus of variations. 

More direct proofs were discovered later. We will mainly look at J.Steiner's proof, E.Schmidt's proof, and Fourier analysis {\&} differential geometry approach to the proof but the other proofs in this section are mainly here to give additional insight on how to think about this problem. 

The seven proofs were done by Jakob Steiner, Karl Weierstrass, Erhard Schmidt, Vladimir Boltjanski, Richard Demar, Alfred D. Garvin, David Singmaster and D.J.Souppouris, and Gary Lawlor. This section is mostly following from Kimberly Holman as her Masters Thesis~\citep{holman2022isoperimetric}.
\begin{itemize}
    \item Vladimir Boltjanski's work provided a summary of Steiner's isoperimetric proof. Which starts off by showing that the maximum area of the shape must be convex. 
    \begin{enumerate}
        \item Towards a general shape. He makes a "cross-cut" that divides the boundary into two equal lengths. If every cross-cut has equal area then the shape is extremal. Otherwise, omit the side with smaller area and reflect the larger area across the cross-cut. We may continue in this way until every cross-cut. We may continue in this way until every cross-cut has equal area.
        \item Now  he takes a fixed cross-cut, $a$, $b$, and any boundary points distinct from $a$ and $b$, $c$, and demonstrates that the extremal must have $\angle acb=90^{\circ}$. If the angle is anything else, install a hinge and rotate about $c$ until the angle mesaure of $acb$ is $90^{\circ}$.
        \item The reflect over the cross-cut to achieve a shape with greater area and same perimeter.
    \end{enumerate}

    \item Richard Demar begins with an indirect proof to show that the extremal is convex, then proceeds with a trivial example that the square is not extremal. While the square example is trivial and can easily be proved computationally, the trick Demar uses here will be used in subsequent proofs. is that we start with a square, then we would cut a piece off, then glue it to another place, and hence our shape is nonconvex. An illustration is shown below.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=120mm]{RichardDemar}
            \caption{Left shows square; Middle we replace; Right shows our shape is nonconvex}
        \end{center}
    \end{figure}

    \item Expanding on the work of Demar, Alfred D. Garvin, physical experiments are performed to prove the statements. First, liquid mercury is slowly poured into a confined triangular reservoir and is expected to take on an isoperimetrically optimal configuration, which it does. However, the meniscus effect of the mercury slightly skews the endpoints of the arcs. Next, the reservoir is partially filled with water. A viscous oil is poured slowly onto the water and is expected to take on an isoperimetrically optimal shape, which it does. Again, the meniscus effect of the oil slightly skews the endpoits of the arcs. The third experiment uses a flexible, asymmetrical triangular wood fence and a sturdypaper closed fence with perimeter less than that of the triangle. BB pellets are poured inside the paper fence, which is expected to take on an isoperimetrically optimal shape, which it does. This internal-pressure experiment does not yield any skewed results. The three experiments yield the same description of the isoperimetrically optimal shape: the arcs have equal radii, the arcs have equal chords, and the arcs have equal length.

    \item David Singmaster and D.J. Souppouris looked at the ratio of area to perimeter, A/P. Where it is examined to find the set which produces the greatest number. Using advanced calculus and analysis, the maximal ratio of A/P is a measure of the circularity of the set.

    \item Gary Lawlor presented a new proof of the planar isoperimetric property. His method is of slicing and covering argument, and calls for strategically dividing the circle as well as another, arbitrary region of equal perimeter, into tiny pieces. Each pieces from non-circle region contains the same length of the region’s boundary and has less area than the piece of the circle containing the same length of the circle’s boundary. An advantage of this proof is, as it is comparative, it does not require a proof of existence of an optimum solution.
\end{itemize}

\chapter{2-Dimensional Case ($\mathbb{R}^2$)}
\section{Jakob Steiner}
Firstly, we will look at this proposition. Isosceles triangle has the smallest leg-sum compared to trianges of the same baselien and either height or area, and vice-versa. 

\begin{enumerate}
    \item Given an uneqal triangle, we want to maximise area on a triangle with the same baseline. 

    \item We make the other two sides, not the baseline, equal. The result is a triangle witha smaller leg-sum, and therefor a smaller perimeter, containigng the same area.

    \item Now we can expand on the previous principle to demonstrate that any parallel trapezoid with unequal angles on one baseline may be transformed into another of the same area and baselines; Moreover, the new parallel trapezoid will have symmetry along the axis formed by the baseline midpoints and a smaller sum of side lengths. 
\end{enumerate}

We will show this proof in the next section (section 2.2).
\newline
\newline

\begin{lemma} 
    Among all triangles ABC with same perimeter and same base AB, which has bigger area?
\end{lemma}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=88mm]{lemma3}
        \caption{labeled figure to lemma 3, helps with the proof}
    \end{center}
\end{figure}\leavevmode
Let us note that the third vertex $\mathrm{C}$, is located on the ellipse
\begin{proof} 
    Let $|\mathrm{BC}|=a$, $|\mathrm{AC}|=b$, $|\mathrm{AB}|=c$ be the side of $\triangle ABC$, and let $|\mathrm{OP}|=u$ and $|\mathrm{OQ}|=v$ be the semi-major and semi-minor axis of the ellipse, respectively.

    Since the ellipse is symmetric, we can consider only the I quadrant of the ellipse (non-shaded area of Figure 2.1).

    Following the cosine rule $a^{2}=b^{2}+b^{2}-2bc\cos{\alpha}$,
    \begin{center}
        $\displaystyle a^{2}=b^{2}+c^{2}-2bc\cos{\alpha}$,

        $\displaystyle b^{2}=a^{2}+b^{2}-2ac\cos{\beta}$,

        $\displaystyle 2(b^{2}-a^{2})=2bc\cos{\alpha}-2ac\cos{\beta}$,

        $\displaystyle b-a=\frac{c}{a+b}(b\cos{\alpha}-a\cos{\beta})$

        $\displaystyle =\frac{c}{a+b}(|\mathrm{AH}|-|\mathrm{BH}|)$

        $\displaystyle =\frac{2c}{a+b}|\mathrm{OH}|$

        $\displaystyle =\frac{2c}{a+b}x$

        Since $\displaystyle \frac{2c}{a+b}=const$, $\displaystyle \;b-a\sim x$.
    \end{center}
    Expression for the point $\mathrm{C}=(x,y)$ on the ellipic arc $\mathrm{PQ}$ (red arc on figure 2.1) in terms of parameter $\theta\in(0,\frac{\pi}{2})$ gives
    \begin{center}
        $x(\theta)=u\cos{\theta}$,

        $y(\theta)=v\sin{\theta}$,

        $x'(\theta)=-u\sin{\theta}<0\;\;\;\;\;\forall\theta\in(0,\frac{\pi}{2})$,

        $y'(\theta)=v\cos{\theta}>0\;\;\;\;\;\forall\theta\in(0,\frac{\pi}{2})$,
    \end{center}
    so, smaller $x$ is equivalent to biggy and the smaller side difference, the bigger the area.
\end{proof}

\begin{lemma}
    For a given perimeter the equilateral triangle has the biggest area of all the triangles. 
\end{lemma}
\begin{proof} 
    Using Heron's formula for the are ofa triangle to help here
    \begin{center}
        $\displaystyle \mathrm{Area}=\mathrm{A}=\sqrt{s(s-a)(s-b)(s-c)}$
    \end{center}
    where is is the semi-perimeter
    \begin{center}
        $\displaystyle s=\frac{a+b+c}{2}$
    \end{center}
    To find the conditions for the macimum area we want to comput derivatives with respect to $a$, $b$ and $c$, but since they are not independent variables, we first substitue the semi-perimeter equation in to he area equation, to remove $c$
    \begin{center}
        $\displaystyle c=2s-a-b$

        $\displaystyle \therefore\mathrm{A}=\sqrt{s(s-a)(s-b)(a+b-s)}$
    \end{center}
    Setting the derivative with respect to $a$ to $0$:
    \begin{center}
        $\displaystyle \frac{d\mathrm{A}}{da}=\frac{s(s-b)(2s-2a-b)}{2\mathrm{A}}=0$

        $\displaystyle \implies 2s-2a-b=0$
    \end{center}
    Similarly, setting the derivative with respect to $b$ to $0$ yields
    \begin{center}
        $2s-2b-a=0$
    \end{center}
    Solving simultaneously gives
    \begin{center}
        $\displaystyle a=b=\frac{2s}{3}$
    \end{center}
    by substituting $\displaystyle c=\frac{2s}{3}$ back, we get
    \begin{center}
        $\displaystyle a=b=c$ and the triangle is equilateral.
    \end{center}
\end{proof}

\begin{proposition}
    Among all regular polygons with fixed perimeter, an increase in the number of sides results in a larger area.  
\end{proposition}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=140mm]{isofig11}
        \caption{representating increasing number of sides gives larger area (i)triangle, (ii)square, (iii)pentagon, (iv)carries on}
    \end{center}
\end{figure}\leavevmode
\begin{remark}
    We will need to use Heron's formula \textbf{and} the AM-GM inequality for the proof of proposition 2.1.3.
\end{remark}
\begin{proof} 
    Suppose that $n$ is the number of sides of a regular polygon.

    \textbf{Triangle Case, $n=3$:} We start with Heron's formula
    \begin{center}
        $\displaystyle \mathrm{Area}=\mathrm{A}=\sqrt{s(s-a)(s-b)(s-c)}$ where $\displaystyle s=\frac{\mathrm{L}}{2}$ is a constant
    \end{center}
    Applying the AM-GM Inequality
    \begin{center}
        $\displaystyle (\sqrt[3]{(s-a)(s-b)(s-c)})^{3}\leq\Big(\frac{s-a+s-b+s-c}{3}\Big)^{3}$

        $\displaystyle =\Big(\frac{s}{3}\Big)=\Big(\frac{\mathrm{L}}{6}\Big)^{3}$
    \end{center}
    so for the area we have
    \begin{center}
        $\displaystyle \mathrm{Area}=\sqrt{s}\sqrt{(s-a)(s-b)(s-c)}\leq\sqrt{\frac{\mathrm{L}^{3}}{6^3}}\times\sqrt{\frac{\mathrm{L}}{3}}$

        $\displaystyle =\sqrt{\frac{\mathrm{L}^{4}}{2\times2^{3}\times3^{3}}}=\frac{\mathrm{L}^{2}}{4\times3\sqrt{3}}=\frac{\mathrm{L}^{2}}{12\sqrt{3}}$
    \end{center}
    hence we get $\displaystyle s-a=s-b=s-c\;\therefore$ regular triangle

    \textbf{Square Case, $n=4$:} If we lable Figure 2.2 (ii) sides with $a$ and $b$ adjacently. The area is
    \begin{center}
        $\displaystyle \mathrm{Area}=ab$ where $\displaystyle a+b=\frac{\mathrm{L}}{2}$
    \end{center}
    Applying the AM-GM Inequality again
    \begin{center}
        $\displaystyle \sqrt{ab}\leq\frac{a+b}{2}=\frac{L}{4}$
    \end{center}
    hence
    \begin{center}
        $\displaystyle \mathrm{Area}=ab\leq\Big(\frac{a+b}{2}\Big)^{2}=\frac{\mathrm{L}^{2}}{16}$
    \end{center}

    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=75mm]{isofig12}
            \caption{a labeled hexagon in a circle, showing that a circle }
        \end{center}
    \end{figure}\leavevmode
    
    Lets now move on to the main part, \textbf{$n$-gon Case:} Suppose that the angle $\displaystyle \theta=\frac{2\pi}{n}$, the length $a=\frac{\mathrm{L}}{n}$, and 
    \begin{center}
        $\displaystyle \frac{(a/2)}{h}=\tan{(\theta/2)}$

        $\displaystyle \frac{(a)}{h}=2\tan{(\theta/2)}$

        $\displaystyle h=\frac{a}{2\tan{(\pi/n)}}$
    \end{center}
    So the area is
    \begin{center}
        $\displaystyle \mathrm{Area}=\mathrm{A}=n\cdot\text{area of }\triangle\mathrm{OAB}=n\cdot\frac{a}{2}\cdot h$

        $\displaystyle n\cdot\frac{a^{2}}{4\tan{\pi/n}}=n\frac{\cdot\mathrm{L}^{2}}{4n^{2}\tan{\pi/n}}$

        $\displaystyle =\frac{\mathrm{L^{2}}}{4n\tan{(\pi/n)}}$
    \end{center}
\end{proof}

\begin{note}
    we can see that $\displaystyle \frac{\mathrm{L}^{2}}{12\sqrt{3}}<\frac{\mathrm{L}^{2}}{16}$, as dividing by $12\sqrt{3}$ gives a smaller result than dividing by $16$. Hence the square is a better choice. And that $\displaystyle 4n\tan{(\pi/n)>{16}}$.
\end{note}
\begin{problem}
    So what happens when $n$ increases to infinity (i.e. $n\to\infty$)?

    \begin{center}
        $\displaystyle \underset{n\to\infty}{\lim}\frac{\mathrm{L}^{2}}{4n\tan{(n/\pi)}}$

        $\displaystyle =\underset{n\to\infty}{\lim}\frac{\mathrm{L}^{2}\cos{(\pi/n)}}{4\pi\frac{n}{\pi}\sin{(\pi/n)}}$

        $\displaystyle =\underset{n\to\infty}{\lim}\frac{\mathrm{L}^{2}\cos{(\pi/n)}}{4\pi\frac{\sin{(\pi/n)}}{\pi/n}}$
    \end{center}
    as $\displaystyle \frac{\sin{(\pi/n)}}{\pi/n}=1$, and $\cos{\pi/n}=1$
    \begin{center}
        $\displaystyle \underset{n\to\infty}{\lim}\frac{\mathrm{L}^{2}}{4n\tan{(n/\pi)}}=\frac{\mathrm{L}^{2}\cdot1}{4\pi\cdot1}$,

        $\displaystyle =\frac{\mathrm{L}^{2}}{4\pi}$,
    \end{center}
    which gives us the area of the circle.
\end{problem}

\begin{theorem}
    If L is the perimeter and A is the area of any regular 2n-sided polygon, then 
    \begin{center}
        $L^{2}\geq8n*A*\tan{(\frac{\pi}{2n})}$
    \end{center}
\end{theorem}

\begin{figure} [h]
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{isofig8.png} % first figure itself
        \caption{Figure V}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{isofig9.png} % second figure itself
        \caption{figure VI}
    \end{minipage}
\end{figure}

\begin{proof}
        Since its a regular polygon we could consider one of the 2n triangles its made off as shown in the figure above. 
    \begin{center}
        $\displaystyle \tan(\alpha)=\frac{(\frac{L}{4n})}{h}$
    \end{center}
        Rearranging the formula to make h the subject as well as using the fact that $\alpha=\frac{2\pi}{2n} \frac{1}{2}=\frac{\pi}{2n}$, we get 
    \begin{center}
        $\displaystyle h=\frac{L}{4n} \frac{1}{\tan(\frac{\pi}{2n})}$
    \end{center}
    Now for the area of the above triangle we get $\displaystyle \frac{1}{2}h*\frac{L}{2n}$
        Substituting h, we obtain
    \begin{center}
        $\displaystyle \frac{L^{2}}{16n^{2}} \frac{1}{\tan(\frac{\pi}{2n})}$
    \end{center}
        Finally, we consider the area of the whole polygon which is just 2n times of the above expression. So we have 
    \begin{center}
            $\displaystyle A=\frac{L^{2}}{8n} \frac{1}{\tan(\frac{\pi}{2n})}$
    \end{center}
        Since this is the optimal area we can be more precise and by rearranging the express we can conclude our desired expression which was $L^{2} \ge 8nA\tan(\frac{\pi}{2n})$
\end{proof}

\begin{theorem}
    Let $C$ be a simple closed curve in the plane with length $L$ and bounding a region of area $A$ . 
    Then $L^2 \leq 4\pi A$ with equality if and only if $C$ is a circle.
\end{theorem}
The circle therefore bounds the biggest area among all simple closed curves in the plane with a given length.
\subsection{J.Steiner's Proof}
The proof that I will be unpacking and taking a closer look at will be from the book (reference the book here), and is credited by them to Jakob Sternier. Packed and concise proof from~\citep{gluck2012isoperimetric}. To reiterate, the German mathematician Peter Dirichlet (1805- 1859), remarked, Steiner had made an underlying assumption not explicitly addressed in his proof, namely that a solution existed (Nahin 59~\citep{nahin2021least}). A rather helpful computer visualisation, before we start the proof, to aid in the identification that indeed the circle is an answer, and how naturally a compressed circle (ellipse) has less area than a full and complete circle.
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=150mm]{steinerproofvisualisation}
        \caption{Digitally showing area comparison of curves.}
    \end{center}
\end{figure}
\begin{proof} 
    We will begin the proof by assuming the existence of a solution. In other words, that there exists a simple closed curve $\mathrm{C}$ of a specified length L, enclosing a region with the maximum possible area.
    \textbf{Step 1:} We claim that the curve $\mathrm{C}$ must be convex, in the sense that any line segment joining two points of $\mathrm{C}$ must lie entirely in the closure of the region bouded by $\mathrm{C}$.

    We see this as follows. If $\mathrm{C}$ were not convex, then we could draw a segment $\mathrm{OP}$ between two points of $\mathrm{C}$ which lies entirely (except for its endpoints) outside of $\mathrm{C}$.

    Reflecting the appropriate arc of $\mathrm{C}$ between $\mathrm{O}$ and $\mathrm{P}$ in this line would produce another curve of the same length but bouding a larger area, as in the figure below.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=80mm]{steiner1}
            \caption{a labeled hexagon in a circle, showing that a circle }
        \end{center}
    \end{figure}\leavevmode
    Hence $\mathrm{C}$ must already be convex

    \textbf{Step 2:} Now choose  two points, $\mathrm{A}$ and $\mathrm{B}$, dividing our solution curve $\mathrm{C}$ into arcs of equal length.

    Then the line segment $\mathrm{AB}$ must also divide the region bounded by $\mathrm{C}$ into two parts of equal area. Otherwise, the part of greater area could be reflected in $\mathrm{AB}$ to give another curve of the same length $\mathrm{L}$ bounding a region of area greater than that bounded by $\mathrm{C}$.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=80mm]{steiner2}
            \caption{a labeled hexagon in a circle, showing that a circle }
        \end{center}
    \end{figure}\leavevmode
    It follows that half of our solution curve $\mathrm{C}$ must solve the following problem: To find the arc of length $\mathrm{L}/2$ with endpoints $\mathrm{A}$ and $\mathrm{B}$ lying anywhere on a straight line, such taht the arc together with the segment $\mathrm{AB}$ encloses a region of maximum area.

    \textbf{Step 3:} Now we'll show that the solution to this new problem is a semi-circle, so tghat the solution to the orignal problem must be a full circle, so that the solution to the original problem must be a full circle.

    Suppose the arc $\mathrm{AOB}$ shown at the left below solves this new problem It is sufficient to show that every inscribed angle, such as the one at $\mathrm{O}$, is a right angle, for this will prove that our arc is a semi-circle.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=130mm]{steiner3}
            \caption{a labeled hexagon in a circle, showing that a circle }
        \end{center}
    \end{figure}\leavevmode
    Suppose, to the contrary, that the angle at $\mathrm{O}$ is not $90^{\circ}$. Then we can view the arc as hinged at $\mathrm{O}$, and either open it or close it so as to make the angle at $\mathrm{O}$ exactly $90^{\circ}$

    This will not change the length of the arc, nor change the two shaded areas, but will increase the triangular area, and therefore increase the total area enclosed by the arc $\mathrm{AOB}$ and the line segment $\mathrm{AB}$.

    But this was already maximized by the original arc, so its inscribed angle at $\mathrm{O}$ is $90^{\circ}$ and the arc itself a semi-circle.

    \textbf{Step 4:} Let $\mathrm{C}$ be a smooth, regular simple closed curve in the plane, with $\mathrm{L}$ and bounding a region of area $\mathrm{A}$.

    For each $\epsilon>0$, we can inscribe in $\mathrm{C}$ a polygon $\mathrm{P}_{\epsilon}$ whose length $\mathrm{L}_{\epsilon}$ satisfies $|\mathrm{L}_{\epsilon}-\mathrm{L}|<\epsilon$ and whose area $\mathrm{A}_{\epsilon}$ satisfies $|\mathrm{A}_{\epsilon}-\mathrm{A}|<\epsilon$.

    For the polygon $\mathrm{P}_{\epsilon}$ we already have the isoperimetric inequality $\mathrm{L}_{\epsilon}^{2}\geq4\pi\mathrm{A}_{\epsilon}$.

    Now let $\epsilon\to0$ and we get the isoperimetric inequality for the given curve $\mathrm{C}$, $\mathrm{L}^{2}\geq4\pi\mathrm{A}$.

    Since the cirlce of the same length $\mathrm{L}$ bounds a region of area $\mathrm{A}_{0}$ satisfying $\mathrm{L}^{2}=4\pi\mathrm{A}_{0}$, we know that $\mathrm{A}\leq\mathrm{A}_{0}$.

    Thus we know that a circle maximizes the enclosed area among all smooth regular simple closed curves of the same length. So the maximizers exists.

    Then by parts (1)-(3) of this proof, there are no other maximizers, completing the proof of the isoperimetric theorem.
\end{proof}

\section{Karl Weierstrass}
Relying on calculus of variation, this proof defines area and length in terms of integrals. However Karl Weierstrass's calculus of variation is very strong, and that the isoperimetric problem pops out of it. Calculus of variations is concerned with the problem of extremising "functionals", finding extrema of functions of \textit{infinite} variables. Functionals can be looked at like "functions of functions". The result is two Euler-Lagrange equations which when solved, provide an equation in the form of a circle and the length of the radius which optimizes the area given the length of the perimeter. The lagrangian, denoted by $L(x,y,y')$ normally opted as $L=T-V$, the kinetic energy minus the potential energy. Extremal curves represent solutions to the isoperimetric problem, providing the shapes that maximize the enclosed area under a fixed perimeter. Extremal curves are smooth and regular, ensuring the validity of the Euler-Lagrange equation and the associated boundary conditions. We shall not give proofs to these theorem and lemmas.
\begin{theorem}
	Consider the functional $\mathrm{J}(Y)$, an extremum, defined as follows:
	\begin{center}
		$\displaystyle \mathrm{J}[y]=\int_{a}^{b}L(x,y,y')\,dx$
	\end{center}
	where $L(x,y,y')$ is the lagrangian and $y'$ denotes the derivative of $y$ with respect to $x$. The critical points of $J[y]$ satisfy the Euler-Lagrange equation:
	\begin{center}
		$\displaystyle \frac{\partial}{\partial x}\Big(\frac{\partial L}{\partial y'}\Big)-\frac{\partial L}{\partial y}=0$
	\end{center}
\end{theorem}
\begin{proof}
    Consider functions $\mathrm{Y}_{\epsilon}(x)$ of the form $\mathrm{Y}_{\epsilon}(x)=\mathrm{Y}(x)+\epsilon\eta(x)$

    where $\epsilon\in\mathbb{R}$, a smooth curve $\eta(x)\in \mathrm{C}^{2}[a,b]$ satisfies $\eta(a)=\eta(b)=0$ so that $\mathrm{Y}_{\epsilon}(a)=\mathrm{A}$ and $\mathrm{Y}_{\epsilon}(b)=\mathrm{B}$ i.e. $\mathrm{Y}_{\epsilon}$ still satisfies the boundary conditions.

    so $\mathrm{Y}_{\epsilon}$ is a function which satisfies our boundary conditions and which is ``near to'' $\mathrm{Y}$ when $\epsilon$ is small. $\mathrm{I}(\mathrm{Y}_{\epsilon})$ depends on the value of $\epsilon$ and we write $\mathrm{I}[\epsilon]$ for the value of $\mathrm{I}(\epsilon)$:
    \begin{center}
        $\displaystyle \mathrm{I}[\epsilon]=\int_{a}^{b}\mathrm{F}(x,\mathrm{Y}_{\epsilon},\mathrm{Y}_{\epsilon}')\,dx$
    \end{center}
    when $\epsilon=0$, the function $\mathrm{I}[\epsilon]$ has an extremum and so
    \begin{center}
        $\displaystyle \frac{d\mathrm{I}}{d\epsilon}=0$ when $\epsilon=0$ 
    \end{center}
    we can compute the derivative $\displaystyle \frac{d\mathrm{I}}{d\epsilon}$ by differentiating under the integral sign:
    \begin{center}
        $\displaystyle \frac{d\mathrm{I}}{d\epsilon}=\frac{d}{d\epsilon}\int_{a}^{b}\mathrm{F}(x,\mathrm{Y}_{\epsilon},\mathrm{Y}_{\epsilon}')\,dx=\int_{a}^{b}\frac{d\mathrm{F}}{d\epsilon}\mathrm{F}(x,\mathrm{Y}_{\epsilon},\mathrm{Y}_{\epsilon}')\,dx$
    \end{center}
    we now use the multivariable chain rule to differentiate $\mathrm{F}$ with respect to $\epsilon$. Well, in our case, the first argument $x$ is independant of $\epsilon$, so $\displaystyle \frac{dx}{d\epsilon}=0$, and since $\mathrm{Y}_{\epsilon}=\mathrm{Y}+\epsilon\eta$ we have $\displaystyle \frac{d\mathrm{Y}_{\epsilon}}{d\epsilon}=\eta$ and $\displaystyle \frac{d\mathrm{Y}_{\epsilon}'}{d\epsilon}=\eta'$. Therefore
    \begin{center}
        $\displaystyle \frac{d\mathrm{F}}{d\epsilon}(x,\mathrm{Y}_{\epsilon},\mathrm{Y}_{\epsilon}')=\int_{a}^{b}\Big(\frac{\partial\mathrm{L}}{\partial y}\frac{\partial y}{\partial \epsilon}+\frac{\partial\mathrm{L}}{\partial y'}\frac{\partial y'}{\partial \epsilon}\Big)\,dx=\frac{\partial\mathrm{F}}{\partial y}\eta(x)+\frac{\partial\mathrm{F}}{\partial y'}\eta(x')$.
    \end{center}
    but recall that $\displaystyle \frac{d\mathrm{I}}{d\epsilon}$ when $\epsilon=0$. Since $\mathrm{Y}_{0}=\mathrm{Y}$ and $\mathrm{Y}_{0}'=\mathrm{Y}'$.
    \begin{center}
        $\displaystyle 0=\int_{a}^{b}\frac{\partial\mathrm{F}}{\partial y}(x,\mathrm{Y},\mathrm{Y}')\eta(x)+\frac{\partial\mathrm{F}}{\partial y'}(x,\mathrm{Y},\mathrm{Y}')\eta'(x)\,dx$
    \end{center}
    integrating the second term above by parts, we get
    \begin{center}
        $\displaystyle \int_{a}^{b}\frac{\partial\mathrm{F}}{\partial y'}\eta'(x)\,dx=\Big[\frac{\partial\mathrm{F}}{\partial y'}\eta(x)\Big]_{a}^{b}-\int_{a}^{b}\frac{d}{dx}\Big(\frac{\partial\mathrm{F}}{\partial y'}\Big)\eta(x)\,dx$.
    \end{center}
    the first term on the right hand side vanishes because $\eta(a)=\eta(b)=0$ and by substituting the second term we get 
    \begin{center}
        $\displaystyle \int_{a}^{b}\Big(\frac{\partial\mathrm{F}}{\partial y}-\frac{d}{dx}\frac{\partial\mathrm{F}}{\partial y'}\Big)\eta(x)\,dx=0$
    \end{center}
    the equation above holds for any $\eta(x)\in\mathrm{C}^2[a,b]$ satisfying $\eta(a)=\eta(b)=0$, so the fundamental lemma of calculus of variations tells us that $\mathrm{Y}(x)$ satisfies
    \begin{center}
        $\displaystyle \frac{\partial}{\partial x}\Big(\frac{\partial \mathrm{L}}{\partial y'}\Big)-\frac{\partial \mathrm{L}}{\partial y}=0$
    \end{center}
\end{proof}
\begin{remark}
	$Y$ satisfying the Euler-Lagrange equation is a necessary, but not sufficient, condition for $J(Y)$ to be an extremum. In other words, a function $Y(x)$ may satisfy the Euler-Lagrange equation even when $J(Y)$ is not an extremum.
\end{remark}
\subsubsection{Isoperimetric with Lagrangian}
For the isoperimetric problem, the Lagrangian $L(x, y, y')$ becomes the integrand of the perimeter functional, which is the square root of $1 + (y')^2$.
\begin{center}
	$L(x, y, y') = \sqrt{1 + (y')^2}$
\end{center}
Applying the Euler-Lagrange equation to this Lagrangian, we get:
\begin{center}
	$\frac{d}{dx} \left( \frac{y'}{\sqrt{1 + (y')^2}} \right) - \frac{y}{\sqrt{1 + (y')^2}} = 0$
\end{center}
\begin{lemma}(\textbf{Existence of Extremal Curves})
        There exists at least one extremal curve that satisfies the Euler-Lagrange equation and corresponds to a critical point of the functional \( J[y] \).
    \end{lemma}

    \begin{lemma}(\textbf{Uniqueness of Extremal Curves})
        Under certain regularity conditions, there exists a unique extremal curve that satisfies the Euler-Lagrange equation and optimizes the area under a fixed perimeter.

        Solving the differential equation subject to the fixed endpoints~\citep{goldstein1980classical} and~\citep{hilbert1985methods}, along with the fixed area constraint, leads us to the discovery of extremal curves that not only minimize the perimeter but also provide profound insights into the Isoperimetric Inequality in two-dimensional spaces.
    \end{lemma}
Direct proofs from Weierstrass' corollary can be found in $Curves$ $and$ $Surfaces$ $in$ $Euclidean$ $Spaces$~\citep{chern1966curves}.

\section{Erhard Schmidt}
E.Schmidt simplified the work of Weierstrass to whom provided a complete proof of the Isoperimetric problem, however this proof seemed difficult to digest thus later mathematicians came in to assist, decades later. Beginning with parameterised curves, a circle is defined using carefully selected intervals and bounding. Using advanced calculus, isoperimetric equality is obtained if all calculated isoperimetric inequality statements are equalities. But here we will start off with the initial formula that we will see down below and how this initial formula will be used.

\textbf{Initial Formula}
Area, A, bounded by a positively oriented simple closed curve where: 
\begin{center}
	$\alpha(t)=(x(t),y(t)), t\in [a,b]$
\end{center}
\begin{center}
	$A=-\int_{a}^{b}y(t)x'(t)\,dt=\int_{a}^{b}x(t)y'(t)\,dt = 1/2\int_{a}^{b}(xy'-yx')\,dt$
\end{center}

\begin{definition}
    Let $\mathrm{C}$ be a simple closed curve then $\mathrm{C}$ is called positively oriented if the traversal of the curve is counter clockwise.

    The curve is called negatively oriented if the traversal of the curve is clockwise. 
\end{definition}

\begin{remark}
    The Green's theorem uses the definition of positively oriented curves.
\end{remark}

\subsection{E.Schmidt's Proof}
This proof will need:
\begin{enumerate}
	\item AM-GM Inequality 
	\item Cauchy-Schwarz Inequality
	\item $A=\int_{0}^{l} xy' \,dx = -\int_{0}^{l} yx' \,ds$ so $c(s)=(x(s),y(s))$
\end{enumerate}
\textbf{Green's Theorem} $f(x,y)=(u(x,y),v(x,y))$, $\int_{\delta R}\overrightarrow{f} d\overrightarrow{r}$

\begin{proof}
	Let's begin the proof by trying to compute $\iint_{1} 1 \,du\,dv$

	(some figure)

	One condition we know is $\frac{\delta v}{\delta x}-\frac{\delta u}{\delta y}=1$
	
	So we have two solutions:
	\begin{enumerate}
		\item $f(0,x)$
		\item $g(-y,0)$
	\end{enumerate}
	
	taking the line integral of $f(0,x)$ and $g(-y,0)$
	\begin{enumerate}
		\item
			$\int_{C} \overrightarrow{f} \,dr$ \;\;\;where\; $C=(x(t),y(t))$
				
			$= \int_{0}^{l} \overrightarrow{f}(c(t))c'(t) \,dt$ \;\;\;by definition of line integral

			$= \int_{0}^{l} (0,x(t))(x',y') \,dt$
			
			$= \int_{0}^{l} xy' \,dt$ \;\;\;by Green's theorem
		\item
			$\int_{0}^{l} (-y,0)(x',y') \,dt$
			
			$= \int_{0}^{l} x'y \,dt$ \;\;\;by Green's theorem
	\end{enumerate}
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=100mm]{esfigure}
            \caption{asdf}
        \end{center}
    \end{figure}\leavevmode
    $\mathrm{C}(s)=(x(s),y(s))\;s\in[0,l]$
\end{proof}

When does the inequality hold?
\begin{enumerate}
    \item Does the AM-GM inequality hold? when both are the same.
    \begin{center}
        $\sqrt{aa}=\frac{a+a}{2}$

        $\mathrm{A}=\pi r^{2}=\frac{l^{2}}{4\pi}$
    \end{center}

    So, as we rotate $\mathrm{C}$, the radius has to be fixed.

    \item Does the Cauchy-Schwarz inequality hold?
\end{enumerate}

\section{Proof Using Fourier Analysis {\&} Differential Geometry}
In this proof of the Isoperimetric Inequality in two dimensions, we will look at domains
with continuously differentiable boundary. We will identify the Euclidean plane with $\mathrm{C}$
and we will consider the boundary as a periodic function from $\mathrm{R}$ to $\mathrm{C}$, so that we are able
to use Fourier analysis. 

\chapter{n-Dimensional Case ($\mathbb{R}^n$)}
The idea of the proof for this theorem is to show the inequality above using induction on $n$. Here, we will use the Integral Theorem of Fubini to establish induction step. In this chapter, some statements of the theory of convex, compact sets will be introduced as well as properties of the volume functional. Later, we will show the Isoperimetric Inequality using the theorem of Brunn–Minkowski. We will follow~\citep{schneider2014convex}.

\section{Volume and Surface Measure}
In this subsection, we will introduce the volume functional and show its continuity. The results of this subsection are important in the proof of Brunn-Minkowski.

\begin{definition}
    Let $M\subseteq\mathbb{R}^{n}, p\geq0$. For $\delta>0$ define
    \begin{center}
        $\displaystyle \mathscr{H}_{\delta}^{P}(M):=\inf\{\sum\limits_{i=1}^{\infty}\alpha(p)(\frac{diam C_{i}}{2})^{p};(C_{i})_{i\in\mathbb{N}}$ open sets in $\mathbb{R}^n$

        \hspace{1cm}with $diam C_{i}\leq\delta$ and $M\subseteq\underset{i\in\mathbb{N}}{\cup}{C_{i}}\}$
    \end{center}
    with $\alpha(p)=\frac{\pi^{\frac{p}{2}}}{\Gamma(p)(\frac{p}{2}+1)}$ for $p\neq0$, where $\Gamma(p):=\int_{0}^{\infty}t^{-1}e^{-t}\,dt$ and $\alpha(0)=0$.
    
    Define the p-dimensional Hausdorff measure of $M$ by
    \begin{center}
        $\mathscr{H}^{p}(M):=\underset{\delta>0}{\sup}\mathscr{H}_{\delta}^{p}(M)=\underset{\delta\to0}{\lim}\mathscr{H}_{\delta}^{p}(M)$.
    \end{center}
\end{definition}

\begin{remark}
    Let $t\in\mathbb{R}^{n}$ and $\lambda\in\mathbb{R}$, then we have
    \begin{center}
        $\mathscr{H}^{p}(\lambda M)=\lambda^{p}\mathscr{H}^{p}(M)$ and $\mathscr{H}^{p}(M=t)=\mathscr{H}^{p}(M)$.
    \end{center}
    Furthermroe, for $A\subseteq B$ we have $\mathscr{H}^{p}(A)\leq\mathscr{H}^{p}(B)$.
\end{remark}

\begin{definition}
    The volume funcational $V_{n}$ on $\mathscr{K}^{n}$ is defined by the restriction of the $n$-dimensional Hausdorff measure on $\mathscr{K}^{n}$.
\end{definition}

\begin{theorem}
    The volume functional $V_{n}:\mathscr{K}^{n}\to\mathbb{R}$ is continuous.
\end{theorem}
\begin{proof}
    \textbf{Case 1 $\mathrm{V}_{n}(\mathrm{K})=0$:}
    Let $\overline{a}\in\mathscr{K}^{n}$ and, without loss of generality, assume $\delta(K,\overline{K})=\alpha\leq1$. Thus, it holds that $\overline{K}\subseteq K+\alpha B^{n}$. Since $V_{0}(K)=0$ and $K$ is convex, we know that $K$ has to be contained in a hyperplane. From the monotony of the Hausdorff measure it follows for $u$ orthogonal on the hyperplane, that
    \begin{center}
        $V_{n}(\mathrm{K})\leq \mathrm{V}_{n}(K+\alpha \mathrm{B}_{n})$

        $=\int_{-\alpha}^{\alpha}\mathrm{V}_{n-1}([\mathrm{K}+\alpha \mathrm{B}^{n}]\cap\mathrm{H}_{u,\zeta})\,d\zeta$

        $\leq\int_{-\alpha}^{\alpha}\mathrm{V}_{n-1}(K+(\alpha\mathrm{B}^{n}\cap\mathrm{H}_{u,\zeta}))\,d\zeta$

        $=2\alpha \mathrm{V}_{n-1}(K+(\alpha\mathrm{B}^{n}\cap\mathrm{H}_{u,0}))$

        $\overset{\alpha\leq1}{\leq}\underbrace{2\mathrm{~V}_{n-1}\left(\mathrm{~K}+\left(\mathrm{B}^n\cap \mathrm{H}_{u, 0}\right)\right)}_{:=c(\mathrm{~K})}\cdot\alpha$,
    \end{center}
    In the second line we used that $K+\alpha B^{n}$ varies in the fixed coordinate of $K$ by $2\alpha$. Since $c(K)$ is fixed and does not depend on $\alpha$ the continuity follows.

    \textbf{Case 2 $\mathrm{V}_{n}(\mathrm{K})>0$:}
    Without loss of generality, assume that $0\in\overset{\circ}{\mathrm{K}}$ (if not, we can shift it, since the Hausdorff measure is invariant under shifts). Let $\epsilon>0$ and choose $\lambda>1$ such that
    \begin{center}
        $(\lambda^{n}-1)\lambda^{n}\mathrm{V}_{n}(\mathrm{K})<\epsilon$
    \end{center}
    and $\rho>0$ so that $\rho\mathrm{B}^{n}\subseteq\overset{\circ}{\mathrm{K}}$. From Lemma 13, we 
    know that there is an $\alpha>0$ with $\alpha\leq(\lambda-1)\rho$ so that $\rho\mathrm{B}_{n}\subseteq\overset{\circ}{\mathrm{K}}\subseteq\overline{\mathrm{K}}$. For all $\mathrm{K}$ with $\delta(K,\overline{\mathrm{K}})<\alpha$. From $\delta(\mathrm{K},\overline{\mathrm{K}})<\alpha$ it follows
    \begin{center}
        $\mathrm{K}\subseteq\overline{\mathrm{K}}+\alpha\mathrm{B}^{n}\subseteq\overline{\mathrm{K}}+(\lambda-1)\rho\mathrm{B}^{n}\subseteq\overline{\mathrm{K}}+(\lambda-1)\overline{\mathrm{K}}=\lambda\overline{\mathrm{K}}$
    \end{center}
    With the same argument, we can also show that $\overline{\mathrm{K}}\subseteq\lambda\mathrm{K}$. Hence we have the inequalities $\mathrm{V}_{n}(\mathrm{K})\leq\mathrm{V}_{n}(\lambda\mathrm{K})=\lambda^{n}\mathrm{V}_{n}(\overline{\mathrm{K}})$ and $\mathrm{V}(\overline{\mathrm{K}})\leq\mathrm{V}_{n}(\lambda\mathrm{K})=\lambda^{n}\mathrm{V}_{n}{\mathrm{K}}$. \newline
    This implies
    \begin{center}
        $\mathrm{V}_{n}(\mathrm{K})-\mathrm{V}_{n}(\overline{\mathrm{K}})\leq(\lambda^{n}-1)\mathrm{V}_{n}(\overline{\mathrm{K}})\leq(\lambda^{n}-1)\lambda^{n}\mathrm{V}_{n}(\mathrm{K})$ and

        $\mathrm{V}_{n}(\overline{\mathrm{K}})-\mathrm{V}_{n}(\mathrm{K})\leq(\lambda^{n}-1)\mathrm{V}_{n}(\mathrm{K})\overset{\lambda>1}{\leq}(\lambda^{n}-1)\lambda^{n}\mathrm{V}_{n}(\mathrm{K})$.
    \end{center}
    As a consequence we have the estimate
    \begin{center}
        $|\mathrm{V}_{n}(\mathrm{K})-\mathrm{V}_{n}(\overline{\mathrm{K}})|\leq(\lambda^{n}-1)\lambda^{n}\mathrm{V}_{n}(\mathrm{K})<\epsilon$.
    \end{center}
    This implies the continuity of $\mathrm{V}_{n}$.
\end{proof}

\begin{theorem}(Steiner's Formula)
    There are $\mathrm{V}_{m}:\mathscr{K}^{n}\to\mathbb{R}$ and cofficients $k_i\in\mathbb{R}$ for $i=0,1,\dots,n$ such that 
    \begin{center}
        $\mathrm{V}_{n}(\mathrm{K}+\rho\mathrm{B}^{n})=\overset{n}{\underset{m=0}{\sum}}\rho^{n-m}k_{n-m}\mathrm{V}_{m}(\mathrm{K})$
    \end{center}
    for all $\mathrm{K}\in\mathscr{K}^{n}$, $\rho\geq0$.
\end{theorem}
A proof of this can be found in~\citep{schneider2014convex} (Theorem 4.2.1).

\begin{remark}
    Steiner’s formula implies that $\rho\mapsto\mathrm{V}_{n}(\mathrm{K}+\rho\mathrm{B}^{n})$ is a polynomial of degree $n$.
\end{remark}

\begin{definition} (Surface Measure)
    Let $\mathrm{K}\subseteq\mathscr{K}^{n}$. Then we define the \textit{surface measure} of $\mathrm{K}$ by
    \begin{center}
        $\mathrm{S}(\mathrm{K}):=\underset{\rho\to0}{\lim}\frac{\mathrm{V}_{n}(\mathrm{K}+\epsilon\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{\rho}$.
    \end{center}
\end{definition}

\begin{remark}
    This limit exists, because $\mathrm{V}_{n}(\mathrm{K}+\epsilon\mathrm{B}^{n})$ is a polynomial and, therefore, it is smooth.
\end{remark}

\begin{remark}
    Let $\mathrm{B}^{n}\subseteq\mathbb{R}^{n}$ be a ball. We then have
    \begin{center}
        $\mathrm{S}(r\mathrm{B}^{n})=nr^{n-1}\mathrm{V}_{n}(\mathrm{B}^{n})$
    \end{center}
\end{remark}
\begin{proof}
    Using the convexivity of $\mathrm{B}^{n}$ and the properties of the volume functional, we can compute
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{B}^{n})=\underset{\rho\downarrow0}{\lim}\frac{\mathrm{V}_{n}(\mathrm{K}+\epsilon\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{\rho}$

        $\displaystyle =\underset{\rho\downarrow0}{\lim}\frac{((r+\rho)^{n}-r^{n})\mathrm{V}_{n}(\mathrm{B}^{n})}{\epsilon}$

        $\displaystyle =\mathrm{V}_{n}(\mathrm{B}^{n})\underset{\rho\downarrow0}{\lim}\frac{(r+\rho)^{n}-r^{n}}{\epsilon}=\mathrm{V}_{n}(\mathrm{B})\cdot n\cdot r^{n-1}$.
    \end{center}
\end{proof}

\section{Brunn-Minkowski Theorem}
First we will show an important theorem of convex geometry, the Brunn-Minkowski Theorem, which we will use in the proof of the isoperimetric inequality in the next subsection. Osserman~\citep{osserman1978isoperimetric} wrote an extensive survey on the isoperimetric inequality. The traditional isoperimetric inequality for significant classes of subsets of $\mathbb{R}^{n}$ can be obtained quickly from the proof of the Brunn-Minkowski inequality, which takes only one page, and deserves to be better known.

The Minkowski Addition of two arbitrary sets $\mathrm{S},\mathrm{T}\subset\mathbb{R}^{n}$ is defined to be
\begin{center}
    $a\mathrm{S}\boxplus b\mathrm{T}:=\{x+y:x\in a\mathrm{S}$ and $y\in b\mathrm{T}\}$
\end{center}
where $a,b$ are nonnegative numbers and $a\mathrm{S}$ is the dilation by factor $a$
\begin{center}
    $a\mathrm{S}=\{ax:x\in\mathrm{S}\}$.
\end{center}
For example, the Minkowski sum of two rectanbles is still a rectangle.
\begin{center}
    $r([0,a]\times[0,b])\boxplus s([0,c]\times[0,d])=[0,ra+sc]\times[0,rb+sd]$.
\end{center} 
(image here of Minkowski sum)

According to the Brunn-Minkowski theorem, the area of the added figure is greater than the area of the summands because the Minkowski addition tends to "round out" the figures being added. So the theorem goes as:

\begin{theorem}(Brunn-Minkowski)
    Let $\mathrm{K}_{0},\mathrm{K}_{1}\in\mathscr{K}^{n}$ be two convex bodies and $\lambda\in[0,1]$, then
    \begin{center}
        $\displaystyle \mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}\geq (1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{\frac{1}{n}}+\lambda\mathrm{V}_{n}(\mathrm{K}_{0})^{\frac{1}{n}}$.
    \end{center}
    Equality holds for $\lambda\in(0, 1)$ if and only if $\mathrm{K}_{0}$ and $\mathrm{K}_{1}$ are contained in parallel hyperplanes or are homothetic.
\end{theorem}
\begin{proof}
    First, consider the case that $\mathrm{K}_{0},\mathrm{K}_{1}\in\mathscr{K}^{n}$ are two contrained in parallel hyperplanes.
    
    Let $\mathrm{K}_{0}\subset\mathrm{E}$ and $\mathrm{K}_{1}\subset\mathrm{F}$ with E and F huperplanes. Without loss of generality, assume that for all $x\in\mathrm{E}$ we have $x=t$ for some $t\in\mathbb{R}$, and for all $y\in\mathrm{F}$ we have $y_{1}=r$ for some $r\in\mathbb{R}$.
    
    It then follows for all $z\in(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1}$ that there are $x\in\mathrm{K}_{0}$ and $y\in\mathrm{K}_{1}$ with
    \begin{center}
        $z_{1}=(1-\lambda)x_{1}+\lambda y_{1}=(1-\lambda)t+\lambda s$.
    \end{center}
    Therefore, $(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1}$ is also contained in a parallel hyperplane. Since hyperplanes are $n-1$ dimensional, equality holds trivially.

    Now, let $\mathrm{K}_{0},\mathrm{K}_{1}\in\mathscr{K}^{n}$ be homothetic and $\mathrm{K}_{0}=\mu\mathrm{K}_{1}$ for $\mu\in\mathbb{R}$ and $t\in\mathbb{R}^{n}$. For $\lambda\in[0,1]$ we have
    \begin{center}
        $\mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}=\mathrm{V}_{n}([(1-\lambda)\mu+\lambda]\mathrm{K}_{1}+t)^{\frac{1}{n}}$

        $=\mathrm{V}_{n}([(1-\lambda)\mu+\lambda]\mathrm{K}_{1})^{\frac{1}{n}}$

        $=[(1-\lambda)\mu+\lambda]\mathrm{V}_{n}(\mathrm{K}_{1}){\frac{1}{n}}$

        $=(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{\frac{1}{n}}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{\frac{1}{n}}$,
    \end{center}
    and therefore equality holds.

    In the following, we will show the inequality in Brunn-Minkowski Theorem.

    \textbf{Case 1 $\dim{\mathrm{K}_{0}}=\dim{\mathrm{K}_{1}}<n$.} Since $\mathrm{V}_{n}(\mathrm{K}_{0})=\mathrm{V}_{n}(\mathrm{K}_{1})=0$ this case is trival. Equality implies $\dim((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})<n$. This implies that all three convex bodies have to be contained in parallel hyperplanes.\

    \textbf{Case 2 $\dim{\mathrm{K}_{0}}<0, \dim{\mathrm{K}_{1}}=n$.} For $x\in\mathrm{K}_{0}$ we have
    \begin{center}
        $(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1}\supseteq(1-\lambda)x+\lambda\mathrm{K}_{1}$,
    \end{center}
    which implies that
    \begin{center}
        $\mathrm{V}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{1}}$.
    \end{center}
    This implies the Brunn-Minkowski inequality. If equality holds then $\mathrm{K}_{0}=\{x\}$. Hence, $\mathrm{K}_{0}$ and $\mathrm{K}_{1}$ are homothetic.

    \textbf{Case 3 $\dim{\mathrm{K}_{0}}=\dim{\mathrm{K}_{1}}=n$.} This case will be proven by induction.

    The case $n=1$ is trivial. Now consider the iteration from $n-1$ to $n$.

    Without loss of generality, assume $\mathrm{V}_{n}(\mathrm{K}_{0})=\mathrm{V}_{n}(\mathrm{K}_{1})=1$. This is allowed becuase the general inequality follows from this special case. Indeed, for $\mathrm{K}_{0},\mathrm{K}_{1}\in\mathscr{K}^{n}$ being $n$-dimensional with arbitrar volume and $\lambda\in[0,1]$ consider
    \begin{center}
        $\displaystyle \overline{\mathrm{K}_{i}}:=\frac{\mathrm{K}_{i}}{\mathrm{V}_{n}(\mathrm{K}_{i})^{\frac{1}{n}}}$ und $\displaystyle \overline{\lambda}:=\frac{\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}{(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^\{1/n\}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}\in[0,1]$.
    \end{center}
    Then we get
    \begin{center}
        $\displaystyle \mathrm{V}_{n}((1-\overline{\lambda})\overline{\mathrm{K}_{0}}+\overline{\lambda}\overline{\mathrm{K}_{1}})^{\frac{1}{n}}=\mathrm{V}_{n}\Big(\frac{(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}\overline{\mathrm{K}_{0}}-\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}\overline{\mathrm{K}_{0}}+\lambda\mathrm{K}_{1}}{(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{1/n}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}\Big)^{1/n}$

        $\displaystyle =\frac{1}{(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}\mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}$.
    \end{center}
    In addition, we also have (because the inequality is already proven for $\mathrm{V}_{n}(\overline{\mathrm{K}_{i}})=1$)
    \begin{center}
        $\displaystyle \mathrm{V}_{n}((1-\overline{\lambda})\overline{\mathrm{K}_{0}}+\overline{\lambda}\overline{\mathrm{K}_{1}})^{\frac{1}{n}}\geq(1-\overline{\lambda})\mathrm{V}_{n}(\overline{\mathrm{K}_{0}})^{\frac{1}{n}}+\overline{\lambda}\mathrm{V}_{n}(\mathrm{K}_{1})^{\frac{1}{n}}=1$.
    \end{center}
    This implies
    \begin{center}
        $\displaystyle \frac{1}{(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{1/n}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}\mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}\geq1$.
    \end{center}
    Thus, the inequality in Brunn-Minkowski Theorem is proven.

    Therefore let $\mathrm{V}_{n}(\mathrm{K}_{0})=\mathrm{V}_{n}(\mathrm{K}_{1})=1$. Choose $u\in\mathbb{S}^{n}$ and $\lambda\in[0,1]$. We now introduce the following notations to shorten the computations. We set $\mathrm{K}_{\lambda}:=(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1}$ and $\beta_{\lambda}:=h(\mathrm{K}_{\lambda},u)$, and $\alpha_{\lambda}:=-h(\mathrm{K}_{\lambda},-u)$. Furthermore, for $\zeta\in(\alpha_{i},\beta_{i})$\;$i=0,1$ we set the half space $\mathrm{H}^{-}(\zeta):=\{x\in\mathbb{R}^{n};\langle x,u\rangle\leq\zeta\}$ and the hyperplane $\mathrm{H}(\zeta):=\{x\in\mathbb{R}^{n};\langle x,u\rangle=h(\mathrm{K},u)\}$, as well as the volume $v_{i}:=\mathrm{V}_{n-1}(\mathrm{K}_{i}\cap\mathrm{H}(\zeta))$.

    Let us define for every $\zeta\in[\alpha_{i}\beta_{i}]$
    \begin{center}
        $\displaystyle w_{i}(\zeta):=\int_{\alpha_{i}}^{\zeta}v_{i}(t)\,dt$.
    \end{center}
    We know that the support functions $h$ and $\mathrm{V}_{n}$ are continuous. Hence, $\mathrm{V}_{n}(\mathrm{K}_{i}\cap\mathrm{H}^{-}(\zeta))$ is also continous in $\zeta$ and we can apply the Fundamental Theorem of Calculus on $w_{i}$. It follows that $w_i$ is differentiable and it holds that $w'_{i}(\zeta)=v_{i}>0$ (because $\dim\mathrm{K}_{i}=n$). This implies that $w_{i}$ is strictly monotonically increasing and is therefore a bijection on its image $(0,1)$. For $i=0,1$ define $z_{i}$ as the inverse function of $w_{i}$. Intuitively, this means that for a volume $\tau\in(0,1)$ with $\mathrm{V}_{n}(\mathrm{K}_{i}\cap\mathrm{H}^{-}(z_{i}(\tau)))=\tau$, the function $z_{i}$ maps $\tau$ to the ``height'' of $\mathrm{H}$ (figure).

    Consider $z_{\lambda}(\tau):=(1-\lambda)z_{0}+\lambda z_{1}$ for $\lambda\in(0,1)$, $i=0,1$, and $\tau\in(0,1)$. Let $k_i(\tau):=\mathrm{K}_{i}\cap\mathrm{H}(z_i(\tau))$, then we have
    \begin{center}
        $\displaystyle (1-\lambda)k_{0}(\tau)+\lambda k_{1}(\tau)\subseteq\mathrm{K}_{\lambda}\cap\mathrm{H}(z_{\lambda}(\tau))\;\forall\lambda,\tau\in(0,1)$
    \end{center}
    Now, we can prove the inequality in Brunn-Minkowski Theorem by induction. As mentioned before, the case $n=1$ holds trivially. For the iteration from $n-1$ to $n$, we can compute
    \begin{center}
        $\displaystyle \mathrm{V}_{n}(\mathrm{K}_{\lambda})\overset{Fubini}{=}\int_{\alpha_{\lambda}}^{\beta_{\lambda}}\mathrm{V}_{n-1}(\mathrm{K}_{\lambda}\cap\mathrm{H}(\zeta))\,d\zeta$

        $\displaystyle \overset{\zeta=z_{\lambda}(\tau)}{=}\int_{0}^{1}\mathrm{V}_{n-1}(\mathrm{K}_{\lambda}\cap\mathrm{H}(z_{\lambda}(\tau)))\cdot z'_{\lambda}(\tau)\,d\tau$

        $\displaystyle \overset{\zeta=z_{\lambda}(\tau)}{\geq}\int_{0}^{1}\mathrm{V}_{n-1}((1-\lambda)k_{0}(\tau)+\lambda k_{1}(\tau))\cdot z'_{\lambda}(\tau)\,d\tau$

        $\displaystyle \begin{aligned} & \geq \int_0^1[(1-\lambda) \underbrace{\mathrm{V}{n-1}\left(k_0(\tau)\right)^{\frac{1}{n-1}}}_{=\nu_0\left(z_0(\tau)\right)^{\frac{1}{n-1}}}+\lambda \underbrace{\mathrm{V}_{n-1}\left(k_1(\tau)\right)^{\frac{1}{n-1}}}_{=\nu_1\left(z_1(\tau)\right)^{\frac{1}{n-1}}}]^{n-1} \cdot\left(\frac{1-\lambda}{\nu_0\left(z_0(\tau)\right)}+\frac{\lambda}{\nu_1\left(z_1(\tau)\right)}\right) d \tau \\ & =\int_0^1\left((1-\lambda) \nu_0\left(z_0(\tau)\right)^{\frac{1}{n-1}}+\lambda \nu_1\left(z_1(\tau)\right)^{\left.\frac{1}{n-1}\right)}\right)^{n-1} \cdot\left(\frac{1-\lambda}{\nu_0\left(z_0(\tau)\right)}+\frac{\lambda}{\nu_1\left(z_1(\tau)\right)}\right) d \tau,\end{aligned}$
    \end{center}
    where we used in the third line the Inverse Function Theorem, which implies
    \begin{center}
        $\displaystyle z'_{i}(\tau)=\frac{1}{w'_{i}(\tau)}=\frac{1}{v_{i}(\tau)}$,
    \end{center}
    and the claim for $n-1$.

    To simplify the notation, define $\mathit{p}:=\frac{1}{n-1}$ and $v_{i}=v_{i}(z_{i}(\tau))$. The concavity of log implies
    \begin{center}
        $\displaystyle \log\Big([(1-\lambda)v^{\mathit{p}}_{0}+\lambda v^{\mathit{p}}_{1}]^{\frac{`}{\mathit{p}}}\cdot\Big(\frac{1-\lambda}{v_{0}}+\frac{\lambda}{v_{1}}\Big)\Big)=\frac{1}{\mathit{p}}\log[(1-\lambda)v^{\mathit{p}}_{0}+\lambda v^{\mathit{p}}_{1}]+\log\Big(\frac{1-\lambda}{v_{0}}+\frac{\lambda}{v_{1}}\Big)$

        $\geq\frac{1}{\mathit{p}}[\mathit{p}(1-\lambda)\log{v_{0}}+\mathit{p}\lambda\log{v_{1}}]-[(1-\lambda)\log{v_{0}}+\lambda\log{v_{1}}]=0$.
    \end{center}
    After applying exp, we see that
    \begin{center}
        $\displaystyle \Big((1-\lambda)v_{0}(z_{0}(\tau))^{\frac{1}{n-1}}+\lambda v_{1}(z_{1}(\tau))^{\frac{1}{n-1}}\Big)^{n-1}\cdot\Big(\frac{1-\lambda}{v_{0}(z_{0}(\tau))}+\frac{\lambda}{v_{1}(z_{1}(\tau))}\Big)\geq1$.
    \end{center}
    This implies
    \begin{center}
        $\displaystyle \int_{0}^{1}\Big((1-\lambda)v_{0}(z_{0}(\tau))^{\frac{1}{n-1}}+\lambda v_{1}(z_{1}(\tau))^{\frac{1}{n-1}}\Big)^{n-1}\cdot\Big(\frac{1-\lambda}{v_{0}(z_{0}(\tau))}+\frac{\lambda}{v_{1}(z_{1}(\tau))}\Big)\,d\tau\geq1$
    \end{center}
    on $(0,1)$. Hence, the inequality
    \begin{center}
        $\displaystyle \mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}=\mathrm{V}_{n}(\mathrm{K}_{\lambda})^{\frac{1}{n}}\geq(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{\frac{1}{n}}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{\frac{1}{n}}$.
    \end{center}
    is proven. Now, it only remains to show that he equality implies that $\mathrm{K}_{1}$ and $\mathrm{K}_{2}$ are homothetic. Suppose for a $\lambda\in(0,1)$ that equality holds.

    This implies $\mathrm{K}_{\lambda}\cap\mathrm{H}(z_{\lambda}(\tau))=(1-\lambda)k_{0}(\tau)+\lambda k_{1}(\tau)$. Thus, we have $k_{1}(\tau)=k_{0}(\tau)$ and therefore also $v_{1}(z_{1}(\tau))=v_{0}(z_{0}(\tau))$. This implies $z'_{1}(\tau)=z'_{0}(\tau)$, and hence, $z_{1}(\tau)-z_{0}(\tau)$ is constant.

    Without loss of generality, assume that $\int_{\mathrm{K}_i}y\,dy=0$, for $i=0,1$ (otherwise shift the sets).

    Then we see that $\int_{\mathrm{K}_i}\langle y,u\rangle\,dy=\sum_{i=1}^{n}u_{i}\int_{\mathrm{K}_i}y\,dy=0$. This implies
    \begin{center}
        $\displaystyle 0=\int_{\mathrm{K}_i}\langle y,u\rangle\,dy=\int_{\alpha_{i}}^{\beta_{i}}\int_{\mathrm{K}\cap\mathrm{H}(\zeta)}\underbrace{\langle u,z\rangle}_{=\zeta}\,dz\,d\zeta$

        $\displaystyle =\int_{\alpha_{i}}^{\beta_{i}}\mathrm{V}_{n-1}(\mathrm{K}_{i}\cap\mathrm{H}(\zeta))\zeta\,d\zeta$

        $\displaystyle =\int_{0}^{1}\mathrm{V}_{n-1}(\mathrm{K}_{i}\cap\mathrm{H}(z_{i}(\tau)))z_{\tau}\dot{z}_{i}(\tau)\,d\tau$







        $\displaystyle =\int_{0}^{1}v_{i}(z_{i}(\tau))z_{i}(\tau)\frac{1}{v_{i}(z_{i}(\tau))}\,d\tau=\int_{0}^{1}z_{i}(\tau)\,d\tau$,
    \end{center}
    by using $\mathrm{K_{i}=\bigcup_{\zeta}\mathrm{K}_{i}\cap\mathrm{H}(\zeta)}$ and Fubini's Theorem.

    Now, we konw that $\int_{0}^{1}z_{0}(\tau)-z_{1}(\tau)\,d\tau=0$, and $z_{0}=z_{1}$ on $(0,1)$. Therefore, we also know $w_{1}=w_{0}$ and $v_{1}=v_{0}$. Furthermore, using
    \begin{center}
        $\int_{\alpha_{1}}^{\beta_{1}}v_{1}(\tau)\,dt=w_{1}=w_{0}=\int_{\alpha_{0}}^{\beta_{0}}v_{0}(t)\,dt$,
    \end{center}
    we can conclude that $\alpha_{0}=\alpha_{1}$ and $\beta_{0}=\alpha_{1}$. This implies $h(\mathrm{K}_{0},u)=h(\mathrm{K}_{1},u)$ and, with Remark 8, we get that $\mathrm{K}_{0}=\mathrm{K}_{1}$. In particular $\mathrm{K}_{0}$ and $\mathrm{K}_{1}$ are homothetic.
\end{proof}

\begin{remark}
    The Brunn-Minkowski Inequality can also be proven for domains with differentiable boundary. Using this, it is also possible to prove the isoperimetric inequality. In addition, there is also a Brunn-Minkowski inequality for general domains. More information can be found in~\citep{gardner2002brunn}.
\end{remark}

\begin{corollary}
    Let $\mathrm{K}_{0}, \mathrm{K}_{1}\in\mathscr{K}_{n}$ and $\mathrm{I}=[0,1]$. Then the function
    \begin{center}
        $f:\mathrm{I}\to\mathbb{R}\;\lambda\to\mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{1/n}$
    \end{center}
    is concave. The function $f$ is linear if and only if $\mathrm{K}_{0}$ and $\mathrm{K}_{0}$ are contained in parallel hyperplanes or are homothetic.
\end{corollary}

The next lemma follows by using basic tools of analysis. Hence, we will not prove it here, but we will use it in the proof of the isoperimetric inequality.

\begin{lemma}
    Let $f:\mathrm{I}\to\mathbb{R}$ be a smooth, convex functions such that $f'(0)=f(1)-f(0)$ holds. Then $f$ is linear.
\end{lemma}

\section{Proof of the Isoperimetric Inequality in n-Dimension}
Before proving the isoperimetric inequality using methods of convex geometry. Therefore, we need to adapt the assumptions of our theorem. Since we have introduced new language describing convex geometry, it is better that we also reintroduce the isoperimetric theorem in terms of our new language. Hence:
\begin{theorem} (Isoperimetric Inequality)
    Let $\mathrm{K}\in\mathscr{K}_{0}^{n}$. Then
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K})\geq n\mathrm{V}_{n}(\mathrm{B}_{n})^{1/n}\mathrm{V}_{n}(\mathrm{K})^{1-1/n}$.
    \end{center}
    Equality holds if and only if $\mathrm{K}$ is a ball.
\end{theorem}
\begin{proof}
    Let $\mathrm{K}\in\mathscr{K}_{0}^{n}$. We have $\mathrm{V}_{n}(\mathrm{K})\neq0$. Consider $\displaystyle \epsilon:=\frac{t}{1-t}$. We compute
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K})=\underset{t\downarrow0}{\lim}\frac{\mathrm{V}{n}(\mathrm{K}+\frac{t}{1-t}\mathrm{B}^{n})-\mathrm{V}{n}(\mathrm{K})}{(\frac{t}{1-t})}$

        $\displaystyle =\underset{t\downarrow0}{\lim}\frac{\mathrm{V}{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})-(1-t)^{n}\mathrm{V}{n}(\mathrm{K})}{(1-t)^{n-1}t}$

        $\displaystyle =\underset{t\downarrow0}{\lim}\Big[\frac{\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{t}+\frac{(1-(1-t)^{n})\mathrm{V}_{n}(\mathrm{K})}{t}\Big]$

        $\displaystyle =\underset{t\downarrow0}{\lim}\Big[\frac{\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{t}\Big]+n\mathrm{V}_{n}(\mathrm{K})$.
    \end{center}
    In the third line, we used that the limits are the same. In the last line, we used the Theorem of l'Hopital. This implies
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K})-n\mathrm{V}_{n}(\mathrm{K})=\underset{t\downarrow0}{\lim}\frac{\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{t}\cdot(\ast)$
    \end{center}
    Now consider the function $f(t):=\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})^{1/n}$ and observe
    \begin{center}
        $f'(t)=\frac{1}{n}\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})^{1/{n-1}}\cdot\frac{d}{dt}\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})$.
    \end{center}
    This implies $f'(0)\overset{(\ast)}{=}\frac{1}{n}\mathrm{V}_{n}(\mathrm{K})^{1/{n-1}}(\mathrm{S}(\mathrm{K})-n\mathrm{V}_{n}(\mathrm{K}))$. By using corollary 1, it follows that $f$ is concave on [0,1]. hence, we know that $f'(0)\geq f(1)-f(0)$. This implies the inequality
    \begin{center}
        $\displaystyle \frac{1}{n}\mathrm{V}_{n}(\mathrm{K})^{1/{n-1}}\mathrm{S}(\mathrm{K})-\mathrm{V}_{n}(\mathrm{K})^{1/n}=\frac{1}{n}\mathrm{V}_{n}(\mathrm{K})^{1/{n-1}}(\mathrm{S}(\mathrm{K})-n\mathrm{V}_{n}(\mathrm{K}))\geq\mathrm{V}_{n}(\mathrm{B}^{n})^{1/n}-\mathrm{V}_{n}(\mathrm{K})^{1/n}$.
    \end{center}
    Therefore, the isoperimetric inequality
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K})\geq n\mathrm{V}_{n}(\mathrm{B}_{n})^{1/n}\mathrm{V}_{n}(\mathrm{K})^{1-1/n}$
    \end{center}
    follows. If $\mathrm{K}$ is a ball, equality follows by using remark 12.

    Equality implies $f'(0)=f(1)-f(0)$. By using the concavity of $f$ and lemma 17, it follows that $f$ is linear. From corollary 1, we know that $\mathrm{K}$ and $\mathrm{B}^{n}$ are homothetic.

    Hence, $\mathrm{K}$ is a ball.
\end{proof}

\subsection{3-Dimensional Case ($\mathbb{R}^{3}$)}
For dimension two, the isoperimetric inequality in theorem 18 can be written as
\begin{center}
$\displaystyle \mathrm{U}(\mathrm{K})\geq 2\mathrm{V}_{2}(\mathrm{B}_{2})^{1/2}\mathrm{V}_{2}(\mathrm{K})^{1/2}=2\sqrt{\pi}\mathrm{A}[\mathrm{K}]^{1/2}$,
\end{center}
where $\mathrm{A}$ is the area and $\mathrm{U}$ is the perimeter of $\mathrm{K}$. By squaring this, we get
\begin{center}
$4\pi\cdot\mathrm{A}[\mathrm{G}]\leq\mathrm{U}[\mathrm{G}]^{2}$.
\end{center}

For the dimension three, the isoperimetric inequality in theorem 18 can be written as
\begin{center}
$\displaystyle \mathrm{U}(\mathrm{K})\geq 3\mathrm{V}_{3}(\mathrm{B}_{3})^{1/3}\mathrm{V}_{2}(\mathrm{K})^{1/3}=3\sqrt{\pi}\mathrm{A}[\mathrm{K}]^{2/3}$
\end{center}

\bibliography{The-Isoperimetric-Problem-References}
\end{document}