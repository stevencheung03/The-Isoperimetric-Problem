\documentclass[a4paper]{book}
\usepackage{extarrows}
\usepackage{amsmath,amsthm}\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{answers}
\usepackage{eufrak}
\usepackage{eucal}
\usepackage{fancyhdr}
\usepackage{graphicx}
{\setlength\arraycolsep{2pt}
\usepackage{mathrsfs}
\usepackage{graphicx,fancyhdr}
\usepackage{graphicx} 
\graphicspath{ {./images/} }
\usepackage{caption}
\usepackage{CJKnumb}
\usepackage{titlesec}
\titleformat{\chapter}{}{}{0em}{\bf\huge}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}
\usepackage[colorlinks,urlcolor=blue,citecolor=blue,linkcolor=blue]{hyperref}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{xspace}
\usepackage{parskip}
\usepackage[sort,comma]{natbib}
\usepackage{float}

\newtheorem{theorem}{Theorem}%[section]
\newtheorem{lemma}[theorem]{Lemma}%[section]
\newtheorem{example}[theorem]{Example}%[section]
\newtheorem{remark}[theorem]{Remark}%[section]
\newtheorem{note}[theorem]{Note}%[section]
\newtheorem{proposition}[theorem]{Proposition}%[section]
\newtheorem{definition}[theorem]{Definition}%[section]
\newtheorem{conjecture}[theorem]{Conjecture}%[section]
\newtheorem{corollary}[theorem]{Corollary}%[section]
\newtheorem{problem}[theorem]{Problem}%[section]
\newtheorem{condition}[theorem]{Condition}%[section]

\numberwithin{theorem}{section}%[fixes numbering]

\renewcommand{\proofname}{\textbf{Proof}}

\newenvironment{ddd}{\begin{rmdef}\rm}{\end{rmdef}}
\newenvironment{eee}{\begin{rmexa}\rm}{\end{rmexa}}
\newenvironment{rrr}{\begin{rmrem}\rm}{\end{rmrem}}
\newenvironment{pf}[1][Proof]{\par\noindent{\em #1}. }{\hfill\framebox(6,6)\par\medskip}

\usepackage{geometry}
 \usepackage[normalem]{ulem}
%\renewcommand{\baselinestretch}{1.5}

\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

\newcommand{\Poincare}{Poincar\'e\xspace}
\newcommand{\Holder}{Hölder}

\usepackage{graphicx} %picture
\usepackage{float} %picture
\usepackage{subfigure} %picture

\usepackage[nottoc,notlot,notlof]{tocbibind}
%Hölder
%\renewcommand{\baselinestretch}{1.5}
\let\cleardoublepage\clearpage
\begin{document}

\begin{titlepage}\phantom{|}\vspace{0.75in}
\begin{center}
    \underline{THE ISOPERIMETRIC PROBLEM}
\end{center}
\begin{center}
    \underline{}
\end{center}
\vspace{1.5in}%{2.0in}
\begin{center}
    Dissertation submitted at the University of Leicester \\
    in partial fulfilment of the requirements for \\ 
    the degree of Bachelor of Science of Mathematics\\
\end{center}
\vspace{.5in}
\begin{center}
    by
\end{center}
\vspace{.5in}
\begin{center}
    Steven Cheung \\
    Department of Mathematics \\
    University of Leicester \\
\end{center}
\vspace{0.5in}
\begin{center}
    May 2024
\end{center}
\end{titlepage}

\bibliographystyle{agsm}
\renewcommand{\bibname}{References}

\tableofcontents
\thispagestyle{empty}
\chapter*{Declaration}                % The * means no number for this chapter
\pagenumbering{arabic}
\addcontentsline{toc}{chapter}{\hspace{0.2in}Declaration}
All sentences or passages quoted in this project dissertation from other
people's work have been specifically acknowledged by clear cross referencing
to author, work and page(s). I understand that failure to do this amounts
to plagiarism and will be considered grounds for failure in this module and
the degree examination as a whole.


\bigskip

\noindent
Name: Steven Cheung


\bigskip

\noindent
Signed: 


\bigskip

\noindent
Date: May 2024

%-------------------------------------------------------------------------------------
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{\hspace{0.2in}Abstract}
In general, we want the maximum area whose boundary must pertain a specific length. This basic idea of the isoperimetric problem leaves many mathematicians puzzled still to this day.
\newline
\newline
\textbf{Rich History:} Our problem is one not to be trifled with, and across many a centuries to even dating back to 200 BC, we can see the events unfold of how we learn about how the small intricacies become part of something larger and more complex. 
\newline
\newline
\textbf{2-D Case:} The isoperimetric problem revolves around finding the shape that achieves the maximum enclosed area among all closed curves with a given length. We introduce three proofs from different approaches from different disciplines of mathematics. Amongst the many simple curves, we identify that the circle is unique for pertaining the optimal area. We touch on Steiner's proof along the way to provide his insight into how this particular curve is maximal comparative to others. We then show how the Euler-Lagrange Equation comes into effect; the finding of extremal curves with fixed areas and fixed perimeters. Finally, we will then show how Fourier analysis and differential geometry can be used as tools to prove the problem. Our overall findings and conclusions are to show that across many a proofs through the decades, mathematicians have opted to find curves under this fixed perimeter constraint with additional factors taking place. 
\newline
\newline
\textbf{N-Dimensions:} Spherical in 3-D, which allows us to refer back to our 2-D case. Here we will discuss the spherical isoperimetric inequality. To begin we introduce several more important tools, the support function, Hausdorff metric, volume and surface measure, and then prove the Brunn-Minkowski inequality. Using this inequality, the proof of the isoperimetric inequality in $n$-dimension will be shown. We will then see how the 2-D and the 3-D cases will behave under this new result.
\newline
\newline
Finally a comparison between the proofs. Where we shall discuss the limitations of each proof and how it differs to each other.

%-------------------------------------------------------------------------------------
%\chapter{Introduction}
%\addcontentsline{toc}{chapter}{\hspace{0.2in}Introduction}
\chapter{Historical Notes}
%\addcontentsline{toc}{section}{\hspace{0.2in}Historical Notes}
Isoperimeter, isos which is ancient Greek for equal and perimetron for perimeter. The isoperimetric problem, even though it was not properly formalized, was already thought about all throughout the history. 
\newline
\newline
Book V of Pappus of Alexandria's Mathematical collections~\citep{wiegert2010sagacity} began with a preface titled ``On the Sagacity of Bees'', rather than the history of mathematicians past or their accomplishments to follow. This was written near the end of the 3rd century $A.D.$. Observing, Pappus credited the bees with ``a certain geometrical forethought'' (Thomas 593~\citep{ivor1941selections}) for their nearly faultless hexagonal comb structure. He wrote
\begin{center}
    \begin{quote}
        ``Bees know just this fact which is useful to them, that 
        the hexagon is greater than the square and the triangle 
        and will hold more honey for the same expenditure of 
        material in constructing each'' (Thomas 593~\citep{ivor1941selections})
    \end{quote}
\end{center}
Beyond the efficiency of bees, Pappus prefaced, ``We'' he continued
\begin{center}
    \begin{quote}
        ``... will {}investigate a somewhat wider problem, namely that, 
        of all equilateral and equiangular plane figures having an equal 
        perimeter, that which has the greater number of angles is always great 
        and the greates of them all is the circle having it's perimeter equal to them'' (Thomas 593~\citep{ivor1941selections})
    \end{quote}
\end{center}

Pappus then started working on the isoperimetric problem, which included numerous smaller problems within it. The main objective of the problem is to determine which of the planes and figures with the same perimeter has the largest area amongst them.

Although Pappus addressed the problem in the collections, it has been a topic of interest for centuries before. Appearing in both mathematical and literary materials and captivating the minds of mathematicians. 
\newline
\newline
The isoperimetric problem demonstrates ancient mathmaticians' perceptiveness and the consistency of mathematical endeavor over time, even in the modern age. The problem have been used by poets and historians, despite its mathematical nature. Most famously, Virgil made use of the concept in his Roman epic, The Aeneid. To quote Virgil
\begin{center}
    \begin{quote}
        ``At last they landed, where from far your eyes
        May view the turrets of new Carthage rise;
        There bought a space of ground, which Byrsa call'd,
        From the bull's hide they first inclos'd and wall'd.'' (Book I of Aeneid~\citep{virgil1981aeneid})
    \end{quote}
    
\end{center}

Virgil's version has it that Dido, daughter of the king of Tyre, fled home after her brother killed her husband. Dido ended up on the north coast of Africa, where she bargained to buy as much land as she could enclose with an oxhide. Thus, she cut the hide into thin strips, where she presumably met and solved enclosing the largest area with a given perimeter - the isoperimetric problem. Dido may have been clever enough and chose an area by the coast to exploit the shore as part of the perimeter. But this mostly spoils the purity of posed problem. Kline concludes~\citep{kline1985mathematics}. The Aeneid was written between $29$ and $19 B.C.$.
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=130mm]{dido_1}
        \caption{Representations of areas bounded by common shapes of the same perimeter. The semicircle, answer to Dido's problem which contains the greatest area. (image and caption from~\citep{demjanenko2008isoperimetric})}
    \end{center}
\end{figure}\leavevmode \\

In the 3rd century $A.D.$, Roman historian Marcus Junianus Justinus compliled an account of Carthaginian folklore that the legendary founding of Carthage by Dido, called Elissa by the Greeks (the mythological origin of the city):
\begin{center}
    \begin{quote}
        ``Then [Elissa] bout some land, just as much as could be covered by a cow's hide, where she could give some recreation to her men... She next gave orders for the hide to be cut into very fine strips, and in this way she took possession of a great area than she had apparently bargained for'' (Book XVIII 157~\citep{yardley1994justin})
    \end{quote}
\end{center}

Since ancient Greece, around $100B.C.$, they wanted to measure the size of islands by timing how long it takes to circumnavigate the entire island. Proclus, a classical mathematician, mocked geometers for ``measuring the size of a city from the lengths of its walls''. To the common person of antiquity, two shapes with equal perimeter may have different areas. Interestingly, some individuals exploited this misconception to defraud others of land. Considerably more amusing, these con artists were viewed as liberal which demonstrates how unnatural the idea of shapes with a similar edge having different regions was to the old Greeks.
\newline
\newline
Geoffrey of Monmouth's Historia Regum Britanniae (History of the Kings of England), a 12th century $A.D.$ chronicle of Arthurian legends, mentions the isoperimetric problem. In this story, Hengist, a German duke, appeals to King Vortigern for land in exchange for his military service:
\begin{center}
    \begin{quote}
        ``'Grant', said Vortigern, 'unto thy servant but so much only as may be compassed round about by a single thong within the land thou hast given me, that so I ma build me a high place therein whereunto if need be I may betake me’...Straightaway...Hengist took a bull’s hide, and wrought the same into a single thong throughout. He then compassed round with his thong a stony place that he had right cunningly chosen, and within the space thus meted out did begin to build a castle that was afterwards called in British , Kaercorrei, but in Saxon, Thongceaster, the which in Latin’s speech is called Castrum corrigae''' (Monmouth 105-106~\citep{evans1920histories})
    \end{quote}
\end{center}
\leavevmode
\newline
\newline
Thus, the poets and historians who chronicled the exploits of these mythological characters as well as the figures themselves found special meaning in the isoperimetric problem. Despite its extensive implications, the notion of isoperimetry was ``naturally greek''. The Greeks have pretty much solved it, by their standards. Zenodorus was an ancient Greek mathematician from around $200B.C.$ to $120B.C.$. And have mostly proved that a circle has greater area than any polygon with the same perimeter. Majority of his work was lost. However, fortunately, parts of his work survived through references by Pappus and Theon of Alexandria.

Theon of Alexandria then develops this idea, with a summary of the proofs present by Zenodorus in ``On Isoperimetric Figures''. According to Theon, Zenodorus did not initiate his disussion of isoperimetry with the circle. Rather he stated that ``Of all rectilinear figures having an equal perimeter - I mean equilateral and equiangular figures - the greatest is that which has the most angles'' (Thomas 388-389~\citep{ivor1941selections}). In more modern language, the proposition is stated as follows: ``Given two regular $n$-gons with the same perimeter, one with $n=n_1$ and the other with $n=n_2>n_1$ then the regular $n_2$-gon has the larger area'' (Nahin 47~\citep{nahin2021least}). Following this, Zenodorus was able to arrive at the proposition that ``if a circle have an equal perimeter with an equilateral, equiangular, and rectilinear figure, the circle shall be the great" (Thomas 391~\citep{ivor1941selections}). As Heath notes in his ``History of Greek Mathematics'', Zenodorus chose to base his proof of this proposition on the theorem already established by Archimedes that ``the area of a circle is equal to the right-angled triange with perpendicular side equal to the radius and base equal to the perimeter of the circle'' (Heath 209~\citep{heath2013history}). From here, Zenodorus proceeded on the basis of two preliminary lemmas: first that ``if there be two triangles on the same base and with the same perimeter, one being isosceles and the other scalene, the isosceles triangle has the greater area'' (Heath 209~\citep{heath2013history}); second that ``given two isosceles triangles not similar to one another, if [one constructs] on the same bases, two triangles similar to one another such that the same of the areas of the similar triangles is great than the sum of the areas of the non-similar triangles'' (Heath 210~\citep{heath2013history}). Both commentors seem to hint that it will be covered in subsequent chapters, but as Heath bemoans ``in the text as we have it the promise is not fulfilled'' (Heath 212~\citep{heath2013history}) (this entire paragraph is lifted from~\citep{wiegert2010sagacity})
\newline
\newline
In the ancient world, the problem of isoperimetry was associated with the work of Zenodorus and his commentator, Pappus. It was the work of a Swiss mathematician Jacob Steiner (1796-1863) who tackled the isoperimetric theorem in the modern word.

Indeed, the problem of isoperimetry in the nineteenth century emerged at an important juncture in mathematical thought. Mathematicians working in all fields of inquiry struggled over the use of analytic (i.e. calculus) or synthentic (i.e pure geometry) methods in solving problems~\citep{wiegert2010sagacity}. Nahin notes that Steiner's 1842 geometrical proof of the isoperimetric theorem is still regarded as a ``model of mathematical ingenuity'' despite subsequent discoveries of defects in the synthetic approach. The following propositions must be understood to be logically equivalent in order for Steiner's proof of the isoperimetric theorem to hold:
\begin{center}
    \begin{quote}
        A. ``Of all closed curves in a plane with equal perimeters, the cicle bounds the largest area''
        \newline
        [and]
        \newline
        B. ``Of all closed curves in a plane with equal areas, the cricle has the smallest perimeter'' (Nahim 55~\citep{nahin2021least})
    \end{quote}
\end{center}

Steiner thought he had demonstrated that the circle was the answer to the isoperimetric problem. As later researchers, especially the German mathematician Peter Dirichlet (1805-1859) remarked, Steiner had made an underlying assumption not explicitly addressed in his proof, namely that a solution existed (Nahin 59~\citep{nahin2021least}).
\newline
\newline
Other mathematicians attempted to tackle the isoperimetric problem from the analytic or calculus-based perspective. And to no avail. We will expand on this in later sections.

Problems posed by the ancients, not only speeded the progression towards more rigorous and complete systems of mathematics, but also prompted later innovators to develop new systems to deal with these early questions. The isoperimetric problem thus demonstrates an important continuity in mathematical thought. From Zenodorus to Pappus and from Steiner to the mathematicians of the twenty-first century, isoperimetry has transcended its origins in ancient geometry to become a building block of more modern analytic systems of mathematics~\citep{wiegert2010sagacity}. Below is a table summary, where we have timelined the history of the problem:
\newline
\newline
\begin{center}
    \begin{tabular}{||c c c||} 
        \hline
        Name & Time Period & What they did? \\ [0.5ex] 
        \hline
        Pappus & written 3rd Century $A.D.$ & started working about the isoperimetric problem \\ && from bee's hexagonal comb structure  \\ 
        \hline
        Dido (The Aeneid) & 29$B.C.$-19$B.C.$ & enclose as much land with oxhide \\
        \hline
        Zenodorus & 200$B.C.$-120$B.C.$ & more angles means more area \\
        \hline
        Ancient Greece & 100$B.C.$ & circumnavigate land \\
        \hline
        Arthurian Legends & 12th Century $A.D.$ & exchanged land for military service \\
        \hline
        Steiner & 1842 & first proof (existence) \\ 
        \hline
        Peter Dirichlet & 1805-1859 & noticed flaw with Steiner's proof \\ [1ex]
        \hline
    \end{tabular}
\end{center}

\chapter{Preliminaries}
%\addcontentsline{toc}{chapter}{\hspace{0.2in}Important Preliminaries}
\section{2-Dimensional Preliminaries}
These preliminiaries should cover all the knowledge we should need for all the $2$-Dimensional proofs. To begin, we will introduce basic knowledge, starting from ideas of simple and closed, then looking at what the curve means to be compact, then Fourier series, then the notation and finally look at what it means for an object to be convex. 

Firstly, we will take for granted the Jordan Curve Theorem:
\begin{theorem}[Jordan Curve Theorem]
    A simple closed curve in the plane divides the plane into two regions, one compact and one non-compact, and in the common boundary of both regions.
\end{theorem} 

The Jordan Curve Theorem is just a standard, but highly non-trivial, result of the topology of $\mathbb{R}^2$, that any simple closed curve in the plane has an 'interior' and 'exterior': more precisely, the complement of the image of $\gamma$ (i.e. the set of two points $\mathbb{R}^2$ that are \underline{not} in the image of $\gamma$) is the disjoint union of two subsets of $\mathbb{R}^2$, denoted by $int(\gamma)$ and $ext(\gamma)$, with the following properties:
\begin{enumerate}
    \item $int(\gamma)$ is bounded, i.e. it is contained inside the circle of sufficiently large radius.
    \item $ext(\gamma)$ is unbounded
    \item Both of the regions $int(\gamma)$ and $ext(\gamma)$ are connected, i.e. they have the property that any two points in the same region can be joined by a curve contained entirely in the region (but any curve joining a point of $int(\gamma)$) to a point of $ext(\gamma)$ must cross the curve $\gamma$)
\end{enumerate}


\begin{note} 
    When we talk of the region bounded by a simple closed curve in the plane, we always mean the compact region
\end{note}

\begin{definition}
    A closed curve, is a curve that changes direction but does not cross itself whilst changing direction and which completely encloses an \textit{area}. 

    An open curve, is a curve that does not enclose any area within itself and has two endpoints.
\end{definition}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=110mm]{ClosedCurve}
        \caption{(i) are closed curves, (ii) are open curves}
    \end{center}
\end{figure}\leavevmode

\begin{definition}
    A simple curve, is a curve that changes direction but does not cross itself whilst changing direction. 

    A nonsimple curve, is a curve that cross itself.
\end{definition}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=110mm]{SimpleCurves}
        \caption{(i) is simple curves, (ii) is nonsimple curves}
    \end{center}
\end{figure}\leavevmode

\begin{definition}
    A simple closed curve in $\mathbb{R}^2$, is a closed curve in $\mathbb{R}^2$ that has no self-intersections
\end{definition}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=120mm]{SimpleClosedCurveExamples}
        \caption{(i) is simple curves, (ii) is nonsimple curves}
    \end{center}
\end{figure}\leavevmode

The two definitions, above, are vital into understanding the main theorem. Since the isoperimetric inequality is a global result, we borrow concepts from topology, such as:

\begin{definition}
    A function is bounded if $\exists M \in \mathbb{R}$ such that $\left| f(x) \right| \leq M$.
\end{definition}

\begin{definition}
	Let $f:D\to\mathbb{R}$ a function and $c\in\mathbb{R}$ such that there exists $p>0$ such that $(c-p,c+p)\in D$. Then $f$ is called \textit{continuous} at $c$ if
	\begin{center}
		$\underset{x\to c}{\lim}f(x)=f(c)$.
	\end{center}
\end{definition}

\begin{definition}
    Let $X$ be a topological space and $A \subset X$. An open cover for $A$ is a family $\{U_\lambda\}_{\lambda\in I}$ of open subsets of $X$ such that
    \begin{center}
        $A \subset\underset{\lambda\in I}{\bigcup}{U_\lambda}$
    \end{center}
    An open cover is called finite if $\|I\|<\infty$. If $\{U_\lambda\}_{\lambda\in I}$ is an open cover for $A$ and $J \subset I$ is such that $A\subset\underset{\lambda\in J}{\bigcup}{U_\lambda}$, then $\{U_\lambda\}_{\lambda\in J}$ is called a subcover of $\{U_\lambda\}_{\lambda\in I}$.
\end{definition}

\begin{definition}
    A subset $A \subset X$ of a topological space called compact if every open cover of $A$ has a finite subcover. A space is called compact space if it is a compact subset of itself.
\end{definition}

\begin{definition} (Heine-Borel Theorem)
    A set in $\mathbb{R}^n$ is said to be compact if it is closed and bounded.
\end{definition}

\begin{definition} (Heron's Formula)
    Suppose a triangle $\mathrm{ABC}$, with sides $a$, $b$, $c$. The area,
    \begin{center}
        $\displaystyle \mathrm{A}=\sqrt{s(s-a)(s-b)(s-c)}$, where $s=\frac{a+b+c}{2}$, the semi-perimeter
    \end{center}
\end{definition}

\begin{definition} (AM-GM Inequality)
    If $x_1,_2,\ldots,x_n\geq0$, then $\displaystyle \frac{x_1+_2+\ldots,x_n}{n}\geq\sqrt{x_1 x_2 \ldots x_n}$ with equality if and only if $x_1=x_2=\ldots=x_n$.
\end{definition}

Over the next couple subsections we will introduce the necessary knowledge, language and notation to prove the 2-D case. Although we will also give other proofs, the final 2-D proof we are going to give, will continue nicely into the $n$-D proof.

\subsection{Fourier Series}
We use Fourier series to expand periodic functions from $\mathbb{R}$ to $\mathbb{C}$. This is so we can simplify the fourmulas of area by rewriting it using Fourier coefficients. We shall be introducing the theory behind Fourier series and answer the questions of existence and convergence of Fourier expansions.

\begin{definition}
    A function $f:\mathbb{R}\to\mathbb{C}$ is called \textit{periodic} with period $\mathrm{L}\in\mathbb{R}$ if it satisfies
    \begin{center}
        $f(x+L)=f(x)$
    \end{center}
    for all $x\in\mathbb{R}$.
\end{definition}

\begin{remark}
    We will concentrate functions with period $2\pi$. We can transform a periodic function $f$ with period $\mathrm{L}$ to a function with period $2\pi$ using $\displaystyle \mathrm{F}(x):=f(\frac{\mathrm{L}}{2\pi}x)$.
\end{remark}

\begin{definition}
    Let $f:\mathbb{R}\to\mathbb{C}$ be a periodic function that is Riemann integrable on the interval $[0,2\pi]$. Then the numbers
    \begin{center}
        $\displaystyle c_{k}:=\frac{1}{2\pi}\int_{0}^{2\pi}f(x)e^{-ikx}\,dx\;$, $k\in\mathbb{Z}$
    \end{center}
    are called the \textit{Fourier coefficients} of $f$. With the partial sums $\mathfrak{F}[f](x)=\sum_{k=-\mathrm{N}}^{\mathrm{N}}c_{k}e^{ikx}$, we define the formal limit of the partial sums
    \begin{center}
        $\displaystyle \mathfrak{F}[f](x):=\underset{n\to\infty}{\lim}\mathfrak{F}[f](x)=\overset{\infty}{\underset{k=-\infty}{\sum}}c_{k}e^{ikx}$
    \end{center}
    as the \textit{Fourier series} of $f$.
\end{definition}

\begin{theorem}
    Let $f:\mathbb{R}\to\mathbb{C}$ be a periodic function that is piecewise continuously differentiable. Then the Fourier series of $f$ converges uniformly to $f$.
\end{theorem}
\begin{proof}
    Can be found in~\citep{forster2011analysis}(Chapter 23, Theorem 3).
\end{proof}

\subsection{Plane Curves}
In this subsection, we consider curves in the Euclidean plane. Here, we will introduce briefly the language of the differential geometry of curves.

\begin{definition}
    Let $\mathrm{I}\subseteq\mathbb{R}$ be an interval. A \textit{plane parameterized curve} is a continuously differential map $c:\mathrm{I}\to\mathbb{R}^{2}$. A plane parametrized curve is called \textit{regular}, if for all $t\in\mathrm{I}$ the derivative of $c$, denoted by $\dot{c}=(c'_{1},c'_{2})$, satisfies $\dot{c}(t)\neq0$.
\end{definition} 

\begin{note}
    From now on, all our curves will be regularly parameterized curves.
\end{note}

\begin{definition}
    A curve $c:\mathbb{R}\to\mathbb{R}^{2}$ is called
    \begin{itemize}
        \item periodic with $\mathrm{L}$, if it holds that
        \begin{enumerate}
            \item $\exists\mathrm{I}>0: c(t+\mathrm{L})=c(t)\;\forall t\in\mathbb{R}$, and
            \item $\forall\mathrm{L}'$ with $c(t+\mathrm{L}')=c(t)\;\forall t\in\mathbb{R}$: $\mathrm{L}\leq\mathrm{L}'$.
        \end{enumerate}
        \item closed if it has a periodic regular parametrization
        \item simply closed if it has a periodic regular parametrization $c$ with period $\mathrm{L}$ so that $c|_{[0,\mathrm{L})}$ is injective.
    \end{itemize}
\end{definition}

\begin{remark}
    The definition 1.2.16 of a period above is a special case of 1.2.11. Contrary to defition 1.2.11, we require that the period $\mathrm{L}$ is the smallest possible number with the needed properties. Later this will be important because we want to know at which time the curve finishes one round around the domain. Furthermore, we need a boundary curve of a domain and, if we have a curve that is not simply close, our enclosed set is not connected.
\end{remark}

\subsection{Length and Area}
In this subsection we will show the relation between the parameterization of a curve and the enclosed area. First we, will introduce a few properties on the length of a curve that can be proved with simple computation.

\begin{definition}
    A unit speed curve is a regular curve $c:\mathrm{I}\to\mathbb{R}^2$ satisfying $||\dot{c}(t)||=1\;\;\;\forall t\in\mathrm{I}$, where $||\cdot||$ is the Euclidean norm.
\end{definition}

\begin{proposition}
    For all regualr curves $c$, there exists a transformation of parameter $\varphi$ so that the reparameterization $c\circ\varphi$ is a unit speed curve.
\end{proposition}

\begin{definition}
    Let $c:[a,b]\to\mathbb{R}^2$ be a curve. Then $\mathrm{L}[c]:=\int_{a}^{b}||\dot{c}(t)||\,dt$ is called the length of c.
\end{definition}

\begin{lemma}
    The length of a curve is invariant under reparameterization.
\end{lemma}

\begin{remark}
    Before we prove the Isoperimetric Inequality we will show a way to compute the area of a domain using the parametrization of the boundary curve.
\end{remark}

\begin{lemma}
    let $\mathrm{G}\subseteq\mathbb{R}^{2}$ be a bounded domain such that the boundary is a simply closed curve with parameterization $c(t)=(x(t),y(t))^{\mathrm{T}}$ and period $\mathrm{L}$, Then
    \begin{center}
        $\mathrm{A}[\mathrm{G}]=-\int_0^{\mathrm{L}} \dot{x}(t) y(t) d t=\int_0^{\mathrm{L}} x(t) \dot{y}(t) d t=\frac{1}{2} \int_0^{\mathrm{L}}(x(t) \dot{y}(t)-\dot{x}(t) y(t)) d t .$
    \end{center}    
\end{lemma}
\begin{proof}
    Let $c$ be the curve mentioned above. Without loss of generality, assume that $c$ is a unit speed curve and is positively oriented. Let $n(t)$ be the inner unit normal of $c(t)$ and define $i d_{\mathbb{R}^2}: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ with $i d_{\mathbb{R}^2}(x, y)=(x, y)$. Using Gauss theorem and the fact that the curve is a unit speed curve, we get
    $\int_{\mathrm{G}}\left(\frac{\partial\left(i d_{\mathbb{R}^2}\right)^1}{\partial x}+\frac{\partial\left(i d_{\mathbb{R}^2}\right)^2}{\partial y}\right) d x d y=\int_{\mathrm{G}} \operatorname{div} i d_{\mathbb{R}^2} d x d y=-\int_0^{\mathrm{L}}\left\langle i d_{\mathbb{R}^2}(c(t)), n(c(t))\right\rangle d t .$

    First look at the left side of this equation
    $\int_{\mathrm{G}}\left(\frac{\partial\left(i d_{\mathbb{R}^2}\right)^1}{\partial x}+\frac{\partial\left(i d_{\mathbb{R}^2}\right)^2}{\partial y}\right) d x d y=\int_{\mathrm{G}}\left(\frac{\partial x}{\partial x}+\frac{\partial y}{\partial y}\right) d x d y=2 \int_{\mathrm{G}} d x d y=2 \mathrm{~A}[\mathrm{G}] .$

    For the right side, we compute
    $\begin{aligned}
    -\int_0^{\mathrm{L}}\left\langle i d_{\mathbb{R}^2}(c(t)), n(c(t))\right\rangle d t & =-\int_0^{\mathrm{L}}(-x(t) \dot{y}(t)+\dot{x}(t) y(t)) d t \\
    & =\int_0^{\mathrm{L}}(x(t) \dot{y}(t)-\dot{x}(t) y(t)) d t .
    \end{aligned}$

    Putting both sides together, we get
    $2 \mathrm{~A}[\mathrm{G}]=\int_0^{\mathrm{L}}(x(t) \dot{y}(t)-\dot{x}(t) y(t)) d t \Leftrightarrow \mathrm{A}[\mathrm{G}]=\frac{1}{2} \int_0^{\mathrm{L}}(x(t) \dot{y}(t)-\dot{x}(t) y(t)) d t .$

    Using partial integration, it follows
    $\int_0^{\mathrm{L}} x(t) \dot{y}(t) d t=\underbrace{[x(t) y(t)]_0^{\mathrm{L}}}_{=0}-\int_0^{\mathrm{L}} \dot{x}(t) y(t) d t=-\int_0^{\mathrm{L}} \dot{x}(t) y(t) d t .$
\end{proof}

\subsection{Basics in Convex Geometry}
You may be wondering why we would study convex geometry but this is the necessary language and notation, which will be used in the following sections. Convex geometry will give us a way to describe objects and sets in Euclidean space; We consider convex, compact sets in $\mathbb{R}^n$ and their properties (areas, volumes, etc). The term convex is used to refere to a shape that has a curve or a protuding suface. In other words, all the lines across the outline are straight and they point outwards. Examples of convex polygons are signboard, a football, etc. The complement of convex is concave, where the shape curves inwards and no protuding surface at some point. For example the inside of a bowl. A clear definition of when a set is convex is given below. 

As our goal is to maximize, get the largest area, it is quite clear on why we choose convex curves over concave curves. When studying the polygons, it is easy to think that all convex polygons are regular as all regular polygons are convex, but that is not the case.
\newline

\begin{definition}
	A set $A\subseteq\mathbb{R}^n$ is called $convex$ if all $x,y\in A$ satisfy $(1-\lambda)x+\lambda y\in A$, $\forall\lambda\in[0,1]$.
\end{definition}

\begin{remark}
	Intersections of convex sets, and for affine maps the pre-image and the image of convex sets are also convex. Let $A, B \subset\mathbb{R}^n$ be convex and $\lambda\in\mathbb{R}$. Then
	\begin{center}
		$\lambda B=\{x\in\mathbb{R}^n;\exists b\in B$ with $x=\lambda\dot b\}$, and
	
		$\lambda+B=\{x\in\mathbb{R}^n;\exists a\in A, b\in B$ with $x=a+b\}$
	\end{center}
	are also convex.
\end{remark}

\begin{definition}
	Let $A\subseteq\mathbb{R}^n$ be non-empty, compact and convex. Then $A$ is called $convex$ $body$. The set of all convex bodies of $\mathbb{R}^n$ is denoted by $\mathscr{K}^n$ and the set of all convex bodies in $\mathbb{R}^n$ with non-empty interior is denoted by $\mathscr{K}_{0}^{n}$.
\end{definition}

\begin{definition}
	\begin{itemize}
		\item Define $\bar{R}=\mathbb{R}\cup\{ \infty,-\infty\}$,
		\item A function $f:\mathbb{R}^n\to\bar{\mathbb{R}}$ is called $proper$ if it satisfies $\{f=-\infty\}=\emptyset$ and $\{f=\infty\}\neq\mathbb{R}^n$,
		\item A proper function $f:\mathbb{R}^n\to\bar{\mathbb{R}}$ is called $convex$ if it satisfies 
		\begin{center}
			$\displaystyle f((1-\lambda)x+\lambda y)\leq(1-\lambda)f(x)+\lambda f(y)$
		\end{center}
		for all $x, y\in\mathbb{R}^n$ and $0\leq\lambda\leq1$,
		\item A function $f:D\to\bar{\mathbb{R}}$ with $D\subseteq\mathbb{R}^n$ is called convex if its expansion on $\mathbb{R}^n$,
		\begin{center}
			\begin{equation*}
				  \tilde{f}(x):=\begin{cases}
				    	f(x), & \text{for $x\in D$}.\\
				   	 \infty, & \text{otherwise}.
				  \end{cases}
			\end{equation*}
		\end{center}
		is convex,
		\item A function $f$ is $concave$ if $-f$ is convex.
	\end{itemize}
\end{definition}
\begin{figure}[h]
    \begin{center}   
        \includegraphics[width=80mm]{ConcaveFunction}
        \caption{The blue, green and red graphs are associated to convex functions but the pink graph is associated to a concave.}
    \end{center}
\end{figure}

\section{$n$-Dimensional Preliminaries}
The next couple of subsections will help us understand what goes on behind the $n$-Dimesional proofs. Looking at useful tools to help in the proof, we then look at the support function, and finally focus on Hausdorff metric

\begin{definition}
    A hyperplane is a set described by a single scalar product equality. Precisely, a hyperplane in $\mathrm{R}^{n}$ is a set of the form
    \begin{center}
        $\displaystyle \mathrm{H}=\{x:a^{\mathrm{T}}x=b\}$,
    \end{center}
    where $\displaystyle a\in\mathrm{R}^{n}$, $\displaystyle a\neq0$, and $\displaystyle b\in\mathrm{R}$ are given.~\citep{tsai2023applications}
\end{definition}

When $\displaystyle b=0$, the hyperplane is simply the set of points that are orthogonal to $a$; when $\displaystyle b\neq0$, the hyperplane is a translation, along direction $a$, of that set.

If $\displaystyle x_{0}\in\mathrm{H}$, then for any other element $\displaystyle x\in\mathrm{H}$, we have
\begin{center}
    $\displaystyle b=a^{\mathrm{T}x_{0}}=a^{\mathrm{T}x}$.
\end{center}

Hence, the hyperplane can be characterized as the set of vectors x such that $\displaystyle x-x_{0}$ is orthogonal to $a$:
\begin{center}
    $\displaystyle \mathrm{H}=\{x:a^{\mathrm{T}}(x-x_{0})=b\}$.
\end{center}
Hyperplanes are very useful because they allows to separate the whole space in two regions, giving us a seperated set. Hence an illustrative figure is given:
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=130mm]{hyperplane}
        \caption{Left is in $2$-Dimensions; Right is in $3$-Dimensions; both showing a seperation of the space}
    \end{center}
\end{figure}\leavevmode

Integration and differentiation are related, as stated in the fundamental theorem of calculus. And gives us a way to evaluate definite integrals without using Riemann sums or calculating areas. 

In the first part of the theorem, it statse that a definite integral of a function can be evaluated by computing the indefinite integral of that function. The sectnd part of the theorem, it mentions that the differentiation is the inverse of integration, and vice versa. We will not give the proof.

\begin{theorem} (Fundamental Theorem of Calculus)
    \begin{enumerate}
        \item (Integrals and Antiderivative) Suppose $\mathrm{F}$ is a function such that $\mathrm{F}'(x)=f(x)$ exists and is continuous on $[a,b]$. Then
        \begin{center}
            $\displaystyle \int_{a}^{b}f(x)\,dx=\mathrm{F}(b)-\mathrm{F}(a)$.
        \end{center}

        \item (The Evaluation Theorem) Suppose that $f$ is continuous on $[a,b]$ and $\displaystyle \mathrm{F}(x)=\int_{a}^{x}f(t)\,dt$. Then $\mathrm{F}$ is differentiable on $(a,b)$ and
        \begin{center}
            $\displaystyle \mathrm{F}'(x)=f(x)$.
        \end{center}
    \end{enumerate}
\end{theorem}

\begin{remark}
    We have a defined function, $\mathrm{F}(x)$, as the definite integral of another function, $f(t)$, from the point $a$ to the point $x$. To clarify on why it is $\mathrm{F}(x)$, when we have the definite integral, but the function $\mathrm{F}(x)$ returns a number (the value of the definite integral) for each value of $x$.
\end{remark}

\begin{remark}
    We have some key implications of this theorem:
    \begin{itemize}
        \item Establishes relationship between integration and differentiation,
        \item Guarantees existence of antiderivative for any integrable function,
        \item Specifically ensures any continuous function has an antiderivative.
    \end{itemize}
\end{remark}

Application of this theorem is rather simple once you have approximated areas using the sum of n rectangles. Just computing the antiderivative at the beginning and ending points of the interval yields an almost unbelievably easy way to get the area of a curved region.

\begin{theorem} (Fubini's Theorem)
    If $f(x,y)$ is continuous on $\displaystyle \mathrm{R}=[a,b]\times[c,d]$ then,
    \begin{center}
        $\displaystyle \underset{\mathrm{R}}{\iint}f(x,y)\,d\mathrm{A}=\int_{a}^{b}\int_{c}^{d}f(x,y)\,dydx=\int_{c}^{b}\int_{a}^{b}f(x,y)\,dxdy$
    \end{center}
    These integrals are called iterated integrals.
\end{theorem}

\begin{note}
    Note that there are two ways to compute a double integral over a rectangle. It is crucial to understand that the limits of the inner integral and the differential variable inside correlate, just as the limits and the outside differential do.
\end{note}

\begin{theorem} (Inverse Function Theorem)
    Let $f$ be a continuous strictly increasing function on an interval $J=[a,b]$ of positive length, such that $f'(x)>0$ for all $x\in interior(\mathrm{J})$. Let $\mathrm{I}$ be the image of $\mathrm{J}$ and let
    \begin{center}
        $\displaystyle g:\mathrm{I}\to\mathrm{J}$
    \end{center}
    be the inverse function for $f$. Then $g$ is differentiable on the interior of $\mathrm{I}$ and
    \begin{center}
        $\displaystyle g'(s)=\frac{1}{f'(g(s))}$ for all $s\in interior(\mathrm{I})$.
    \end{center}
\end{theorem}

\subsection{The Support Function}
The following section introduces the support function, which can be used to ascertain the "height" of a convex body. The support function is a convex function on $\mathbb{R}$ and is compatible with many geometric opetions such as scaling, translation, rotation and importantly the \textbf{Minkowski addition}. These characteristics make the support function one of the most important foundational ideas in convex geometry.~\citep{gehring2019isoperimetric}

\begin{definition}
    Let $K\subseteq\mathbb{R}^n$ be non-empty, convex and closed. The $support$ $function$ $h(K,\cdot\space)=h_k$ is defined by
    \begin{center}
        $h(K,u):=\sup\{\langle x,u\rangle;x\in K\}$ for $u\in\mathbb{R}^n$
    \end{center}
    Furthermore we define for $u\in dom\,h(K,\cdot)\backslash\{0\}$
    \begin{center}
        $H(K,u):=\{x\in\mathbb{R}^n;\langle x,u\rangle=h(K,u)\}$ a supporting plane of K,
        
        $H^{-}:=\{x\in\mathbb{R}^n;\langle x,u\rangle\leq h(K,u)\}$ a support half space of K, and 
        
        $F(K,u):=H(K,u)\cap K$ a support domain of K.
    \end{center}
\end{definition}

\begin{remark}
    The suuport function for $u\in\mathbb{S}^{n-1}\cap dom\,h(K,\cdot)$ can be viewed as the distance of the supporting plane at K with outer unit normal to the origin.
\end{remark}

\begin{remark}
    For $B^{n}$ and $u\in\mathbb{S}^{n-1}$ the support function can be computed easily. For arbirary $x\in B^{n}$ and $u\in\mathbb{S}^{n-1}$ Cauch-xSwarz gives us
    \begin{center}
        $|\langle x,u\rangle|\leq||u||\:||x||\leq1$
    \end{center}
    The support function is equal 1 on $B^{n}$ since the maximum is also 1.
\end{remark}

\begin{remark}
    The support funtion has the following properties:
    \begin{enumerate}
        \item $h_{k}\leq h_{L}$ if and only if $K\subseteq L$,
        \item $h(\{z\},u)=\langle x,y\rangle$ for $z,u\in\mathbb{R}^{n}$,
        \item $h(K+t,u)=h(K,u)+\langle t,u\rangle$ for $t,u\in\mathbb{R}^{n}$,
        \item $h(\lambda K, u)=\lambda h(K,u)=h(K,\lambda u)$ for $\lambda\in\mathbb{R}_{0}^{+}$, $u\in\mathbb{R}^{n}$,
        \item $h(-K,u)=h(K,-u)$ for $u\in\mathbb{R}^{n}$,
        \item $h(K,u_{1}+u_{2})\leq h(K,u_{1})+h(K,u_{2})$ for $u_{1},u_{2}\in\mathbb{R}^{n}$,
        \item $h(K,\cdot)=: h_{k}$ is convex.
    \end{enumerate}
\end{remark}

\begin{lemma}
    Let $K,L\in\mathscr{K}^{n}$, then$h(K+L,u)=h(K,u)+h(L,u)$.
\end{lemma}
\begin{proof}
    Let $u\in\mathbb{R}^{n}\backslash\{0\}$.

    First, we show $h(K+L,u)\geq h(K,u)+h(L,u)$. Since $K$ and $L$ are compact, the supremum of the support function is attained. Thus, there exists $x\in K$ and $y\in L$ such that $h(L,u)=\langle y,u\rangle$ and $h(K,u)=\langle x,u\rangle$.

    Then we have
    \begin{center}
        $h(K,u)+h(L,u)=\langle y,u\rangle+\langle x,u\rangle=\langle x+y,u\rangle\leq h(K+L,u)$.
    \end{center}

    Secondly, we want to show $h(K+L,u)\leq h(K,u)+h(L,u)$. Let $z\in K+L$ so that $H(K+L,u)=\langle u,z\rangle$. Then there exists $x\in K$ and $y\in L$ such that $z=x+y$. It follows
    \begin{center}
        $h(K+L,u)=\langle z,u\rangle=\langle x+y,u\rangle=\langle x,u\rangle+\langle y,u\rangle\leq h(K,u)+h(L,u)$.
    \end{center}
    Both inequalities are shown and so the claim follows.
\end{proof}

\subsection{The Hausdorff Metric}
To prove the continuity of the volume functional and of the support function with respect to convex bodies, we need a metric on the set of convex bodies. This metric will be introduced in the following subsection.~\citep{gehring2019isoperimetric}

\begin{definition}
    For $K,L\in K^{n}$, define Hausdorff distance or Hausedorff metric by
    \begin{center}
        $\delta(K,L):=\min\{\lambda\geq;K\subseteq L+\lambda B^{n},L\subseteq K+\lambda B^{n}\}$.
    \end{center}
\end{definition}

\begin{remark}
    The Hausdorff distance (Hausdorff metric) on the set of convex bodies. This follows directly from the properties of minima and from the convexity of $K$.
\end{remark}

\begin{lemma}
    Let $K,L\in\mathscr{K}^{n}$, $K,L\subseteq RB^{n}$, where $R>0$, and $u,v\in\mathbb{R}^{n}$. Then
    \begin{center}
        $|h(K,u)-h(L,v)|\leq R|u-v|+\max\{|u|,|v|\}\delta(K,L)$.
    \end{center}
\end{lemma}
\begin{proof}
    Proof can be found in~\citep{schneider2014convex} (section 1.8, Lemma 1.8.12).
\end{proof}

\begin{remark}
    Lemma above proves the local Lipschitz continuity of the support function in both arguments.
\end{remark}

\begin{theorem}
    Let $K,L\in\mathscr{K}^{n}$, then
    \begin{center}
        $\delta(K,L)=\underset{u\in\mathbb{S}^{n-1}}{\sup}|h(K,u)-h(L,u)|=:||\bar{h}_{K}-\bar{h}_{L}||$,
    \end{center}
    where $\displaystyle \bar{h}_{K}=h_{k}|_{\mathbb{S}^{n-1}}$.
\end{theorem}
\begin{proof}
    Let $\delta(K,L)\leq\alpha$. This implies $K\subseteq L+\alpha B^{n}$. For $u\in\mathbb{S}^{n-1}$, it follows 
    \begin{center}
        $h(K,u)\leq h(L+\alpha B^{n},u)=h(L,u)+\alpha h(B^{n},u)=h(L,u)+\alpha$
    \end{center}
    After switching $K$ and $L$, we can conclude for $u\in\mathbb{S}^{n-1}$ that
    \begin{center}
        $|h(K,u)-h(L,u)|\leq\alpha$
    \end{center}
    This implies $||\bar{h}_{K}-\bar{h}_{L}||\leq\delta(K,L)$. Using a similar argument one can show the other estimation.
\end{proof}

\begin{lemma}
    Let $K_{1},K_{2}\in\mathscr{K}^{n}$ and $K_{2}\subseteq\mathring{K}_{1}$. Then there exists $\eta>0$ such that for all $K\in\mathscr{K}^{n}$ with $\delta(K,K_{1})<\eta$, $K_{2}\subseteq K$ holds.
\end{lemma}
\begin{proof}
    Can be found in~\citep{schneider2014convex} (Section 1.8, Lemma 1.8.18)
\end{proof}

%-------------------------------------------------------------------------------------

\chapter{Multiple Proofs Concerning the Isoperimetric Property}
This is possibly may be one of the oldest problem in differential geometry. With that it comes with multiple mathematicians trying to prove the problem and or simplify the problem. The first considered real and rigorous proof was by Jakob Steiner however it had an apparent flaw, later indicated by K. Weierstrass. That it only proved the existence. In fact the isoperimetric problem was only a corollary of a theory developed by Weierstrass to handle problems of maximizing or minimizing certain integrals, this theory is called calculus of variations. 

More direct proofs were discovered later. We will mainly look at J.Steiner's proof, E.Schmidt's proof, and Fourier analysis {\&} differential geometry approach to the proof but the other proofs in this section are mainly here to give additional insight on how to think about this problem. 

The seven proofs were done by Jakob Steiner, Karl Weierstrass, Erhard Schmidt, Vladimir Boltjanski, Richard Demar, Alfred D. Garvin, David Singmaster and D.J.Souppouris, and Gary Lawlor. This section is mostly following from Kimberly Holman as her Masters Thesis~\citep{holman2022isoperimetric}.
\begin{itemize}
    \item An overview of Steiner's isoperimetric evidence was given by Vladimir Boltjanski's work~\citep{boltjansky1985geometry}. It first demonstrates the need for the shape's largest area to be convexv. 
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=70mm]{Boltjanski1}
            \caption{Solution must be convex}
        \end{center}
    \end{figure}
    \begin{enumerate}
        \item Towards a general shape. He makes a "cross-cut" that divides the boundary into two equal lengths. If every cross-cut has equal area then the shape is extremal. Otherwise, omit the side with smaller area and reflect the larger area across the cross-cut. We may continue in this way until every cross-cut. We may continue in this way until every cross-cut has equal area.
        \item Now  he takes a fixed cross-cut, $a$, $b$, and any boundary points distinct from $a$ and $b$, $c$, and demonstrates that the extremal must have $\angle acb=90^{\circ}$. If the angle is anything else, install a hinge and rotate about $c$ until the angle mesaure of $acb$ is $90^{\circ}$.
        \item The reflect over the cross-cut to achieve a shape with greater area and same perimeter.
    \end{enumerate}

    \item Richard Demar begins with an indirect proof to show that the extremal is convex, then proceeds with a trivial example that the square is not extremal~\citep{demar1975simple}. While the square example is trivial and can easily be proved computationally, the trick Demar uses here will be used in subsequent proofs. is that we start with a square, then we would cut a piece off, then glue it to another place, and hence our shape is nonconvex. An illustration is shown below.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=120mm]{RichardDemar}
            \caption{Left shows square; Middle we replace; Right shows our shape is nonconvex}
        \end{center}
    \end{figure}\leavevmode
    \newline
    We want to now round off those sharp corners on the triangles in the figures above, and very naturally leads us to the following theorem.
    \begin{theorem}
        Let $\mathrm{T}$ be a given triangular region with perimeter $\mathrm{P}$ and with a circumference of the inscribed circle equal to $c$. Let $p$ be a number such that $c\leq p\leq\mathrm{P}$. Then among all regions contained in $\mathrm{T}$ and having perimeter $p$, the region $\mathrm{R}$ of maximum area has boundary $\gamma$ consisting of three circular arcs of all the same radius, each tangent to two adjacent sides of the boundary of $\mathrm{T}$, together with the three segments of sides of $\mathrm{T}$ between endpoints of these arcs.
    \end{theorem}
    Demar indicates that $\gamma$ contains at least one circular arc through citing the previous theorem (Proposition 4.1.3). Demar uses an indirect proof. He demonstrates that $\gamma$ comprises three circular arcs since none of the vertices of $\mathrm{T}$ can coincide with $\gamma$. While length and area are preserved, a nonconvex region is produced by replacing a tiny sector of the arc near $\mathrm{B}$ and a small corner piece at $\mathrm{C}$.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=60mm]{Demar1}
            \caption{Replacing a small corner with a small sector, and vice-versa}
        \end{center}
    \end{figure}\leavevmode
    By using indirect proof again, Demar shows that the radii of each of the three arcs are identical. So when the extremal is assumed to have different radii, using replacement of small sectors, a nonconvex shape is achieved, implying that the radii are equal.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=60mm]{Demar2}
            \caption{Replace two small sectors with each other}
        \end{center}
    \end{figure}\leavevmode
    Lastly to show that each of the circular arcs of $\gamma$ is tangent to $\mathrm{T}$, and indirect approach is used. Reflections and replacements yield a $\gamma'$ which is not convex, hence, the arcs are tangent to $\mathrm{T}$.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=60mm]{Demar3}
            \caption{Drawing a tangent to the arc, segments on AB, and triangles from AB to the point of tangency resulting in a contradiction such that the point of tangency touches BC}
        \end{center}
    \end{figure}
    \newpage
    If we zoom into one of the corners where the arc is reflected and replaced, the figure below (Figure 3.6) helps illustrate.
    \begin{figure}[hbt!]
        \centering
        \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=63mm]{Demar4} % first figure itself
            \caption{a zoomed in view of where the arc is reflected and replaced}
        \end{minipage}\hfill
        \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=45mm]{Demar5} % second figure itself
            \caption{The maximum area solution}
        \end{minipage}
    \end{figure}

    \item Expanding on the work of Demar, Alfred D. Garvin, physical experiments are performed to prove the statements. 
    \begin{enumerate}
        \item Initially, a triangular reservoir is filled with liquid mercury in a slow and controlled manner. The intention is for the mercury to adopt an isoperimetrically optimal configuration, and indeed, it successfully achieves this desired state. However, due to the meniscus effect of the mercury, the endpoints of the arcs become slightly distorted.
        First, a confined triangular reservoir is slowly and gradually filled with liquid mercury and eventually assuming an isoperimetrically optimal shape.

        \item Secondly, the reservoir is partially filled with water, followed by a gradual pour of viscous oil is poured onto the surface of water. It is expected that the oil will adopt an isoperimetrically optimal form, and indeed, it does so. Nevertheless, the meniscus effect of the oil once again leads to a slight distortion of the endpoints of the arcs. 

        \item Moving on to the third experiment, an asymmetrical triangular wooden fence and a sturdy paper fence with a perimeter smaller than that of the triangle are employed. BB pellets are poured into the paper fence, with the expectation that it will adopt an isoperimetrically optimal shape. Which it does.

        \item All three experiments yield a consistent description of the isoperimetrically optimal shape. Specifically, the arcs exhibit equal radii, equal chords, and equal lengths.
    \end{enumerate}~\citep{garvin1975note}
    
    \item David Singmaster and D.J. Souppouris looked at the ratio of area to perimeter, A/P. Where it is examined to find the set which produces the greatest number. Through the application of advanced calculus and analysis, the maximum ratio of A/P serves as an indicator of the circularity of the given set.~\citep{singmaster1978problem}
    \newpage
    \item Gary Lawlor presented a new proof of the planar isoperimetric property. His method is of slicing and covering argument, and calls for strategically dividing the circle as well as another, arbitrary region of equal perimeter, into tiny pieces. 
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=40mm]{Lawlor1}
            \caption{Slicing the circle}
        \end{center}
    \end{figure}\leavevmode
    \newline
    Each pieces from non-circle region contains the same length of the region’s boundary and has less area than the piece of the circle containing the same length of the circle’s boundary. But the two main ideas that Lawlor employs goes as: the local maximization proof is based on the observation that when considering triangles with a common base and opposite angle, the one with the greatest area is always an isosceles triangle. 
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=40mm]{Lawlor3}
            \caption{Among triangles with fixed base and fixed opposite angle, the one with greatest area is isosceles}
        \end{center}
    \end{figure}\leavevmode
    \newline
    And then in order to connect local and global perspectives, it is necessary to develop a method for tiling a specific region with triangles. These triangles should be oriented in such a way that their shorter base aligns with the boundary of the region, while also maintaining a constant fixed angle opposite to this base.
    \newline
    And constructing the covering triangles. Let $\mathrm{S}_{1}$ be the curve of length $\pi/2$, which is the portion of $\mathrm{S}$ lying in the first quadrant
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=100mm]{Lawlor2}
            \caption{}
        \end{center}
    \end{figure}\leavevmode
    \newline
    An advantage of this proof is, as it is comparative, it does not require a proof of existence of an optimum solution.~\citep{lawlor1998new}
\end{itemize}

\chapter{2-Dimensional Case ($\mathbb{R}^2$)}
\section{Jakob Steiner}
Firstly, we will look at this proposition. Isosceles triangle has the smallest leg-sum compared to trianges of the same baselien and either height or area, and vice-versa. 

\begin{enumerate}
    \item Given an uneqal triangle, we want to maximise area on a triangle with the same baseline. 

    \item We make the other two sides, not the baseline, equal. The result is a triangle witha smaller leg-sum, and therefor a smaller perimeter, containigng the same area.

    \item Now we can expand on the previous principle to demonstrate that any parallel trapezoid with unequal angles on one baseline may be transformed into another of the same area and baselines; Moreover, the new parallel trapezoid will have symmetry along the axis formed by the baseline midpoints and a smaller sum of side lengths. 
\end{enumerate}

We will show this proof in the next section.
\newline
\newline

\begin{lemma} 
    Among all triangles ABC with same perimeter and same base AB, which has bigger area?
\end{lemma}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=88mm]{lemma3}
        \caption{labeled figure to lemma 4.1.1, helps with the proof}
    \end{center}
\end{figure}\leavevmode
Let us note that the third vertex $\mathrm{C}$, is located on the ellipse
\begin{proof} 
    Let $|\mathrm{BC}|=a$, $|\mathrm{AC}|=b$, $|\mathrm{AB}|=c$ be the side of $\triangle ABC$, and let $|\mathrm{OP}|=u$ and $|\mathrm{OQ}|=v$ be the semi-major and semi-minor axis of the ellipse, respectively.

    Since the ellipse is symmetric, we can consider only the I quadrant of the ellipse (non-shaded area of Figure 4.1).

    Following the cosine rule $a^{2}=b^{2}+b^{2}-2bc\cos{\alpha}$,
    \begin{center}
        $\displaystyle a^{2}=b^{2}+c^{2}-2bc\cos{\alpha}$,

        $\displaystyle b^{2}=a^{2}+b^{2}-2ac\cos{\beta}$,

        $\displaystyle 2(b^{2}-a^{2})=2bc\cos{\alpha}-2ac\cos{\beta}$,

        $\displaystyle b-a=\frac{c}{a+b}(b\cos{\alpha}-a\cos{\beta})$

        $\displaystyle =\frac{c}{a+b}(|\mathrm{AH}|-|\mathrm{BH}|)$

        $\displaystyle =\frac{2c}{a+b}|\mathrm{OH}|$

        $\displaystyle =\frac{2c}{a+b}x$

        Since $\displaystyle \frac{2c}{a+b}=const$, $\displaystyle \;b-a\sim x$.
    \end{center}
    Expression for the point $\mathrm{C}=(x,y)$ on the ellipic arc $\mathrm{PQ}$ (red arc on figure 4.1) in terms of parameter $\displaystyle \theta\in(0,\frac{\pi}{2})$ gives
    \begin{center}
        $\displaystyle x(\theta)=u\cos{\theta}$,

        $\displaystyle y(\theta)=v\sin{\theta}$,

        $\displaystyle x'(\theta)=-u\sin{\theta}<0\;\;\;\;\;\forall\theta\in(0,\frac{\pi}{2})$,

        $\displaystyle y'(\theta)=v\cos{\theta}>0\;\;\;\;\;\forall\theta\in(0,\frac{\pi}{2})$,
    \end{center}
    so, smaller $x$ is equivalent to biggy and the smaller side difference, the bigger the area.
\end{proof}

\begin{lemma}
    For a given perimeter the equilateral triangle has the biggest area of all the triangles. 
\end{lemma}
\begin{proof} 
    Using Heron's formula for the are ofa triangle to help here
    \begin{center}
        $\displaystyle \mathrm{Area}=\mathrm{A}=\sqrt{s(s-a)(s-b)(s-c)}$
    \end{center}
    where is is the semi-perimeter
    \begin{center}
        $\displaystyle s=\frac{a+b+c}{2}$
    \end{center}
    To find the conditions for the macimum area we want to comput derivatives with respect to $a$, $b$ and $c$, but since they are not independent variables, we first substitue the semi-perimeter equation in to he area equation, to remove $c$
    \begin{center}
        $\displaystyle c=2s-a-b$

        $\displaystyle \therefore\mathrm{A}=\sqrt{s(s-a)(s-b)(a+b-s)}$
    \end{center}
    Setting the derivative with respect to $a$ to $0$:
    \begin{center}
        $\displaystyle \frac{d\mathrm{A}}{da}=\frac{s(s-b)(2s-2a-b)}{2\mathrm{A}}=0$

        $\displaystyle \implies 2s-2a-b=0$
    \end{center}
    Similarly, setting the derivative with respect to $b$ to $0$ yields
    \begin{center}
        $2s-2b-a=0$
    \end{center}
    Solving simultaneously gives
    \begin{center}
        $\displaystyle a=b=\frac{2s}{3}$
    \end{center}
    by substituting $\displaystyle c=\frac{2s}{3}$ back, we get
    \begin{center}
        $\displaystyle a=b=c$ and the triangle is equilateral.
    \end{center}
\end{proof}

\begin{proposition}
    Among all regular polygons with fixed perimeter, an increase in the number of sides results in a larger area.  
\end{proposition}
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=140mm]{isofig11}
        \caption{representating increasing number of sides gives larger area (i)triangle, (ii)square, (iii)pentagon, (iv)carries on}
    \end{center}
\end{figure}\leavevmode
\begin{remark}
    We will need to use Heron's formula \textbf{and} the AM-GM inequality for the proof of proposition 4.1.3.
\end{remark}
\begin{proof} 
    Suppose that $n$ is the number of sides of a regular polygon.

    \textbf{Triangle Case, $n=3$:} We start with Heron's formula
    \begin{center}
        $\displaystyle \mathrm{Area}=\mathrm{A}=\sqrt{s(s-a)(s-b)(s-c)}$ where $\displaystyle s=\frac{\mathrm{L}}{2}$ is a constant
    \end{center}
    Applying the AM-GM Inequality
    \begin{center}
        $\displaystyle (\sqrt[3]{(s-a)(s-b)(s-c)})^{3}\leq\Big(\frac{s-a+s-b+s-c}{3}\Big)^{3}$

        $\displaystyle =\Big(\frac{s}{3}\Big)=\Big(\frac{\mathrm{L}}{6}\Big)^{3}$
    \end{center}
    so for the area we have
    \begin{center}
        $\displaystyle \mathrm{Area}=\sqrt{s}\sqrt{(s-a)(s-b)(s-c)}\leq\sqrt{\frac{\mathrm{L}^{3}}{6^3}}\times\sqrt{\frac{\mathrm{L}}{3}}$

        $\displaystyle =\sqrt{\frac{\mathrm{L}^{4}}{2\times2^{3}\times3^{3}}}=\frac{\mathrm{L}^{2}}{4\times3\sqrt{3}}=\frac{\mathrm{L}^{2}}{12\sqrt{3}}$
    \end{center}
    hence we get $\displaystyle s-a=s-b=s-c\;\therefore$ regular triangle

    \textbf{Square Case, $n=4$:} If we lable Figure 2.2 (ii) sides with $a$ and $b$ adjacently. The area is
    \begin{center}
        $\displaystyle \mathrm{Area}=ab$ where $\displaystyle a+b=\frac{\mathrm{L}}{2}$
    \end{center}
    Applying the AM-GM Inequality again
    \begin{center}
        $\displaystyle \sqrt{ab}\leq\frac{a+b}{2}=\frac{L}{4}$
    \end{center}
    hence
    \begin{center}
        $\displaystyle \mathrm{Area}=ab\leq\Big(\frac{a+b}{2}\Big)^{2}=\frac{\mathrm{L}^{2}}{16}$
    \end{center}

    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=75mm]{isofig12}
            \caption{a labeled hexagon in a circle, showing that a circle }
        \end{center}
    \end{figure}\leavevmode
    
    Lets now move on to the main part, \textbf{$n$-gon Case:} Suppose that the angle $\displaystyle \theta=\frac{2\pi}{n}$, the length $a=\frac{\mathrm{L}}{n}$, and 
    \begin{center}
        $\displaystyle \frac{(a/2)}{h}=\tan{(\theta/2)}$

        $\displaystyle \frac{(a)}{h}=2\tan{(\theta/2)}$

        $\displaystyle h=\frac{a}{2\tan{(\pi/n)}}$
    \end{center}
    So the area is
    \begin{center}
        $\displaystyle \mathrm{Area}=\mathrm{A}=n\cdot\text{area of }\triangle\mathrm{OAB}=n\cdot\frac{a}{2}\cdot h$

        $\displaystyle n\cdot\frac{a^{2}}{4\tan{\pi/n}}=n\frac{\cdot\mathrm{L}^{2}}{4n^{2}\tan{\pi/n}}$

        $\displaystyle =\frac{\mathrm{L^{2}}}{4n\tan{(\pi/n)}}$
    \end{center}
\end{proof}

\begin{note}
    we can see that $\displaystyle \frac{\mathrm{L}^{2}}{12\sqrt{3}}<\frac{\mathrm{L}^{2}}{16}$, as dividing by $12\sqrt{3}$ gives a smaller result than dividing by $16$. Hence the square is a better choice. And that $\displaystyle 4n\tan{(\pi/n)>{16}}$.
\end{note}
\begin{problem}
    So what happens when $n$ increases to infinity (i.e. $n\to\infty$)?

    \begin{center}
        $\displaystyle \underset{n\to\infty}{\lim}\frac{\mathrm{L}^{2}}{4n\tan{(n/\pi)}}$

        $\displaystyle =\underset{n\to\infty}{\lim}\frac{\mathrm{L}^{2}\cos{(\pi/n)}}{4\pi\frac{n}{\pi}\sin{(\pi/n)}}$

        $\displaystyle =\underset{n\to\infty}{\lim}\frac{\mathrm{L}^{2}\cos{(\pi/n)}}{4\pi\frac{\sin{(\pi/n)}}{\pi/n}}$
    \end{center}
    as $\displaystyle \frac{\sin{(\pi/n)}}{\pi/n}=1$, and $\cos{\pi/n}=1$
    \begin{center}
        $\displaystyle \underset{n\to\infty}{\lim}\frac{\mathrm{L}^{2}}{4n\tan{(n/\pi)}}=\frac{\mathrm{L}^{2}\cdot1}{4\pi\cdot1}$,

        $\displaystyle =\frac{\mathrm{L}^{2}}{4\pi}$,
    \end{center}
    which gives us the area of the circle.
\end{problem}

\begin{theorem}
    If L is the perimeter and A is the area of any regular 2n-sided polygon, then 
    \begin{center}
        $L^{2}\geq8n*A*\tan{(\frac{\pi}{2n})}$.
    \end{center}
\end{theorem}

\begin{figure} [h]
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{isofig8.png} % first figure itself
        \caption{}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{isofig9.png} % second figure itself
        \caption{}
    \end{minipage}
\end{figure}

\begin{proof}
        Since its a regular polygon we could consider one of the 2n triangles its made off as shown in the figure above. 
    \begin{center}
        $\displaystyle \tan(\alpha)=\frac{(\frac{L}{4n})}{h}$
    \end{center}
        Rearranging the formula to make h the subject as well as using the fact that $\displaystyle \alpha=\frac{2\pi}{2n} \frac{1}{2}=\frac{\pi}{2n}$, we get 
    \begin{center}
        $\displaystyle h=\frac{L}{4n} \frac{1}{\tan(\frac{\pi}{2n})}$
    \end{center}
    Now for the area of the above triangle we get $\displaystyle \frac{1}{2}h*\frac{L}{2n}$
        Substituting h, we obtain
    \begin{center}
        $\displaystyle \frac{L^{2}}{16n^{2}} \frac{1}{\tan(\frac{\pi}{2n})}$
    \end{center}
        Finally, we consider the area of the whole polygon which is just 2n times of the above expression. So we have 
    \begin{center}
            $\displaystyle A=\frac{L^{2}}{8n} \frac{1}{\tan(\frac{\pi}{2n})}$
    \end{center}
        Since this is the optimal area we can be more precise and by rearranging the express we can conclude our desired expression which was $L^{2} \ge 8nA\tan(\frac{\pi}{2n})$
\end{proof}

\begin{theorem}
    Let $C$ be a simple closed curve in the plane with length $L$ and bounding a region of area $A$ . 
    Then $L^2 \leq 4\pi A$ with equality if and only if $C$ is a circle.
\end{theorem}
The circle therefore bounds the biggest area among all simple closed curves in the plane with a given length.
\subsection{J.Steiner's Proof}
The proof that I will be unpacking and taking a closer look at will be from the book (reference the book here), and is credited by them to Jakob Sternier. Packed and concise proof from~\citep{gluck2012isoperimetric}. To reiterate, the German mathematician Peter Dirichlet (1805- 1859), remarked, Steiner had made an underlying assumption not explicitly addressed in his proof, namely that a solution existed (Nahin 59~\citep{nahin2021least}). A rather helpful computer visualisation, before we start the proof, to aid in the identification that indeed the circle is an answer, and how naturally a compressed circle (ellipse) has less area than a full and complete circle.
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=120mm]{steinerproofvisualisation}
        \caption{Digitally showing area comparison of curves.}
    \end{center}
\end{figure}
\begin{proof} 
    We will begin the proof by assuming the existence of a solution. In other words, that there exists a simple closed curve $\mathrm{C}$ of a specified length L, enclosing a region with the maximum possible area.

    \textbf{Step 1:} We claim that the curve $\mathrm{C}$ must be convex, in the sense that any line segment joining two points of $\mathrm{C}$ must lie entirely in the closure of the region bouded by $\mathrm{C}$.

    We see this as follows. If $\mathrm{C}$ were not convex, then we could draw a segment $\mathrm{OP}$ between two points of $\mathrm{C}$ which lies entirely (except for its endpoints) outside of $\mathrm{C}$. Reflecting the appropriate arc of $\mathrm{C}$ between $\mathrm{O}$ and $\mathrm{P}$ in this line would produce another curve of the same length but bouding a larger area, as in the figure below.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=80mm]{steiner1}
            \caption{a labeled hexagon in a circle, showing that a circle }
        \end{center}
    \end{figure}\leavevmode
    Hence $\mathrm{C}$ must already be convex

    \textbf{Step 2:} Now choose  two points, $\mathrm{A}$ and $\mathrm{B}$, dividing our solution curve $\mathrm{C}$ into arcs of equal length.

    Then the line segment $\mathrm{AB}$ must also divide the region bounded by $\mathrm{C}$ into two parts of equal area. Otherwise, the part of greater area could be reflected in $\mathrm{AB}$ to give another curve of the same length $\mathrm{L}$ bounding a region of area greater than that bounded by $\mathrm{C}$. 

    The existence of such a pair of points is intuitively evident and will be accepted here without proof. But it seems clear why such a pair of points exists, since the pair of points are on the curve itself.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=80mm]{steiner2}
            \caption{}
        \end{center}
    \end{figure}\leavevmode\newline
    Now let $\mathrm{A}_{1}$, $\mathrm{A}_{2}$ be the areas between the diameter $\mathrm{AB}$ and $k_{1}$, $k_{2}$ respectively (so that $\mathrm{A}_{1}+\mathrm{A}_{2}$ is the area enclosed by $\mathrm{C}$) and suppose that $\mathrm{A}_{1}\geq\mathrm{A}_{2}$. Replace $k_{2}$ by the arc $k'_{2}$, obtained through reflection of $k_{1}$ with respect to the diameter $\mathrm{AB}$. The new curve $k'$, consisting of $k_{1}$ and $k'_{2}$, has the same length as $k$ but the included area is $2\mathrm{A}_{1}\geq\mathrm{A}_{1}+\mathrm{A}_{2}$, so that the area has certainly not diminished.

    It follows that half of our solution curve $\mathrm{C}$ must solve the following problem: To find the arc of length $\mathrm{L}/2$ with endpoints $\mathrm{A}$ and $\mathrm{B}$ lying anywhere on a straight line, such taht the arc together with the segment $\mathrm{AB}$ encloses a region of maximum area.

    But how do we choose where $\mathrm{A}$ and $\mathrm{B}$ to go? Since if we place $\mathrm{A}$ and $\mathrm{B}$ in a different location on the curve, $\mathrm{C}$, we can get a different distance between $\mathrm{A}$ and $\mathrm{B}$. We not always guaranteed that the two divided areas will be unbalanced. And that in the off chance that the divided areas are equal, we can just pick another two location on $\mathrm{C}$, for $\mathrm{A}$ and $\mathrm{B}$. Knowing this, another question arises: how do we make sure that the two points picked for $\mathrm{A}$ and $\mathrm{B}$, will yeild a bigger unbalance of area?

    \textbf{Step 3:} Now we'll show that the solution to this new problem is a semi-circle, so tghat the solution to the orignal problem must be a full circle, so that the solution to the original problem must be a full circle.

    Suppose the arc $\mathrm{AOB}$ shown at the left below solves this new problem It is sufficient to show that every inscribed angle, such as the one at $\mathrm{O}$, is a right angle, for this will prove that our arc is a semi-circle.
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=130mm]{steiner3}
            \caption{}
        \end{center}
    \end{figure}\leavevmode\\
    Suppose, to the contrary, that the angle at $\mathrm{O}$ is not $90^{\circ}$. Then we can view the arc as hinged at $\mathrm{O}$, and either open it or close it so as to make the angle at $\mathrm{O}$ exactly $90^{\circ}$

    This will not change the length of the arc, nor change the two shaded areas, but will increase the triangular area, and therefore increase the total area enclosed by the arc $\mathrm{AOB}$ and the line segment $\mathrm{AB}$.

    But this was already maximized by the original arc, so its inscribed angle at $\mathrm{O}$ is $90^{\circ}$ and the arc itself a semi-circle.

    Since we have figured out what angle is best to maximize the area, how about when we add the two together? We relable the curve as such;
    \begin{figure} [hbt!]
        \centering
        \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=50mm]{Steiner4} % first figure itself
            \caption{}
        \end{minipage}\hfill
        \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=50mm]{Steiner5} % second figure itself
            \caption{}
        \end{minipage}
    \end{figure}\leavevmode\newline
    In Figure 4.10, imagine that $\mathrm{ACBC}'$ is made up of four rigid rods freely jointed at the vertices $\mathrm{A}$, $\mathrm{C}$, $\mathrm{B}$, $\mathrm{C}'$. Let us pull the vertices $\mathrm{A}$, $\mathrm{B}$ (if $\phi<90^{\circ}$) or $\mathrm{C}$, $\mathrm{C}'$ (if $\phi>90^{\circ}$) apart, until the angle at $\mathrm{C}$ (and $\mathrm{C}'$) becomes a right angle. Imagine that the four shaded segments enclosed between $k'$ and the rods $\mathrm{AC}$, $\mathrm{CB}$, $\mathrm{BC}'$, $\mathrm{C}'\mathrm{A}$ are carried along during this process as shown.

    In Figure 4.11; The the new curve $k''$ has the same circumference as $k'$ (since it consists of the same four pieces of arc), but its area is larger because the shaded positions are the same but the area of the triangle $\mathrm{ABC}$ in the new position n is larger than in the original position (having the same sides $\mathrm{AC}$, $\mathrm{BC}$, but the right angle at $\mathrm{C}$.

    Thus we were able to increase the area provided that there existed a point $\mathrm{C}$ on $k_{1}$ with $\angle\mathrm{ABC}\neq90^{\circ}$. But if $\phi=90^{\circ}$ for every $\mathrm{C}$ on $k_{1}$ then $k_{1}$ is a semicricle above the diameter $\mathrm{AB}$, and $k_{1}$ is a circle. 

    However, we are not complete as we need to check if the is it fully maximized first, and to do that, we move on to step 4.

    \textbf{Step 4:} Let $\mathrm{C}$ be a smooth, regular simple closed curve in the plane, with $\mathrm{L}$ and bounding a region of area $\mathrm{A}$.

    For each $\epsilon>0$, we can inscribe in $\mathrm{C}$ a polygon $\mathrm{P}_{\epsilon}$ whose length $\mathrm{L}_{\epsilon}$ satisfies $|\mathrm{L}_{\epsilon}-\mathrm{L}|<\epsilon$ and whose area $\mathrm{A}_{\epsilon}$ satisfies $|\mathrm{A}_{\epsilon}-\mathrm{A}|<\epsilon$.

    For the polygon $\mathrm{P}_{\epsilon}$ we already have the isoperimetric inequality $\mathrm{L}_{\epsilon}^{2}\geq4\pi\mathrm{A}_{\epsilon}$.

    Now let $\epsilon\to0$ and we get the isoperimetric inequality for the given curve $\mathrm{C}$, $\mathrm{L}^{2}\geq4\pi\mathrm{A}$.

    Since the cirlce of the same length $\mathrm{L}$ bounds a region of area $\mathrm{A}_{0}$ satisfying $\mathrm{L}^{2}=4\pi\mathrm{A}_{0}$, we know that $\mathrm{A}\leq\mathrm{A}_{0}$.

    Thus we know that a circle maximizes the enclosed area among all smooth regular simple closed curves of the same length. So the maximizers exists. Then by parts (1)-(3) of this proof, there are no other maximizers, completing the proof of the isoperimetric theorem.
\end{proof}

\section{Karl Weierstrass}
Relying on calculus of variation, this proof defines area and length in terms of integrals. However Karl Weierstrass's calculus of variation is very strong, and that the isoperimetric problem pops out of it. Calculus of variations is concerned with the problem of extremising "functionals", finding extrema of functions of \textit{infinite} variables. Functionals can be looked at like "functions of functions". The result is two Euler-Lagrange equations which when solved, provide an equation in the form of a circle and the length of the radius which optimizes the area given the length of the perimeter. The lagrangian, denoted by $L(x,y,y')$ normally opted as $L=T-V$, the kinetic energy minus the potential energy. Extremal curves represent solutions to the isoperimetric problem, providing the shapes that maximize the enclosed area under a fixed perimeter. Extremal curves are smooth and regular, ensuring the validity of the Euler-Lagrange equation and the associated boundary conditions. We shall not give proofs to these theorem and lemmas.

\begin{definition}
    We say that $x=c$ is a critical point of the function $f(x)$ if $f(c)$ exists and if either of the following are true
    \begin{center}
        $f'(c)=0$ OR $f'(c)$ doesn't exist.
    \end{center}
\end{definition}

\begin{theorem}
	Consider the functional $\mathrm{J}(Y)$, an extremum, defined as follows:
	\begin{center}
		$\displaystyle \mathrm{J}[y]=\int_{a}^{b}L(x,y,y')\,dx$
	\end{center}
	where $L(x,y,y')$ is the lagrangian and $y'$ denotes the derivative of $y$ with respect to $x$. The critical points of $J[y]$ satisfy the Euler-Lagrange equation:
	\begin{center}
		$\displaystyle \frac{\partial}{\partial x}\Big(\frac{\partial L}{\partial y'}\Big)-\frac{\partial L}{\partial y}=0$.
	\end{center}
\end{theorem}
\begin{proof}
    Consider functions $\mathrm{Y}_{\epsilon}(x)$ of the form $\mathrm{Y}_{\epsilon}(x)=\mathrm{Y}(x)+\epsilon\eta(x)$

    where $\epsilon\in\mathbb{R}$, a smooth curve $\eta(x)\in \mathrm{C}^{2}[a,b]$ satisfies $\eta(a)=\eta(b)=0$ so that $\mathrm{Y}_{\epsilon}(a)=\mathrm{A}$ and $\mathrm{Y}_{\epsilon}(b)=\mathrm{B}$ i.e. $\mathrm{Y}_{\epsilon}$ still satisfies the boundary conditions.

    so $\mathrm{Y}_{\epsilon}$ is a function which satisfies our boundary conditions and which is ``near to'' $\mathrm{Y}$ when $\epsilon$ is small. $\mathrm{I}(\mathrm{Y}_{\epsilon})$ depends on the value of $\epsilon$ and we write $\mathrm{I}[\epsilon]$ for the value of $\mathrm{I}(\epsilon)$:
    \begin{center}
        $\displaystyle \mathrm{I}[\epsilon]=\int_{a}^{b}\mathrm{F}(x,\mathrm{Y}_{\epsilon},\mathrm{Y}_{\epsilon}')\,dx$
    \end{center}
    when $\epsilon=0$, the function $\mathrm{I}[\epsilon]$ has an extremum and so
    \begin{center}
        $\displaystyle \frac{d\mathrm{I}}{d\epsilon}=0$ when $\epsilon=0$ 
    \end{center}
    we can compute the derivative $\displaystyle \frac{d\mathrm{I}}{d\epsilon}$ by differentiating under the integral sign:
    \begin{center}
        $\displaystyle \frac{d\mathrm{I}}{d\epsilon}=\frac{d}{d\epsilon}\int_{a}^{b}\mathrm{F}(x,\mathrm{Y}_{\epsilon},\mathrm{Y}_{\epsilon}')\,dx=\int_{a}^{b}\frac{d\mathrm{F}}{d\epsilon}\mathrm{F}(x,\mathrm{Y}_{\epsilon},\mathrm{Y}_{\epsilon}')\,dx$
    \end{center}
    we now use the multivariable chain rule to differentiate $\mathrm{F}$ with respect to $\epsilon$. Well, in our case, the first argument $x$ is independant of $\epsilon$, so $\displaystyle \frac{dx}{d\epsilon}=0$, and since $\mathrm{Y}_{\epsilon}=\mathrm{Y}+\epsilon\eta$ we have $\displaystyle \frac{d\mathrm{Y}_{\epsilon}}{d\epsilon}=\eta$ and $\displaystyle \frac{d\mathrm{Y}_{\epsilon}'}{d\epsilon}=\eta'$. Therefore
    \begin{center}
        $\displaystyle \frac{d\mathrm{F}}{d\epsilon}(x,\mathrm{Y}_{\epsilon},\mathrm{Y}_{\epsilon}')=\int_{a}^{b}\Big(\frac{\partial\mathrm{L}}{\partial y}\frac{\partial y}{\partial \epsilon}+\frac{\partial\mathrm{L}}{\partial y'}\frac{\partial y'}{\partial \epsilon}\Big)\,dx=\frac{\partial\mathrm{F}}{\partial y}\eta(x)+\frac{\partial\mathrm{F}}{\partial y'}\eta(x')$.
    \end{center}
    but recall that $\displaystyle \frac{d\mathrm{I}}{d\epsilon}$ when $\epsilon=0$. Since $\mathrm{Y}_{0}=\mathrm{Y}$ and $\mathrm{Y}_{0}'=\mathrm{Y}'$.
    \begin{center}
        $\displaystyle 0=\int_{a}^{b}\frac{\partial\mathrm{F}}{\partial y}(x,\mathrm{Y},\mathrm{Y}')\eta(x)+\frac{\partial\mathrm{F}}{\partial y'}(x,\mathrm{Y},\mathrm{Y}')\eta'(x)\,dx$
    \end{center}
    integrating the second term above by parts, we get
    \begin{center}
        $\displaystyle \int_{a}^{b}\frac{\partial\mathrm{F}}{\partial y'}\eta'(x)\,dx=\Big[\frac{\partial\mathrm{F}}{\partial y'}\eta(x)\Big]_{a}^{b}-\int_{a}^{b}\frac{d}{dx}\Big(\frac{\partial\mathrm{F}}{\partial y'}\Big)\eta(x)\,dx$.
    \end{center}
    the first term on the right hand side vanishes because $\eta(a)=\eta(b)=0$ and by substituting the second term we get 
    \begin{center}
        $\displaystyle \int_{a}^{b}\Big(\frac{\partial\mathrm{F}}{\partial y}-\frac{d}{dx}\frac{\partial\mathrm{F}}{\partial y'}\Big)\eta(x)\,dx=0$
    \end{center}
    the equation above holds for any $\eta(x)\in\mathrm{C}^2[a,b]$ satisfying $\eta(a)=\eta(b)=0$, so the fundamental lemma of calculus of variations tells us that $\mathrm{Y}(x)$ satisfies
    \begin{center}
        $\displaystyle \frac{\partial}{\partial x}\Big(\frac{\partial \mathrm{L}}{\partial y'}\Big)-\frac{\partial \mathrm{L}}{\partial y}=0$.
    \end{center}
\end{proof}
\begin{remark}
	$Y$ satisfying the Euler-Lagrange equation is a necessary, but not sufficient, condition for $J(Y)$ to be an extremum. In other words, a function $Y(x)$ may satisfy the Euler-Lagrange equation even when $J(Y)$ is not an extremum.
\end{remark}
\subsubsection{Isoperimetric with Lagrangian}
For the isoperimetric problem, the Lagrangian $L(x, y, y')$ becomes the integrand of the perimeter functional, which is the square root of $1 + (y')^2$.
\begin{center}
	$\displaystyle L(x, y, y') = \sqrt{1 + (y')^2}$
\end{center}
Applying the Euler-Lagrange equation to this Lagrangian, we get:
\begin{center}
	$\displaystyle \frac{d}{dx} \left( \frac{y'}{\sqrt{1 + (y')^2}} \right) - \frac{y}{\sqrt{1 + (y')^2}} = 0$
\end{center}
\begin{lemma}(\textbf{Existence of Extremal Curves})
    There exists at least one extremal curve that satisfies the Euler-Lagrange equation and corresponds to a critical point of the functional \( J[y] \).
\end{lemma}

\begin{lemma}(\textbf{Uniqueness of Extremal Curves})
    Under certain regularity conditions, there exists a unique extremal curve that satisfies the Euler-Lagrange equation and optimizes the area under a fixed perimeter.

    Solving the differential equation subject to the fixed endpoints~\citep{goldstein1980classical} and~\citep{hilbert1985methods}, along with the fixed area constraint, leads us to the discovery of extremal curves that not only minimize the perimeter but also provide profound insights into the Isoperimetric Inequality in two-dimensional spaces. 
\end{lemma}
\newpage
What if we remove one $x$ or $y$ or $y'$
\begin{itemize}
    \item $\mathrm{L}$ is explicitly independent of $y$. $\frac{\delta\mathrm{L}}{\delta y}=$constant,
    \item $\mathrm{L}=\mathrm{L}(x,y)$. $\frac{\delta\mathrm{L}}{\delta y}=0$,
    \item $\mathrm{L}=\mathrm{L}(y,y')$. $\mathrm{L}-y'\frac{\delta\mathrm{L}}{\delta y'}=$constant.
\end{itemize}

Direct proofs from Weierstrass' corollary can be found in $Curves$ $and$ $Surfaces$ $in$ $Euclidean$ $Spaces$~\citep{chern1966curves}.

\section{Erhard Schmidt}
E.Schmidt simplified the work of Weierstrass to whom provided a complete proof of the Isoperimetric problem, however this proof seemed difficult to digest thus later mathematicians came in to assist, decades later. 

Beginning with parameterised curves, a circle is defined using carefully selected intervals and bounding. Using advanced calculus, isoperimetric equality is obtained if all calculated isoperimetric inequality statements are equalities. But here we will start off with the initial formula that we will see down below and how this initial formula will be used.

\textbf{Initial Formula}
Area, A, bounded by a positively oriented simple closed curve where: 
\begin{center}
	$\displaystyle \alpha(t)=(x(t),y(t)), t\in [a,b]$ is an arbitrary parameter
\end{center}
\begin{center}
	$\displaystyle A=-\int_{a}^{b}y(t)x'(t)\,dt=\int_{a}^{b}x(t)y'(t)\,dt$

    $\displaystyle =1/2\int_{a}^{b}(xy'-yx')\,dt$
\end{center}
Observe that the second formula is acquired from the first one by recognizing that
\begin{center}
    $\displaystyle \int_{a}^{a}xy'\,dt=\int_{a}^{b}(xy)'\,dt-\int_{a}^{b}x'y\,dt$

    $\displaystyle =[xy(b)-xy(a)]-\int_{a}^{b}x'y\,dt$

    $\displaystyle = \int_{a}^{b}(xy)'\,dt$,
\end{center}
since the curve is closed. Folloing immediately from the first two formula, we have the third formula. 

To show the first formula from the initial formula, we consider initally the case where the curve is made up of two straight-line segments parallel to the y-axis
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=75mm]{Schmidt1}
        \caption{}
    \end{center}
\end{figure}\leavevmode\newline
and two arcs that can be written in the form
\begin{center}
    $y=f_{1}(x)$ and $y=f_{1}(x)$, $x\in[x_{0},x_{1}]$, $f_{1}>f_{2}$
\end{center}
Clearly, the area bounded by the curve is
\begin{center}
    $\mathrm{A}=\int_{x_{0}}^{x_{1}}f_{1}(x)\,dx-\int_{x_{0}}^{x_{1}}f_{2}(x)\,dx$.
\end{center}
Since the curve is positaively oriented, we obtain with the notation of Figure 4.10.

To prove the general case, it must be shown that it is possible to divide the region bounded by the curve into a finite number of regions of the above type.
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=80mm]{Schmidt2}
        \caption{curve's region divided into a finite number of regions}
    \end{center}
\end{figure}\leavevmode\newline\newline
If there exists a straight line $\mathrm{E}$ in the plane such that the distance $p(t)$ of $\alpha(t)$ to this line is a function with fintely many critial points. The initial formula can also be obtained by using Green's theorem in the plane.

\begin{definition}
    Let $\mathrm{C}$ be a simple closed curve then $\mathrm{C}$ is called positively oriented if the traversal of the curve is counter clockwise.

    The curve is called negatively oriented if the traversal of the curve is clockwise. 
\end{definition}

\begin{remark}
    The Green's theorem uses the definition of positively oriented curves. Which converts a line integral into a double integral, or the other way.
\end{remark}

\begin{theorem} (Green's Theorem)
    Let $\mathrm{C}$ be a positively oriented, piecewise smooth, simple, closed cruve and let $\mathrm{R}$ be the region enclosed by the curve. $f(x,y)=(u(x,y),v(x,y))$,

    \begin{center}
        $\displaystyle \int_{\delta R}\overrightarrow{f}\,d\overrightarrow{r}=\iint_{R}\frac{\delta v}{\delta x}-\frac{\delta u}{\delta y}\,dA$.
    \end{center}
\end{theorem}

\subsection{E.Schmidt's Proof}
In this proof we will use AM-GM inequality, Cauchy-Schwarz inequality and the fact that $\displaystyle A=\int_{0}^{l} xy' \,dx = -\int_{0}^{l} yx' \,ds$ so $\displaystyle c(s)=(x(s),y(s))$. This proof is quite satisfactory of the fact that the circle is a solution to the isoperimetric problem. Proof from~\citep{do2016differential} but it was also cited in~\citep{gluck2012isoperimetric}, where I started reading~\citep{do2016differential}
\leavevmode \\

Before beginning the main proof, we can show that and prove we can get the area by using Green's Theorem.
\newpage
\begin{proof}
	Let's begin the proof by trying to compute $\displaystyle \iint_{1} 1 \,du\,dv$
	\begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=40mm]{Schmidt3}
            \caption{the region we are computing; R is the region, C is the curve, and $\delta\mathrm{R}$ is the boundary}
        \end{center}
    \end{figure}\leavevmode
    \newline
    We can see that $\displaystyle \iint_{1} 1 \,du\,dv$ will give us the area for our formula.

	And now we should pick our candidates for what $\overrightarrow{f}$ could be, so that coming from the double integral side in the Green's theorem (Theorem 4.3.3) is possible. Hence the one condition that we know is $\displaystyle \frac{\delta v}{\delta x}-\frac{\delta u}{\delta y}=1$.
	
	So we have two solutions, the candidates:
	\begin{enumerate}
		\item $f(0,x)$,
		\item $g(-y,0)$.
	\end{enumerate}
	
	Now, by taking the line integral over these two candidates: $f(0,x)$ and $g(-y,0)$
	\begin{enumerate}
		\item
			$\int_{C} \overrightarrow{f} \,dr$ \;\;\;where\; $C=(x(t),y(t))$

            we will then get below, by definition of line integral; the boundaries of the integral will be from $0$ to $l$, as $l$ is the perimeter. The equation is nicely parameterized, we can just use this formula,
            \begin{center}
                $\displaystyle =\int_{0}^{l} \overrightarrow{f}(c(t))c'(t) \,dt$
            \end{center}

            Since that was the definition of the line integral, we can plug in the numbers from the candidates, giving us,
            \begin{center}
                $\displaystyle = \int_{0}^{l} (0,x(t))(x',y') \,dt$
            \end{center}

            If we take the dot product
			\begin{center}
                $\displaystyle = \int_{0}^{l} xy' \,dt$
            \end{center}
			
		\item
            The premise here will be the same as the previous, in that we take the line integral of $g(-y,0)$, thus
            \begin{center}
                $\displaystyle \int_{0}^{l} (-y,0)(x',y') \,dt$

                $\displaystyle =-\int_{0}^{l} x'y \,dt$
            \end{center}
	\end{enumerate}
    As a result, this will get us the area using Green's Theorem. 
\end{proof}
Thus, we now have everything we need to prove the actual theorem we want to prove.
\newpage
\begin{theorem}
    Let $\mathrm{C}$ be a simple, closed curve of length $l$. Let $\mathrm{A}$ be a region that encloses. Then
    \begin{center}
        $\displaystyle \mathrm{A}\leq\frac{l^2}{4\pi}$.
    \end{center}
\end{theorem}
\begin{proof}
    We first do a construction. The curve is arc length parameterised $\displaystyle \mathrm{C}(s)=(x(s),y(s))\;\;s\in[0,l]$
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=70mm]{esfigure}
            \caption{construction with a curve on top and a perfect cirlce on the bottom; origin starts at the center of the circle}
        \end{center}
    \end{figure}\leavevmode
    \newline
    In Figure 4.13, we will bring the lines $\mathrm{E}$ \& $\mathrm{E}'$ closer and closer together until we have reached $\mathrm{L}$ and $\mathrm{L}'$. Where finally it will be tangent at the two points, $s=0$ and $s=s_{1}$. 

    The circle will have a radius of $r$. 

    We can calculate the area of the curve on top since we have the arc length parameterised $\mathrm{C}(s)$.

    So now we have the circle, we can add both of these areas in Figure 4.13, and we bound both those areas, we can have a bound on the curve. With $\mathrm{C}(s)$, we know it is arc length parameterized, then when we take the derivative, the magnitude of the derivative is $1$. 

    Thus the advantage of having a circle, is that if we take the magnitude of the circle, we will still get $1$.

    Now we shall have to parameterize the circle,
    \begin{center}
        $\displaystyle \overline{\mathrm{C}}(s)=(\overline{x}(s),\overline{y}(s))$
        \begin{equation*}
            =\begin{cases}
                x, & \sqrt{r^{2}-x^{2}}\;\;s\in[0,s_{1}],\\
                x, & -\sqrt{r^{2}-x^{2}}\;\;s\in[s_{1},l].
            \end{cases}
        \end{equation*}
    \end{center}\leavevmode
    We know that the circle is not exactly a function, so we try to parameterize it like a function. For the top part of the curve, we can correlate each point on there to each point on the circle.

    \newpage
    \textbf{For our general idea:} Considering area of the circle and the curve, $\displaystyle \mathrm{A}+\pi r^{2}$
    \begin{figure}[hbt!]
        \begin{center}   
            \includegraphics[width=50mm]{esfigure2}
            \caption{a curve and cricle compressed with a rectangle around them}
        \end{center}
    \end{figure}\leavevmode
    \newline
    Hence we can see that we have a bound on the two areas,
    \begin{center}
        $\displaystyle \mathrm{A}+\pi r^{2}<2rl$
    \end{center}
    By using the AM-GM inequality,
    \begin{center}
        $\displaystyle \sqrt{\mathrm{A}+\pi r^{2}}\leq2rl=rl$
    \end{center}
    Squaring both sides,
    \begin{center}
        $\displaystyle \mathrm{A}+\pi r^{2}<r^{2}l^{2}$
    \end{center}
    And finally, we have $\displaystyle \mathrm{A}\leq\frac{l^2}{4\pi}$

    Since we want this to be stricter, a stricter rule called the Cauchy Schwarz inequality will be used. So the area of the curve
    \begin{center}
        $\displaystyle \mathrm{A}+\pi r^{2}=\int_{0}^{l}xy'\,ds-\int_{0}^{l}\overline{x}'\overline{y}\,ds$
    \end{center}
    The LHS is the parameterization of the curve and the RHS is the parameterization of the circle. So notice that that anytime we use a bar, we talk about the circle. We see that $\overline{x}$ is $x, \sqrt{r^{2}-x^{2}}\;s\in[0,s_{1}]$, which is also $x(s)$. Then
    \begin{center}
        $\displaystyle =\int_{0}^{l}xy'-x'\overline{y}\,ds$
    \end{center}
    The bar on the $y$ remains as one is above the other one. And we can interpret this as the dot product,
    \begin{center}
        $\displaystyle =\int_{0}^{l}(x,\overline{y})\cdot(y',-x')\,ds$
    \end{center}
    Now we use the Cauchy Schwarz inequality, introducing a possibility for an inequality,
    \begin{center}
        $\displaystyle =\int_{0}^{l}|x,\overline{y}|\cdot|y',-x'|\,ds$ ($x$ can also be $\overline{x}$)
    \end{center}
    $\displaystyle|x,\overline{y}|$ is the magnitude of the circle which is $r$, and $\displaystyle |y',-x'|$ is our derivative of our curve but the magnitude will be $1$ since the curve is arc length parameterized, so
    \begin{center}
        $\displaystyle =\int_{0}^{l}r\cdot1\,ds$

        $\displaystyle =rl$
    \end{center}
    For this final step,
    \begin{center}
        $\displaystyle \mathrm{A}\pi r^{2}\leq\Big(\frac{rl}{2}\Big)^{2}=\frac{r^{2}l^{2}}{4}$
    \end{center}
    Hence,
    \begin{center}
        $\displaystyle \mathrm{A}\leq\frac{l^2}{4\pi}$
    \end{center}

    \begin{problem}
        When does the two inequality hold?
    \end{problem}
    \begin{enumerate}
        \item Does the AM-GM inequality hold? We are taking the product of $\mathrm{A}\pi r^{2}$ so when both are the same, it will hold.
        \begin{center}
            $\displaystyle \sqrt{aa}=\frac{a+a}{2}$

            $\displaystyle \mathrm{A}=\pi r^{2}=\frac{l^{2}}{4\pi}$
        \end{center}

        Since, if we rotate the curve, the radius can change. Which changes the area but we know that the area is constant with respect to $r$. Then as we rotate $\mathrm{C}$, the radius has to be fixed.

        \item Does the Cauchy-Schwarz inequality hold? Well if we have two vectors 
        \begin{center}
            $\displaystyle \overrightarrow{v}\cdot\overrightarrow{w}=|\overrightarrow{v}||\overrightarrow{w}|$ when $\overrightarrow{v}=r\overrightarrow{w}$ (a scaling of the other factor)

            $\displaystyle =|\overrightarrow{v}||\overrightarrow{w}|\cos{\theta}$
        \end{center}
        Well, $\cos{\theta}$ is always less than or equal to $1$. And it only equals $1$ when $\theta$ is equal to $0$, meaning they are just parallel.

        $\displaystyle |x,\overline{y}|$ and $\displaystyle |y',-x'|$ are multiples of each other, and we can see that we have 
        \begin{center}
            $\displaystyle x=ry'$

            $\displaystyle y\cdot y_{0}=-rx'$, $y$ is shifted

            $\displaystyle x^{2}+(y-y_{0})^{2}=r^{2}(x'+y')=r^2\cdot1=r^{2}$, since the curve is arc length parameterized
        \end{center}
        \textbf{To check} what we have above
        \begin{center}
            $\displaystyle (\overline{x},\overline{y})\cdot(y',x')=|x,\overline{y}|\cdot|y',-x'|$

            $\displaystyle =r\cdot1$
        \end{center}
        It follows that we have a unit vector, then
        \begin{center}
            $\displaystyle =(\overline{x},\overline{y})=r(y',x')$
        \end{center}
        If $(y',x')$ is a scalar multiple of $(\overline{x},\overline{y})$. We can pull out the scalar and have two unit vectors, where the magnitude is still going to be an unit vector.
        \begin{center}
            $\displaystyle x=ry'$
        \end{center}
        For the second one, we will rotate about $(0,y_0)$
        \begin{center}
            $\displaystyle \begin{bmatrix}
                0 & -1\\
                1 & 0
            \end{bmatrix}
            \begin{bmatrix}
                x\\
                y-y_{0}
            \end{bmatrix}+
            \begin{bmatrix}
                0\\
                y_{0}
            \end{bmatrix}=\begin{bmatrix}
                -(y-y_{0})\\
                x+y_{0}
            \end{bmatrix}$
        \end{center}
        Since the rotations don't change the radius, we have
        \begin{center}
            $\displaystyle -(y-y_{0})=r(x+y_{0})'$

            $\displaystyle \longrightarrow y-y_{0}=-rx'$
        \end{center}
        Square both of these and we will have $\displaystyle r^{2}(x'^{2}+y'^{2})=r^{2}$.
    \end{enumerate}
\end{proof}

\section{Proof Using Fourier Analysis {\&} Differential Geometry}
In this proof of the Isoperimetric Inequality in two dimensions, we will look at domains
with continuously differentiable boundary. We will identify the Euclidean plane with $\mathrm{C}$
and we will consider the boundary as a periodic function from $\mathrm{R}$ to $\mathrm{C}$, so that we are able
to use Fourier analysis.~\citep{bar2010elementare} and~\citep{gehring2019isoperimetric}.

We will establish the isoperimetric inequality again:
\begin{theorem}
    Let $\mathrm{G}\subseteq\mathbb{R}^{2}$ be a bounded domain such that the boundary is a simply closed curve with period $\mathrm{L}$. Let $\mathrm{A}[\mathrm{G}]$ be the area and $\mathrm{U}[\mathrm{G}]$ be the perimeter of $\mathrm{G}$. Then
    \begin{center}
        $4\pi\cdot\mathrm{A}[\mathrm{G}]\leq\mathrm{U}[\mathrm{G}]$.
    \end{center}
\end{theorem}
\begin{proof}
    Without loss of generality, assume $c$ is a unit speed curve. Consider the injective restriction $\displaystyle \left.c\right|_{[0, \mathrm{~L}]}$ and by abusing the notations here, we are going to call it $c$. Hence, let $c(t)=(x(t), y(t))^{\mathrm{T}}$ and consider the complex valued function
    \begin{center}
        $\displaystyle z:\mathbb{R} \rightarrow \mathbb{C},\;\; z(t)=x\left(\frac{\mathrm{L}}{2 \pi} t\right)+i y\left(\frac{\mathrm{L}}{2 \pi t}\right).$
    \end{center}

    The function $z$ parametrizes the curve $c$. Now, we can look at the Fourier series of $z$, written (see Definition 2.1.13) as follows
    \begin{center}
        $\displaystyle \mathscr{F}_n[z](t)=\sum_{k=-\infty}^{\infty}c_k e^{i k t},$
    \end{center}

    where $c_k$ are the Fourier coefficients. Because $z$ is a periodic, continuously differentiable function, with Theorem 2.1.14 we can conclude that
    \begin{center}
        $\displaystyle z(t)=\sum_{k=-\infty}^{\infty} c_k e^{i k t}.$
    \end{center}

    In the next three steps, we will simplify the length and area. 
    
    Step 1. We want to express the length of $c$ by the Fourier coefficients. For this, we first compute
    \begin{center}
        \begin{equation}
            \displaystyle \int_0^{2 \pi}|\dot{z}(t)|^2 d t=\int_0^{2 \pi}\left(\frac{\mathrm{L}}{2 \pi}\right)^2 \underbrace{\left\|\dot{c}\left(\frac{\mathrm{L} t}{2 \pi}\right)\right\|^2}_{=1 \text { unit speed }} d t=\frac{\mathrm{L}^2}{2 \pi},
        \end{equation}
    \end{center}

    where the derivative of $z$ is given by $\displaystyle \dot{z}(t)=\sum_{k=-\infty}^{\infty} c_k i k e^{i k t}$. Hence, we get
    \begin{center}
        $\displaystyle \begin{aligned}\int_0^{2 \pi}|\dot{z}(t)|^2 d t=\int_0^{2 \pi} \dot{z}(t) \overline{\dot{z}(t)} d t & =\int_0^{2 \pi} \sum_{k,l=-\infty}^{\infty} c_k\overline{c_l}kle^{i(k-l)t}dt\\&=2\pi \sum_{k=-\infty}^{\infty}\left|c_k\right|^2 k^2.\end{aligned}$
    \end{center}

    Equation (4.1) implies that for the length of $c$
    \begin{center}
        $\displaystyle \mathrm{L}[c]^2=(2 \pi)^2 \sum_{k=-\infty}^{\infty} k^2\left|c_k\right|^2$
    \end{center}

    Step 2. Next, we want to express the area using the Fourier coefficients. From Lemma 2.1.24 it follows that
    \begin{center}
        $\displaystyle \begin{aligned}&2\mathrm{~A}[\mathrm{G}]=\int_0^{2 \pi} \Re(z(s) \cdot i \cdot \overline{\dot{z}(s)}) d s \\&=\int_0^{2 \pi} \Re\left(\sum_{k=-\infty}^{\infty} c_k e^{i k s} \cdot i \cdot \sum_{l=-\infty}^{\infty} \overline{c_l}(-i) l e^{-i l s}\right) d s \\& =\Re\left(\int_0^{2 \pi} \sum_{k, l=-\infty}^{\infty} l c_k \overline{c_l} e^{l(k-l) s} d s\right)=2 \pi \sum_{k=-\infty}^{\infty} k\left|c_k\right|^2 \\&\end{aligned}$
    \end{center}

    Step 3. Now, we put the first and the second step together. From
    \begin{center}
        $\displaystyle \frac{\mathrm{A}[\mathrm{G}]}{\pi}=\sum_{k=-\infty}^{\infty} k\left|c_k\right|^2 \leq \sum_{k=-\infty}^{\infty} k^2\left|c_k\right|^2=\frac{\mathrm{L}[c]^2}{4 \pi^2}$
    \end{center}

    follows $4 \pi \mathrm{A}[\mathrm{G}] \leq \mathrm{L}[c]^2$. In two dimensions we have $\mathrm{U}[\mathrm{G}]=\mathrm{L}[c]$. Thus, we showed the Isoperimetric Inequality. Equality holds if and only if
    \begin{center}
        $\displaystyle \sum_{k=-\infty}^{\infty} k\left|c_k\right|^2=\sum_{k=-\infty}^{\infty} k^2\left|c_k\right|^2 .$
    \end{center}

    This is equivalent to $c_k=0\; \forall k \neq 0,1$. This is satisfied if and only if we have $z(t)=$ $c_0+c_1 \cdot e^{i t}$, i.e., a circle.
\end{proof}

\chapter{n-Dimensional Case ($\mathbb{R}^n$)}
The idea of the proof for this theorem is to show the inequality above using induction on $n$. Here, we will use the Integral Theorem of Fubini to establish induction step. In this chapter, some statements of the theory of convex, compact sets will be introduced as well as properties of the volume functional. Later, we will show the Isoperimetric Inequality using the theorem of Brunn–Minkowski. We will follow~\citep{schneider2014convex}.

\section{Volume and Surface Measure}
In this subsection, we will introduce the volume functional and show its continuity. The results of this subsection are important in the proof of Brunn-Minkowski.~\citep{gehring2019isoperimetric}

\begin{definition}
    Let $M\subseteq\mathbb{R}^{n}, p\geq0$. For $\delta>0$ define
    \begin{center}
        $\displaystyle \mathscr{H}_{\delta}^{P}(M):=\inf\{\sum\limits_{i=1}^{\infty}\alpha(p)(\frac{diam C_{i}}{2})^{p};(C_{i})_{i\in\mathbb{N}}$ open sets in $\mathbb{R}^n$

        \hspace{1cm}with $diam C_{i}\leq\delta$ and $M\subseteq\underset{i\in\mathbb{N}}{\cup}{C_{i}}\}$
    \end{center}
    with $\displaystyle \alpha(p)=\frac{\pi^{\frac{p}{2}}}{\Gamma(p)(\frac{p}{2}+1)}$ for $p\neq0$, where $\Gamma(p):=\int_{0}^{\infty}t^{-1}e^{-t}\,dt$ and $\alpha(0)=0$.
    
    Define the p-dimensional Hausdorff measure of $M$ by
    \begin{center}
        $\displaystyle \mathscr{H}^{p}(M):=\underset{\delta>0}{\sup}\mathscr{H}_{\delta}^{p}(M)=\underset{\delta\to0}{\lim}\mathscr{H}_{\delta}^{p}(M)$.
    \end{center}
\end{definition}

\begin{remark}
    Let $t\in\mathbb{R}^{n}$ and $\lambda\in\mathbb{R}$, then we have
    \begin{center}
        $\displaystyle \mathscr{H}^{p}(\lambda M)=\lambda^{p}\mathscr{H}^{p}(M)$ and $\mathscr{H}^{p}(M=t)=\mathscr{H}^{p}(M)$.
    \end{center}
    Furthermroe, for $A\subseteq B$ we have $\mathscr{H}^{p}(A)\leq\mathscr{H}^{p}(B)$.
\end{remark}

\begin{definition}
    The volume funcational $V_{n}$ on $\mathscr{K}^{n}$ is defined by the restriction of the $n$-dimensional Hausdorff measure on $\mathscr{K}^{n}$.
\end{definition}

\begin{note}
    If we don't have the restriction here, the $n$ could be anything. Having the restriction, gives us a clearer domain to work with.
\end{note}

\begin{theorem}
    The volume functional $V_{n}:\mathscr{K}^{n}\to\mathbb{R}$ is continuous.
\end{theorem}
\begin{proof}
    \textbf{Case 1 $\mathrm{V}_{n}(\mathrm{K})=0$:}
    Let $\overline{a}\in\mathscr{K}^{n}$ and, without loss of generality, assume $\delta(K,\overline{K})=\alpha\leq1$. Thus, it holds that $\overline{K}\subseteq K+\alpha B^{n}$. Since $V_{0}(K)=0$ and $K$ is convex, we know that $K$ has to be contained in a hyperplane. From the monotony of the Hausdorff measure it follows for $u$ orthogonal on the hyperplane, that
    \begin{center}
        $\displaystyle V_{n}(\mathrm{K})\leq \mathrm{V}_{n}(K+\alpha \mathrm{B}_{n})$

        $\displaystyle =\int_{-\alpha}^{\alpha}\mathrm{V}_{n-1}([\mathrm{K}+\alpha \mathrm{B}^{n}]\cap\mathrm{H}_{u,\zeta})\,d\zeta$

        $\displaystyle \leq\int_{-\alpha}^{\alpha}\mathrm{V}_{n-1}(K+(\alpha\mathrm{B}^{n}\cap\mathrm{H}_{u,\zeta}))\,d\zeta$

        $\displaystyle =2\alpha \mathrm{V}_{n-1}(K+(\alpha\mathrm{B}^{n}\cap\mathrm{H}_{u,0}))$

        $\displaystyle \overset{\alpha\leq1}{\leq}\underbrace{2\mathrm{~V}_{n-1}\left(\mathrm{~K}+\left(\mathrm{B}^n\cap \mathrm{H}_{u, 0}\right)\right)}_{:=c(\mathrm{~K})}\cdot\alpha$,
    \end{center}
    In the second line we used that $K+\alpha B^{n}$ varies in the fixed coordinate of $K$ by $2\alpha$. Since $c(K)$ is fixed and does not depend on $\alpha$ the continuity follows.

    \textbf{Case 2 $\mathrm{V}_{n}(\mathrm{K})>0$:}
    Without loss of generality, assume that $0\in\overset{\circ}{\mathrm{K}}$ (if not, we can shift it, since the Hausdorff measure is invariant under shifts). Let $\epsilon>0$ and choose $\lambda>1$ such that
    \begin{center}
        $\displaystyle (\lambda^{n}-1)\lambda^{n}\mathrm{V}_{n}(\mathrm{K})<\epsilon$
    \end{center}
    and $\rho>0$ so that $\displaystyle \rho\mathrm{B}^{n}\subseteq\overset{\circ}{\mathrm{K}}$. From Lemma 13, we 
    know that there is an $\alpha>0$ with $\displaystyle \alpha\leq(\lambda-1)\rho$ so that $\displaystyle \rho\mathrm{B}_{n}\subseteq\overset{\circ}{\mathrm{K}}\subseteq\overline{\mathrm{K}}$. For all $\mathrm{K}$ with $\delta(K,\overline{\mathrm{K}})<\alpha$. From $\displaystyle \delta(\mathrm{K},\overline{\mathrm{K}})<\alpha$ it follows
    \begin{center}
        $\displaystyle \mathrm{K}\subseteq\overline{\mathrm{K}}+\alpha\mathrm{B}^{n}\subseteq\overline{\mathrm{K}}+(\lambda-1)\rho\mathrm{B}^{n}\subseteq\overline{\mathrm{K}}+(\lambda-1)\overline{\mathrm{K}}=\lambda\overline{\mathrm{K}}$
    \end{center}
    With the same argument, we can also show that $\overline{\mathrm{K}}\subseteq\lambda\mathrm{K}$. Hence we have the inequalities $\displaystyle \mathrm{V}_{n}(\mathrm{K})\leq\mathrm{V}_{n}(\lambda\mathrm{K})=\lambda^{n}\mathrm{V}_{n}(\overline{\mathrm{K}})$ and $\displaystyle \mathrm{V}(\overline{\mathrm{K}})\leq\mathrm{V}_{n}(\lambda\mathrm{K})=\lambda^{n}\mathrm{V}_{n}{\mathrm{K}}$. \newline
    This implies
    \begin{center}
        $\displaystyle \mathrm{V}_{n}(\mathrm{K})-\mathrm{V}_{n}(\overline{\mathrm{K}})\leq(\lambda^{n}-1)\mathrm{V}_{n}(\overline{\mathrm{K}})\leq(\lambda^{n}-1)\lambda^{n}\mathrm{V}_{n}(\mathrm{K})$ and

        $\displaystyle \mathrm{V}_{n}(\overline{\mathrm{K}})-\mathrm{V}_{n}(\mathrm{K})\leq(\lambda^{n}-1)\mathrm{V}_{n}(\mathrm{K})\overset{\lambda>1}{\leq}(\lambda^{n}-1)\lambda^{n}\mathrm{V}_{n}(\mathrm{K})$.
    \end{center}
    As a consequence we have the estimate
    \begin{center}
        $\displaystyle |\mathrm{V}_{n}(\mathrm{K})-\mathrm{V}_{n}(\overline{\mathrm{K}})|\leq(\lambda^{n}-1)\lambda^{n}\mathrm{V}_{n}(\mathrm{K})<\epsilon$.
    \end{center}
    This implies the continuity of $\mathrm{V}_{n}$.
\end{proof}

\begin{note}
    In the case where the volume functinal is not continuous, we would have a disjoint area of region, which cannot happen since this defeats the purpose of the problem.
\end{note}

\begin{theorem}(Steiner's Formula)
    There are $\displaystyle \mathrm{V}_{m}:\mathscr{K}^{n}\to\mathbb{R}$ and cofficients $k_i\in\mathbb{R}$ for $i=0,1,\dots,n$ such that 
    \begin{center}
        $\displaystyle \mathrm{V}_{n}(\mathrm{K}+\rho\mathrm{B}^{n})=\overset{n}{\underset{m=0}{\sum}}\rho^{n-m}k_{n-m}\mathrm{V}_{m}(\mathrm{K})$
    \end{center}
    for all $\mathrm{K}\in\mathscr{K}^{n}$, $\rho\geq0$.
\end{theorem}
A proof of this can be found in~\citep{schneider2014convex} (Theorem 4.2.1).

\begin{remark}
    Steiner’s formula implies that $\rho\mapsto\mathrm{V}_{n}(\mathrm{K}+\rho\mathrm{B}^{n})$ is a polynomial of degree $n$.
\end{remark}

\begin{definition} (Surface Measure)
    Let $\mathrm{K}\subseteq\mathscr{K}^{n}$. Then we define the \textit{surface measure} of $\mathrm{K}$ by
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K}):=\underset{\rho\to0}{\lim}\frac{\mathrm{V}_{n}(\mathrm{K}+\epsilon\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{\rho}$.
    \end{center}
\end{definition}

\begin{note}
    The surface measure, in $3$ dimensional case, will measure the surface area. And in $2$ dimensions, measures the length.
\end{note}

\begin{note}
    It maybe unclear on how to check if the surface measure will be convex or not, however below will solve that issue.
\end{note}

\begin{remark}
    This limit exists, because $\mathrm{V}_{n}(\mathrm{K}+\epsilon\mathrm{B}^{n})$ is a polynomial and, therefore, it is smooth.
\end{remark}

\begin{remark}
    Let $\mathrm{B}^{n}\subseteq\mathbb{R}^{n}$ be a ball. We then have
    \begin{center}
        $\mathrm{S}(r\mathrm{B}^{n})=nr^{n-1}\mathrm{V}_{n}(\mathrm{B}^{n})$
    \end{center}
\end{remark}
\begin{proof}
    Using the convexivity of $\mathrm{B}^{n}$ and the properties of the volume functional, we can compute
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{B}^{n})=\underset{\rho\downarrow0}{\lim}\frac{\mathrm{V}_{n}(\mathrm{K}+\epsilon\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{\rho}$

        $\displaystyle =\underset{\rho\downarrow0}{\lim}\frac{((r+\rho)^{n}-r^{n})\mathrm{V}_{n}(\mathrm{B}^{n})}{\epsilon}$

        $\displaystyle =\mathrm{V}_{n}(\mathrm{B}^{n})\underset{\rho\downarrow0}{\lim}\frac{(r+\rho)^{n}-r^{n}}{\epsilon}=\mathrm{V}_{n}(\mathrm{B})\cdot n\cdot r^{n-1}$.
    \end{center}
\end{proof}

\section{Brunn-Minkowski Theorem}
First we will show an important theorem of convex geometry, the Brunn-Minkowski Theorem, which we will use in the proof of the isoperimetric inequality in the next subsection. Osserman~\citep{osserman1978isoperimetric} wrote an extensive survey on the isoperimetric inequality. The traditional isoperimetric inequality for significant classes of subsets of $\mathbb{R}^{n}$ can be obtained quickly from the proof of the Brunn-Minkowski inequality, which takes only one page, and deserves to be better known.~\citep{gehring2019isoperimetric}

The Minkowski Addition of two arbitrary sets $\mathrm{S},\mathrm{T}\subset\mathbb{R}^{n}$ is defined to be
\begin{center}
    $a\mathrm{S}\boxplus b\mathrm{T}:=\{x+y:x\in a\mathrm{S}$ and $y\in b\mathrm{T}\}$
\end{center}
where $a,b$ are nonnegative numbers and $a\mathrm{S}$ is the dilation by factor $a$
\begin{center}
    $a\mathrm{S}=\{ax:x\in\mathrm{S}\}$.
\end{center}
For example, the Minkowski sum of two rectanbles is still a rectangle.
\begin{center}
    $r([0,a]\times[0,b])\boxplus s([0,c]\times[0,d])=[0,ra+sc]\times[0,rb+sd]$.
\end{center} 
\begin{figure}[hbt!]
    \begin{center}   
        \includegraphics[width=100mm]{BrunnMinkowski1}
        \caption{the Minkowski sum of a triangle and a rectangle}
    \end{center}
\end{figure}\leavevmode

The Brunn-Minkowski theorem states that when figures are added using Minkowski addition, the area of the final figure is greater than the sum of the areas of the individual figures because this addition method "smooths out" the shapes that are being united. As a result, the theorem:

\begin{theorem}(Brunn-Minkowski)
    Let $\mathrm{K}_{0},\mathrm{K}_{1}\in\mathscr{K}^{n}$ be two convex bodies and $\lambda\in[0,1]$, then
    \begin{center}
        $\displaystyle \mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}\geq (1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{\frac{1}{n}}+\lambda\mathrm{V}_{n}(\mathrm{K}_{0})^{\frac{1}{n}}$.
    \end{center}
    Equality holds for $\lambda\in(0, 1)$ if and only if $\mathrm{K}_{0}$ and $\mathrm{K}_{1}$ are contained in parallel hyperplanes or are homothetic.
\end{theorem}
\begin{proof}
    First, consider the case that $\mathrm{K}_{0},\mathrm{K}_{1}\in\mathscr{K}^{n}$ are two contrained in parallel hyperplanes.
    
    Let $\mathrm{K}_{0}\subset\mathrm{E}$ and $\mathrm{K}_{1}\subset\mathrm{F}$ with E and F huperplanes. Without loss of generality, assume that for all $x\in\mathrm{E}$ we have $x=t$ for some $t\in\mathbb{R}$, and for all $y\in\mathrm{F}$ we have $y_{1}=r$ for some $r\in\mathbb{R}$.
    
    It then follows for all $z\in(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1}$ that there are $x\in\mathrm{K}_{0}$ and $y\in\mathrm{K}_{1}$ with
    \begin{center}
        $z_{1}=(1-\lambda)x_{1}+\lambda y_{1}=(1-\lambda)t+\lambda s$.
    \end{center}
    Therefore, $(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1}$ is also contained in a parallel hyperplane. Since hyperplanes are $n-1$ dimensional, equality holds trivially.

    Now, let $\mathrm{K}_{0},\mathrm{K}_{1}\in\mathscr{K}^{n}$ be homothetic and $\mathrm{K}_{0}=\mu\mathrm{K}_{1}$ for $\mu\in\mathbb{R}$ and $t\in\mathbb{R}^{n}$. For $\lambda\in[0,1]$ we have
    \begin{center}
        $\mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}=\mathrm{V}_{n}([(1-\lambda)\mu+\lambda]\mathrm{K}_{1}+t)^{\frac{1}{n}}$

        $=\mathrm{V}_{n}([(1-\lambda)\mu+\lambda]\mathrm{K}_{1})^{\frac{1}{n}}$

        $=[(1-\lambda)\mu+\lambda]\mathrm{V}_{n}(\mathrm{K}_{1}){\frac{1}{n}}$

        $=(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{\frac{1}{n}}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{\frac{1}{n}}$,
    \end{center}
    and therefore equality holds.

    In the following, we will show the inequality in Brunn-Minkowski Theorem.

    \textbf{Case 1 $\dim{\mathrm{K}_{0}}=\dim{\mathrm{K}_{1}}<n$.} Since $\mathrm{V}_{n}(\mathrm{K}_{0})=\mathrm{V}_{n}(\mathrm{K}_{1})=0$ this case is trival. Equality implies $\dim((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})<n$. This implies that all three convex bodies have to be contained in parallel hyperplanes.\

    \textbf{Case 2 $\dim{\mathrm{K}_{0}}<0, \dim{\mathrm{K}_{1}}=n$.} For $x\in\mathrm{K}_{0}$ we have
    \begin{center}
        $(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1}\supseteq(1-\lambda)x+\lambda\mathrm{K}_{1}$,
    \end{center}
    which implies that
    \begin{center}
        $\mathrm{V}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{1}}$.
    \end{center}
    This implies the Brunn-Minkowski inequality. If equality holds then $\mathrm{K}_{0}=\{x\}$. Hence, $\mathrm{K}_{0}$ and $\mathrm{K}_{1}$ are homothetic.

    \textbf{Case 3 $\dim{\mathrm{K}_{0}}=\dim{\mathrm{K}_{1}}=n$.} This case will be proven by induction.

    The case $n=1$ is trivial. Now consider the iteration from $n-1$ to $n$.

    Without loss of generality, assume $\mathrm{V}_{n}(\mathrm{K}_{0})=\mathrm{V}_{n}(\mathrm{K}_{1})=1$. This is allowed becuase the general inequality follows from this special case. Indeed, for $\mathrm{K}_{0},\mathrm{K}_{1}\in\mathscr{K}^{n}$ being $n$-dimensional with arbitrar volume and $\lambda\in[0,1]$ consider
    \begin{center}
        $\displaystyle \overline{\mathrm{K}_{i}}:=\frac{\mathrm{K}_{i}}{\mathrm{V}_{n}(\mathrm{K}_{i})^{\frac{1}{n}}}$ und $\displaystyle \overline{\lambda}:=\frac{\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}{(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^\{1/n\}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}\in[0,1]$.
    \end{center}
    Then we get
    \begin{center}
        $\displaystyle \mathrm{V}_{n}((1-\overline{\lambda})\overline{\mathrm{K}_{0}}+\overline{\lambda}\overline{\mathrm{K}_{1}})^{\frac{1}{n}}=\mathrm{V}_{n}\Big(\frac{(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}\overline{\mathrm{K}_{0}}-\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}\overline{\mathrm{K}_{0}}+\lambda\mathrm{K}_{1}}{(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{1/n}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}\Big)^{1/n}$

        $\displaystyle =\frac{1}{(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}\mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}$.
    \end{center}
    In addition, we also have (because the inequality is already proven for $\mathrm{V}_{n}(\overline{\mathrm{K}_{i}})=1$)
    \begin{center}
        $\displaystyle \mathrm{V}_{n}((1-\overline{\lambda})\overline{\mathrm{K}_{0}}+\overline{\lambda}\overline{\mathrm{K}_{1}})^{\frac{1}{n}}\geq(1-\overline{\lambda})\mathrm{V}_{n}(\overline{\mathrm{K}_{0}})^{\frac{1}{n}}+\overline{\lambda}\mathrm{V}_{n}(\mathrm{K}_{1})^{\frac{1}{n}}=1$.
    \end{center}
    This implies
    \begin{center}
        $\displaystyle \frac{1}{(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{1/n}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{1/n}}\mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}\geq1$.
    \end{center}
    Thus, the inequality in Brunn-Minkowski Theorem is proven.

    Therefore let $\displaystyle \mathrm{V}_{n}(\mathrm{K}_{0})=\mathrm{V}_{n}(\mathrm{K}_{1})=1$. Choose $\displaystyle u\in\mathbb{S}^{n}$ and $\displaystyle \lambda\in[0,1]$. We now introduce the following notations to shorten the computations. We set $\displaystyle \mathrm{K}_{\lambda}:=(1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1}$ and $\displaystyle \beta_{\lambda}:=h(\mathrm{K}_{\lambda},u)$, and $\displaystyle \alpha_{\lambda}:=-h(\mathrm{K}_{\lambda},-u)$. Furthermore, for $\displaystyle \zeta\in(\alpha_{i},\beta_{i})$\;$i=0,1$ we set the half space $\mathrm{H}^{-}(\zeta):=\{x\in\mathbb{R}^{n};\langle x,u\rangle\leq\zeta\}$ and the hyperplane $\displaystyle \mathrm{H}(\zeta):=\{x\in\mathbb{R}^{n};\langle x,u\rangle=h(\mathrm{K},u)\}$, as well as the volume $\displaystyle v_{i}:=\mathrm{V}_{n-1}(\mathrm{K}_{i}\cap\mathrm{H}(\zeta))$.

    Let us define for every $\zeta\in[\alpha_{i}\beta_{i}]$
    \begin{center}
        $\displaystyle w_{i}(\zeta):=\int_{\alpha_{i}}^{\zeta}v_{i}(t)\,dt$.
    \end{center}
    We know that the support functions $h$ and $\mathrm{V}_{n}$ are continuous. Hence, $\mathrm{V}_{n}(\mathrm{K}_{i}\cap\mathrm{H}^{-}(\zeta))$ is also continous in $\zeta$ and we can apply the Fundamental Theorem of Calculus on $w_{i}$. It follows that $w_i$ is differentiable and it holds that $w'_{i}(\zeta)=v_{i}>0$ (because $\dim\mathrm{K}_{i}=n$). This implies that $w_{i}$ is strictly monotonically increasing and is therefore a bijection on its image $(0,1)$. For $i=0,1$ define $z_{i}$ as the inverse function of $w_{i}$. Intuitively, this means that for a volume $\tau\in(0,1)$ with $\mathrm{V}_{n}(\mathrm{K}_{i}\cap\mathrm{H}^{-}(z_{i}(\tau)))=\tau$, the function $z_{i}$ maps $\tau$ to the ``height'' of $\mathrm{H}$ (figure).

    Consider $z_{\lambda}(\tau):=(1-\lambda)z_{0}+\lambda z_{1}$ for $\lambda\in(0,1)$, $i=0,1$, and $\tau\in(0,1)$. Let $k_i(\tau):=\mathrm{K}_{i}\cap\mathrm{H}(z_i(\tau))$, then we have
    \begin{center}
        $\displaystyle (1-\lambda)k_{0}(\tau)+\lambda k_{1}(\tau)\subseteq\mathrm{K}_{\lambda}\cap\mathrm{H}(z_{\lambda}(\tau))\;\forall\lambda,\tau\in(0,1)$
    \end{center}
    Now, we can prove the inequality in Brunn-Minkowski Theorem by induction. As mentioned before, the case $n=1$ holds trivially. For the iteration from $n-1$ to $n$, we can compute
    \begin{center}
        $\displaystyle \mathrm{V}_{n}(\mathrm{K}_{\lambda})\overset{Fubini}{=}\int_{\alpha_{\lambda}}^{\beta_{\lambda}}\mathrm{V}_{n-1}(\mathrm{K}_{\lambda}\cap\mathrm{H}(\zeta))\,d\zeta$

        $\displaystyle \overset{\zeta=z_{\lambda}(\tau)}{=}\int_{0}^{1}\mathrm{V}_{n-1}(\mathrm{K}_{\lambda}\cap\mathrm{H}(z_{\lambda}(\tau)))\cdot z'_{\lambda}(\tau)\,d\tau$

        $\displaystyle \overset{\zeta=z_{\lambda}(\tau)}{\geq}\int_{0}^{1}\mathrm{V}_{n-1}((1-\lambda)k_{0}(\tau)+\lambda k_{1}(\tau))\cdot z'_{\lambda}(\tau)\,d\tau$

        $\displaystyle \begin{aligned} & \geq \int_0^1[(1-\lambda) \underbrace{\mathrm{V}{n-1}\left(k_0(\tau)\right)^{\frac{1}{n-1}}}_{=\nu_0\left(z_0(\tau)\right)^{\frac{1}{n-1}}}+\lambda \underbrace{\mathrm{V}_{n-1}\left(k_1(\tau)\right)^{\frac{1}{n-1}}}_{=\nu_1\left(z_1(\tau)\right)^{\frac{1}{n-1}}}]^{n-1} \cdot\left(\frac{1-\lambda}{\nu_0\left(z_0(\tau)\right)}+\frac{\lambda}{\nu_1\left(z_1(\tau)\right)}\right) d \tau \\ & =\int_0^1\left((1-\lambda) \nu_0\left(z_0(\tau)\right)^{\frac{1}{n-1}}+\lambda \nu_1\left(z_1(\tau)\right)^{\left.\frac{1}{n-1}\right)}\right)^{n-1} \cdot\left(\frac{1-\lambda}{\nu_0\left(z_0(\tau)\right)}+\frac{\lambda}{\nu_1\left(z_1(\tau)\right)}\right) d \tau,\end{aligned}$
    \end{center}
    where we used in the third line the Inverse Function Theorem, which implies
    \begin{center}
        $\displaystyle z'_{i}(\tau)=\frac{1}{w'_{i}(\tau)}=\frac{1}{v_{i}(\tau)}$,
    \end{center}
    and the claim for $n-1$.

    To simplify the notation, define $\mathit{p}:=\frac{1}{n-1}$ and $v_{i}=v_{i}(z_{i}(\tau))$. The concavity of log implies
    \begin{center}
        $\displaystyle \log\Big([(1-\lambda)v^{\mathit{p}}_{0}+\lambda v^{\mathit{p}}_{1}]^{\frac{`}{\mathit{p}}}\cdot\Big(\frac{1-\lambda}{v_{0}}+\frac{\lambda}{v_{1}}\Big)\Big)=\frac{1}{\mathit{p}}\log[(1-\lambda)v^{\mathit{p}}_{0}+\lambda v^{\mathit{p}}_{1}]+\log\Big(\frac{1-\lambda}{v_{0}}+\frac{\lambda}{v_{1}}\Big)$

        $\geq\frac{1}{\mathit{p}}[\mathit{p}(1-\lambda)\log{v_{0}}+\mathit{p}\lambda\log{v_{1}}]-[(1-\lambda)\log{v_{0}}+\lambda\log{v_{1}}]=0$.
    \end{center}
    After applying exp, we see that
    \begin{center}
        $\displaystyle \Big((1-\lambda)v_{0}(z_{0}(\tau))^{\frac{1}{n-1}}+\lambda v_{1}(z_{1}(\tau))^{\frac{1}{n-1}}\Big)^{n-1}\cdot\Big(\frac{1-\lambda}{v_{0}(z_{0}(\tau))}+\frac{\lambda}{v_{1}(z_{1}(\tau))}\Big)\geq1$.
    \end{center}
    This implies
    \begin{center}
        $\displaystyle \int_{0}^{1}\Big((1-\lambda)v_{0}(z_{0}(\tau))^{\frac{1}{n-1}}+\lambda v_{1}(z_{1}(\tau))^{\frac{1}{n-1}}\Big)^{n-1}\cdot\Big(\frac{1-\lambda}{v_{0}(z_{0}(\tau))}+\frac{\lambda}{v_{1}(z_{1}(\tau))}\Big)\,d\tau\geq1$
    \end{center}
    on $(0,1)$. Hence, the inequality
    \begin{center}
        $\displaystyle \mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{\frac{1}{n}}=\mathrm{V}_{n}(\mathrm{K}_{\lambda})^{\frac{1}{n}}\geq(1-\lambda)\mathrm{V}_{n}(\mathrm{K}_{0})^{\frac{1}{n}}+\lambda\mathrm{V}_{n}(\mathrm{K}_{1})^{\frac{1}{n}}$.
    \end{center}
    is proven. Now, it only remains to show that he equality implies that $\mathrm{K}_{1}$ and $\mathrm{K}_{2}$ are homothetic. Suppose for a $\lambda\in(0,1)$ that equality holds.

    This implies $\mathrm{K}_{\lambda}\cap\mathrm{H}(z_{\lambda}(\tau))=(1-\lambda)k_{0}(\tau)+\lambda k_{1}(\tau)$. Thus, we have $k_{1}(\tau)=k_{0}(\tau)$ and therefore also $v_{1}(z_{1}(\tau))=v_{0}(z_{0}(\tau))$. This implies $z'_{1}(\tau)=z'_{0}(\tau)$, and hence, $z_{1}(\tau)-z_{0}(\tau)$ is constant.

    Without loss of generality, assume that $\int_{\mathrm{K}_i}y\,dy=0$, for $i=0,1$ (otherwise shift the sets).

    Then we see that $\int_{\mathrm{K}_i}\langle y,u\rangle\,dy=\sum_{i=1}^{n}u_{i}\int_{\mathrm{K}_i}y\,dy=0$. This implies
    \begin{center}
        $\displaystyle 0=\int_{\mathrm{K}_i}\langle y,u\rangle\,dy=\int_{\alpha_{i}}^{\beta_{i}}\int_{\mathrm{K}\cap\mathrm{H}(\zeta)}\underbrace{\langle u,z\rangle}_{=\zeta}\,dz\,d\zeta$

        $\displaystyle =\int_{\alpha_{i}}^{\beta_{i}}\mathrm{V}_{n-1}(\mathrm{K}_{i}\cap\mathrm{H}(\zeta))\zeta\,d\zeta$

        $\displaystyle =\int_{0}^{1}\mathrm{V}_{n-1}(\mathrm{K}_{i}\cap\mathrm{H}(z_{i}(\tau)))z_{\tau}\dot{z}_{i}(\tau)\,d\tau$







        $\displaystyle =\int_{0}^{1}v_{i}(z_{i}(\tau))z_{i}(\tau)\frac{1}{v_{i}(z_{i}(\tau))}\,d\tau=\int_{0}^{1}z_{i}(\tau)\,d\tau$,
    \end{center}
    by using $\mathrm{K_{i}=\bigcup_{\zeta}\mathrm{K}_{i}\cap\mathrm{H}(\zeta)}$ and Fubini's Theorem.

    Now, we konw that $\int_{0}^{1}z_{0}(\tau)-z_{1}(\tau)\,d\tau=0$, and $z_{0}=z_{1}$ on $(0,1)$. Therefore, we also know $w_{1}=w_{0}$ and $v_{1}=v_{0}$. Furthermore, using
    \begin{center}
        $\int_{\alpha_{1}}^{\beta_{1}}v_{1}(\tau)\,dt=w_{1}=w_{0}=\int_{\alpha_{0}}^{\beta_{0}}v_{0}(t)\,dt$,
    \end{center}
    we can conclude that $\alpha_{0}=\alpha_{1}$ and $\beta_{0}=\alpha_{1}$. This implies $h(\mathrm{K}_{0},u)=h(\mathrm{K}_{1},u)$ and, with Remark 8, we get that $\mathrm{K}_{0}=\mathrm{K}_{1}$. In particular $\mathrm{K}_{0}$ and $\mathrm{K}_{1}$ are homothetic.
\end{proof}

\begin{remark}
    The Brunn-Minkowski Inequality can also be proven for domains with differentiable boundary. Using this, it is also possible to prove the isoperimetric inequality. In addition, there is also a Brunn-Minkowski inequality for general domains. More information can be found in~\citep{gardner2002brunn}.
\end{remark}

\begin{corollary}
    Let $\mathrm{K}_{0}, \mathrm{K}_{1}\in\mathscr{K}_{n}$ and $\mathrm{I}=[0,1]$. Then the function
    \begin{center}
        $f:\mathrm{I}\to\mathbb{R}\;\lambda\to\mathrm{V}_{n}((1-\lambda)\mathrm{K}_{0}+\lambda\mathrm{K}_{1})^{1/n}$
    \end{center}
    is concave. The function $f$ is linear if and only if $\mathrm{K}_{0}$ and $\mathrm{K}_{0}$ are contained in parallel hyperplanes or are homothetic.
\end{corollary}

The next lemma follows by using basic tools of analysis. Hence, we will not prove it here, but we will use it in the proof of the isoperimetric inequality.

\begin{lemma}
    Let $f:\mathrm{I}\to\mathbb{R}$ be a smooth, convex functions such that $f'(0)=f(1)-f(0)$ holds. Then $f$ is linear.
\end{lemma}

\section{Proof of the Isoperimetric Inequality in n-Dimension}
Before proving the isoperimetric inequality using methods of convex geometry. Therefore, we need to adapt the assumptions of our theorem. Since we have introduced new language describing convex geometry, it is better that we also reintroduce the isoperimetric theorem in terms of our new language.~\citep{gehring2019isoperimetric} Hence:
\begin{theorem} (Isoperimetric Inequality)
    Let $\mathrm{K}\in\mathscr{K}_{0}^{n}$. Then
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K})\geq n\mathrm{V}_{n}(\mathrm{B}_{n})^{1/n}\mathrm{V}_{n}(\mathrm{K})^{1-1/n}$.
    \end{center}
    Equality holds if and only if $\mathrm{K}$ is a ball.
\end{theorem}
\begin{proof}
    Let $\mathrm{K}\in\mathscr{K}_{0}^{n}$. We have $\mathrm{V}_{n}(\mathrm{K})\neq0$. Consider $\displaystyle \epsilon:=\frac{t}{1-t}$. We compute
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K})=\underset{t\downarrow0}{\lim}\frac{\mathrm{V}{n}(\mathrm{K}+\frac{t}{1-t}\mathrm{B}^{n})-\mathrm{V}{n}(\mathrm{K})}{(\frac{t}{1-t})}$

        $\displaystyle =\underset{t\downarrow0}{\lim}\frac{\mathrm{V}{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})-(1-t)^{n}\mathrm{V}{n}(\mathrm{K})}{(1-t)^{n-1}t}$

        $\displaystyle =\underset{t\downarrow0}{\lim}\Big[\frac{\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{t}+\frac{(1-(1-t)^{n})\mathrm{V}_{n}(\mathrm{K})}{t}\Big]$

        $\displaystyle =\underset{t\downarrow0}{\lim}\Big[\frac{\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{t}\Big]+n\mathrm{V}_{n}(\mathrm{K})$.
    \end{center}
    In the third line, we used that the limits are the same. In the last line, we used the Theorem of l'Hopital. This implies
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K})-n\mathrm{V}_{n}(\mathrm{K})=\underset{t\downarrow0}{\lim}\frac{\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})-\mathrm{V}_{n}(\mathrm{K})}{t}\cdot(\ast)$
    \end{center}
    Now consider the function $f(t):=\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})^{1/n}$ and observe
    \begin{center}
        $f'(t)=\frac{1}{n}\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})^{1/{n-1}}\cdot\frac{d}{dt}\mathrm{V}_{n}((1-t)\mathrm{K}+t\mathrm{B}^{n})$.
    \end{center}
    This implies $f'(0)\overset{(\ast)}{=}\frac{1}{n}\mathrm{V}_{n}(\mathrm{K})^{1/{n-1}}(\mathrm{S}(\mathrm{K})-n\mathrm{V}_{n}(\mathrm{K}))$. By using corollary 5.2.3, it follows that $f$ is concave on [0,1]. hence, we know that $f'(0)\geq f(1)-f(0)$. This implies the inequality
    \begin{center}
        $\displaystyle \frac{1}{n}\mathrm{V}_{n}(\mathrm{K})^{1/{n-1}}\mathrm{S}(\mathrm{K})-\mathrm{V}_{n}(\mathrm{K})^{1/n}=\frac{1}{n}\mathrm{V}_{n}(\mathrm{K})^{1/{n-1}}(\mathrm{S}(\mathrm{K})-n\mathrm{V}_{n}(\mathrm{K}))\geq\mathrm{V}_{n}(\mathrm{B}^{n})^{1/n}-\mathrm{V}_{n}(\mathrm{K})^{1/n}$.
    \end{center}
    Therefore, the isoperimetric inequality
    \begin{center}
        $\displaystyle \mathrm{S}(\mathrm{K})\geq n\mathrm{V}_{n}(\mathrm{B}_{n})^{1/n}\mathrm{V}_{n}(\mathrm{K})^{1-1/n}$
    \end{center}
    follows. If $\mathrm{K}$ is a ball, equality follows by using remark 5.1.13.

    Equality implies $f'(0)=f(1)-f(0)$. By using the concavity of $f$ and lemma 5.2.4, it follows that $f$ is linear. From corollary 5.2.3, we know that $\mathrm{K}$ and $\mathrm{B}^{n}$ are homothetic.

    Hence, $\mathrm{K}$ is a ball.
\end{proof}

\begin{note}
    Notice in the proof, we use down arrows under our limits, this just means the same as $\to$
\end{note}

\subsection{3-Dimensional Case ($\mathbb{R}^{3}$)}
For dimension two, the isoperimetric inequality in theorem 5.3.1 can be written as
\begin{center}
$\displaystyle \mathrm{U}(\mathrm{K})\geq 2\mathrm{V}_{2}(\mathrm{B}_{2})^{1/2}\mathrm{V}_{2}(\mathrm{K})^{1/2}=2\sqrt{\pi}\mathrm{A}[\mathrm{K}]^{1/2}$,
\end{center}
where $\mathrm{A}$ is the area and $\mathrm{U}$ is the perimeter of $\mathrm{K}$. By squaring this, we get
\begin{center}
$4\pi\cdot\mathrm{A}[\mathrm{G}]\leq\mathrm{U}[\mathrm{G}]^{2}$.
\end{center}

For the dimension three, the isoperimetric inequality in theorem 5.3.1 can be written as
\begin{center}
$\displaystyle \mathrm{U}(\mathrm{K})\geq 3\mathrm{V}_{3}(\mathrm{B}_{3})^{1/3}\mathrm{V}_{2}(\mathrm{K})^{1/3}=3\sqrt{\pi}\mathrm{A}[\mathrm{K}]^{2/3}$
\end{center}
We can use the proof from $n$-dimensions for $n=3$. Hence the proof for the $3$-dimensions is an intermediate step for the $n$-dimension.

\section*{Conclusion}
\addcontentsline{toc}{chapter}{\hspace{0.2in}Conclusion}
We first started with Steiner's proof, where we looked at fixing two points between a concave set, then flipping that arc. And also dividing the length into two equal parts and ``stamping'' the larger area. Then we fount the largest area using interior angles of the quadrilateral. After we show that maximizer exists, we ultimately have the largest area. But this proof is not rigorous enough as it contains a fatal flaw within a logical error; It follows from Steiner’s argument that if the isoperimetric problem has a solution at all then the solution must be a circle.

Later, a rigorous proof is presented by Erhard Schmidt, which used the likes of calculus. The simplistic nature, is quite genius using knowledge of AM-GM inequality, Cauchy-Schwarz inequality and greens theorem, Schmidt is able to prove the isoperimetric problem. Schmidts begin using comparisons of the curve with the desired result, a circle.

In the final proof of the $2$-dimensional case, we needed a domain which has aboundary with high regularity. This proof relied on Fourier series, which cannot be generalized to $n$-dimension, which are only defined on $\mathbb{C}$. Then for the $n$-dimensional proof, the notion of convex and compact sets were important (we do not need any regularity assumptions on the boundary). As we said in the introduction, the convexity assumption is flexible and applicable in n dimensions.

\bibliography{The-Isoperimetric-Problem-References}
\end{document}